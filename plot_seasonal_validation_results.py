#!/usr/bin/env python

'''Plots verification results calculated before with get_skill_season.py and generates binary skill masks that are stored in netCDF format.
Author: Swen Brands, brandssf@ifca.unican.es
'''

#load packages
import math
import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import cartopy.crs as ccrs
import cartopy.feature as cf
import os
import pandas as pd
import xskillscore as xs
from math import radians, cos, sin, asin, sqrt #needed to calculate haversine distance
import pdb as pdb #then type <pdb.set_trace()> at a given line in the code below

#set input parameters
model_dataset = ['ecmwf51'] #list of model or reanalysis datasets: era5 or era5_land
corr_outlier = 'no' #load the outlier-correted validation results; yes or no
detrending = ['no','yes'] #yes or no, linear detrending of the gcm and obs time series prior to validation
file_years = [1981,2022] #start and end years indicated in the input file name, [1982,2016] for mod2strong_Nino, [1984,2022] for mod2strong_Nina
subperiod = 'enso2init' # a string defining the modulating oscillation and its phase, constructed from the <modulator> and <phase> input arguments in get_skill_season.py; currently "none", "enso0init", "enso1init" or "enso2init"
vers = 'v1j_seas'
#vers = 'as_input_file' # 'as_input_file' searches the version stored in the input files generated before with get_skill_season.py; other entries will be directly passed to the netCDF output file produced here
file_system = 'lustre' #lustre or myLaptop; used to create the path structure to the input and output files

# variables = ['SPEI-3-R','SPEI-3-M','fwi','tp','ssrd','si10','t2m','msl'] #variable names in CDS format
# ref_dataset = ['era5','era5','era5','era5','era5','era5','era5','era5'] # #list of model or reference observational dataset paired with <variables> input parameter below

variables = ['SPEI-3-R','SPEI-3-M'] #variable names in CDS format
ref_dataset = ['era5','era5'] # #list of model or reference observational dataset paired with <variables> input parameter below

domain = 'medcof' #the domain the verfication results have been save on by get_skill_season.py
sub_domain = 'iberia' #medcof (corresponds to no sub-domain), medcof2 or iberia; the domain the results are plotted for; if set to <medcof>, then no sub-selection will be applied and the results for the entire medcof domain will be plotted
apply_mask = 'yes' #yes or no; apply land sea-mask generated by Maialen Iturbide; if set to "yes", then the verficiation results over the sea are set to nan
critval_rho = 0.05 #critical value used to define the signficance of the correlation measuere applied here (Pearon and Spearman)
critval_skillscore = 0 #threshold value above which the skill scores applied here indicate skill (is normally set to 0). Currently the climatological mean value of the reference dataset (e.g. ERA5) is used as naiv reference forecast: Skill Score = 1 - SCORE / SCORE_clim  
critval_relbias = 5 #percentage threshold beyond which the absolute relative bias is printed with a dot in the maps and thus assumed to be "important"
critval_bias = 10*8 # this is a dummy threshold so far, replace by p-value from a t-test for bias significantly distinct from zero in future versions
critval_reliability = 0.25
critval_rpc = 1
scores = ['rpc','bias','relbias','spearman_r','pearson_r','crps_ensemble_skillscore_rand','reliability_lower_tercile','reliability_upper_tercile','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'] #skill measures to be plotted
relbias_max = 100 #magnitude of the upper and lower limit to be plotted in case of relbias and tp, this is a percentage value and it is used because the relbias can be very large in dry regions due to the near-to-zero climatological precip. there
manual_cbar_variables = ('SPEI-3-R','SPEI-3-M') #variables not participating in the colorbar adjustment made by the script due to excessive relative biases, the cbar for these variables is set to range from <relbias_max>*-1 to <relbias_max>
meanrho_max = 1.

precision = 'float32' #precision of the variable in the output netCDF files
dpival = 300 #resultion of the output figure in dpi
figformat = 'pdf' #format of the output figures: pdf, png, etc.
colormap_ascend = 'Spectral_r' #ascendig colormap used for plotting: Spectral_r 
colormap_div = 'seismic' #diverging (zero-centered) colormap used for plotting: seismic
titlesize = 6

##EXECUTE ##############################################################

#set directory tree as a function of the file system
if file_system == 'myLaptop':
    home = os.getenv('HOME')
    rundir = home+'/datos/tareas/proyectos/pticlima/pyPTIclima/pySeasonal' #script directory, you should be there or point to this directory when running these scripts via python
    dir_netcdf = home+'/datos/tareas/proyectos/pticlima/seasonal/results/validation/'+vers #path to outupt netcdf files produced with this script, containing an xarray dataset with all verification results
    dir_figs = home+'/datos/tareas/proyectos/pticlima/seasonal/results/validation/'+vers+'/'+sub_domain+'/'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod #path to output figures file generated by this script
    exec(open(rundir+'/functions_seasonal.py').read())
    exec(open(home+'/datos/tareas/proyectos/pticlima/pyPTIclima/pySolar/functions_radiation.py').read())
elif file_system == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    dir_netcdf = home+'/Results/seasonal/validation/'+vers #path to outupt netcdf files produced with this script, containing an xarray dataset with all verification results
    dir_figs = home+'/Results/seasonal/validation/'+vers+'/'+sub_domain+'/'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod #path to output figures file generated by this script
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
    exec(open(rundir+'/functions_seasonal.py').read())
    exec(open(home+'/Inventory/Scripts/pyPTIclima/pySolar/functions_radiation.py').read())
else:
    raise Exception('ERROR: unknown entry for <file_system> input parameter!')

dir_maps = dir_figs+'/maps'

print('INFO: Verfying '+str(model_dataset)+' against for '+str(variables)+' from '+str(ref_dataset)+' domain '+domain+' and sub-domain '+sub_domain+', detrending '+str(detrending)+' and outlier correction '+corr_outlier)
## check consistency of input parameters
if len(variables) != len(ref_dataset):
    raise Exception('ERROR: The two input lists <variables> and <ref_dataset> must have the same length !')

#create output directories if they do not exist.
if os.path.isdir(dir_figs) != True:
    os.makedirs(dir_figs)
for vv in np.arange(len(variables)):
    if os.path.isdir(dir_figs+'/'+variables[vv]) != True:
        os.makedirs(dir_figs+'/'+variables[vv])  

#init global minimum and maximum values
minvals_map = np.zeros((len(detrending),len(variables),len(model_dataset),len(scores)))
minvals_map[:] = np.nan
maxvals_map = minvals_map.copy()
minvals_pcolor_fraction = minvals_map.copy()
maxvals_pcolor_fraction = minvals_map.copy()
minvals_pcolor_mean = minvals_map.copy()
maxvals_pcolor_mean = minvals_map.copy()

#get minimium and maximum values of the colormaps for 1) maps, 2) pcolors displaying areal fractions in percent and 3) pcolors displaying areal mean values
for det in np.arange(len(detrending)):
    for vv in np.arange(len(variables)):
        if os.path.isdir(dir_figs+'/'+variables[vv]+'/maps') != True:
            os.makedirs(dir_figs+'/'+variables[vv]+'/maps')
        for dd in range(len(model_dataset)):
            colormaps_fractions_spatial = [] #one colormap per score
            colormaps_meanvals_spatial = []
            #load netcdf files containing the verification results
            if model_dataset[dd] == 'ecmwf51':
                filename_input = filename_input = 'validation_results_season_'+variables[vv]+'_'+model_dataset[dd]+'_vs_'+ref_dataset[dd]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.nc'
                # if subperiod == '':
                #     filename_input = 'validation_results_season_'+variables[vv]+'_'+model_dataset[dd]+'_vs_'+ref_dataset[dd]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+vers+'.nc'
                # else:
                #     filename_input = filename_input = 'validation_results_season_'+variables[vv]+'_'+model_dataset[dd]+'_vs_'+ref_dataset[dd]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.nc'
            else:
                raise Exception('ERROR: unknown entry for <model_dataset> !')
            nc_results = xr.open_dataset(dir_netcdf+'/'+filename_input) #load the input dataset
            
            #optionally apply land sea mask; set values of sea to nan
            if apply_mask == 'yes':
                print('Upon user request, values for sea grid-boxes are set to nan !')                
                #get mask label as a function of the requested sub-domain
                if sub_domain in ('medcof','medcof2'):
                    masklabel = 'Medcof'
                elif sub_domain == 'iberia':
                    masklabel = sub_domain[0].upper()+sub_domain[1:]
                else:
                    raise Excpetion('ERROR: Xheck entry for <sub_domain> input variable !')                
                mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                nc_mask = xr.open_dataset(mask_file)
                mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                nc_results = nc_results.where(mask_appended == 1, np.nan) #retain grid-boxes marked with 1 in mask
                #nc_results = nc_results.where(nc_mask.mask.values == 1, nc_results, np.nan) #retain grid-boxes marked with 1 in mask
                #pdb.set_trace()
                nc_mask.close()
                del(nc_mask)
            elif apply_mask == 'no':
                print('As requested by the user, the verification results are not filtered by a land-sea mask !')
            else:
                raise Exception('ERROR ! Check entry for <apply_mask> input parameter !')
                
            #optionally cut out sub domain
            if sub_domain in ('iberia','medcof2'):
                nc_results = get_sub_domain(nc_results,sub_domain) #select sub-domain to be verified
            elif sub_domain == 'medcof': #if set to <medcof>, then no sub-domain is chosen
                print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
            else:
                raise Exception('ERROR: unknown entry for <sub_domain> input parameter !')
            
            #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
            if det == 0 and vv == 0 and dd == 0:
                #get meshes for obtaining the areal average or areal percentage of significant hindcast correlation coefficient 
                xx,yy = np.meshgrid(nc_results.x.values,nc_results.y.values)
           
            #extract the min and max values for each score, <map> prefix points to values used for mapping at the grid-box scale and <pcolor> points to the values used in the pcolor figure
            for sc in np.arange(len(scores)):
                if scores[sc] in ('bias','relbias'):
                    if scores[sc] == 'relbias' and variables[vv] in manual_cbar_variables:
                        print('INFO: for '+variables[vv]+' and '+scores[sc]+', no min and max values are stored because they can be very large in dry regions due to the near-to-zero climatolologial precipitation.')
                    else:
                        maxvals_map[det,vv,dd,sc] = np.abs(nc_results[scores[sc]]).max().values
                        minvals_map[det,vv,dd,sc] = np.abs(nc_results[scores[sc]]).max().values*-1
                        meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                        fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                        maxvals_pcolor_mean[det,vv,dd,sc] = np.abs(meanvals_spatial).max()
                        minvals_pcolor_mean[det,vv,dd,sc] = np.abs(meanvals_spatial).max()*-1
                        maxvals_pcolor_fraction[det,vv,dd,sc] = fractions_spatial.max()
                        minvals_pcolor_fraction[det,vv,dd,sc] = 0
                    colormaps_fractions_spatial.append(colormap_ascend)
                    colormaps_meanvals_spatial.append(colormap_div)
                elif scores[sc] in ('mae','mape','rmse','crps_ensemble'):
                    maxvals_map[det,vv,dd,sc] = nc_results[scores[sc]].max().values
                    minvals_map[det,vv,dd,sc] = 0
                    meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                    fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                    maxvals_pcolor_mean[det,vv,dd,sc] = meanvals_spatial.max()
                    minvals_pcolor_mean[det,vv,dd,sc] = 0
                    maxvals_pcolor_fraction[det,vv,dd,sc] = fractions_spatial.max()
                    minvals_pcolor_fraction[det,vv,dd,sc] = 0
                    colormaps_fractions_spatial.append(colormap_ascend)
                    colormaps_meanvals_spatial.append(colormap_ascend)
                elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                    maxvals_map[det,vv,dd,sc] = 0.5 #global maximum for the specific model dataset and variable, suggested by Jose Manuel Gutiérrez
                    minvals_map[det,vv,dd,sc] = nc_results[scores[sc]].min().values #global minimum for the specific model dataset and variable
                    meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                    fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                    maxvals_pcolor_mean[det,vv,dd,sc] = meanvals_spatial.max()
                    minvals_pcolor_mean[det,vv,dd,sc] = meanvals_spatial.min()
                    #minvals_pcolor_mean[det,vv,dd,sc] = 0
                    maxvals_pcolor_fraction[det,vv,dd,sc] = fractions_spatial.max()
                    minvals_pcolor_fraction[det,vv,dd,sc] = 0
                    colormaps_fractions_spatial.append(colormap_ascend)
                    colormaps_meanvals_spatial.append(colormap_ascend)
                elif scores[sc] in ('rpc','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                    meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                    fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy)
                    if scores[sc] == 'rpc':
                        maxvals_map[det,vv,dd,sc] = 2
                        minvals_map[det,vv,dd,sc] = 0
                        maxvals_pcolor_mean[det,vv,dd,sc] = 2
                        minvals_pcolor_mean[det,vv,dd,sc] = 0
                    else:
                        maxvals_map[det,vv,dd,sc] = 1
                        minvals_map[det,vv,dd,sc] = -1
                        maxvals_pcolor_mean[det,vv,dd,sc] = np.abs(meanvals_spatial).max()
                        minvals_pcolor_mean[det,vv,dd,sc] = np.abs(meanvals_spatial).max()*-1
                    
                    #pcolor colorbar limits for rpc and others are equal
                    maxvals_pcolor_fraction[det,vv,dd,sc] = fractions_spatial.max()
                    minvals_pcolor_fraction[det,vv,dd,sc] = 0
                    colormaps_fractions_spatial.append(colormap_ascend)
                    colormaps_meanvals_spatial.append(colormap_div)
                elif scores[sc] in ('pearson_r','spearman_r'):
                    if scores[sc] in ('pearson_r'):
                        score_pval = 'pearson_pval'
                    elif scores[sc] in ('spearman_r'):
                        score_pval = 'spearman_pval'
                    else:
                        raise Exception('ERROR: check entry in <scores[sc]> !')
                    maxvals_map[det,vv,dd,sc] = nc_results[scores[sc]].max().values
                    minvals_map[det,vv,dd,sc] = 0
                    meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                    maxvals_pcolor_mean[det,vv,dd,sc] = meanvals_spatial.max()
                    minvals_pcolor_mean[det,vv,dd,sc] = 0
                    fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rho,pval_f=nc_results[score_pval].values,mode_f='fraction_smaller_pos',lat_f=yy)
                    maxvals_pcolor_fraction[det,vv,dd,sc] = fractions_spatial.max()
                    minvals_pcolor_fraction[det,vv,dd,sc] = 0
                    colormaps_fractions_spatial.append(colormap_ascend)
                    colormaps_meanvals_spatial.append(colormap_ascend)
                    del(score_pval)
                else:
                    raise Exception('ERROR: unknown value for <scores[sc]> !')
            ##close file
            nc_results.close()
            del(nc_results)
    
### get global min and max values covering the range of all considered model / reanalysis datasets, currently does not take into account various GCM datasets, i.e. only works for len(model_dataset) == 1
# minvals_pcolor = np.reshape(minvals_pcolor,(minvals_pcolor.shape[0],minvals_pcolor.shape[1]*minvals_pcolor.shape[2],minvals_pcolor.shape[3])).min(axis=1)
# maxvals_pcolor = np.reshape(maxvals_pcolor,(maxvals_pcolor.shape[0],maxvals_pcolor.shape[1]*maxvals_pcolor.shape[2],maxvals_pcolor.shape[3])).max(axis=1)
# minvals_map = np.reshape(minvals_map,(minvals_map.shape[0],minvals_map.shape[1]*minvals_map.shape[2],minvals_map.shape[3])).min(axis=1)
# maxvals_map = np.reshape(maxvals_map,(maxvals_map.shape[0],maxvals_map.shape[1]*maxvals_map.shape[2],maxvals_map.shape[3])).max(axis=1)

# minvals_pcolor = np.reshape(minvals_pcolor,(minvals_pcolor.shape[0]*minvals_pcolor.shape[1]*minvals_pcolor.shape[2],minvals_pcolor.shape[3])).min(axis=0)
# maxvals_pcolor = np.reshape(maxvals_pcolor,(maxvals_pcolor.shape[0]*maxvals_pcolor.shape[1]*maxvals_pcolor.shape[2],maxvals_pcolor.shape[3])).max(axis=0)
# minvals_map = np.reshape(minvals_map,(minvals_map.shape[0]*minvals_map.shape[1]*minvals_map.shape[2],minvals_map.shape[3])).min(axis=0)
# maxvals_map = np.reshape(maxvals_map,(maxvals_map.shape[0]*maxvals_map.shape[1]*maxvals_map.shape[2],maxvals_map.shape[3])).max(axis=0)

minvals_pcolor_fraction = np.nanmin(np.reshape(minvals_pcolor_fraction,(minvals_pcolor_fraction.shape[0]*minvals_pcolor_fraction.shape[1]*minvals_pcolor_fraction.shape[2],minvals_pcolor_fraction.shape[3])),axis=0)
maxvals_pcolor_fraction = np.nanmax(np.reshape(maxvals_pcolor_fraction,(maxvals_pcolor_fraction.shape[0]*maxvals_pcolor_fraction.shape[1]*maxvals_pcolor_fraction.shape[2],maxvals_pcolor_fraction.shape[3])),axis=0)
minvals_pcolor_mean = np.nanmin(np.reshape(minvals_pcolor_mean,(minvals_pcolor_mean.shape[0]*minvals_pcolor_mean.shape[1]*minvals_pcolor_mean.shape[2],minvals_pcolor_mean.shape[3])),axis=0)
maxvals_pcolor_mean = np.nanmax(np.reshape(maxvals_pcolor_mean,(maxvals_pcolor_mean.shape[0]*maxvals_pcolor_mean.shape[1]*maxvals_pcolor_mean.shape[2],maxvals_pcolor_mean.shape[3])),axis=0)
minvals_map = np.nanmin(np.reshape(minvals_map,(minvals_map.shape[0]*minvals_map.shape[1]*minvals_map.shape[2],minvals_map.shape[3])),axis=0)
maxvals_map = np.nanmax(np.reshape(maxvals_map,(maxvals_map.shape[0]*maxvals_map.shape[1]*maxvals_map.shape[2],maxvals_map.shape[3])),axis=0)

#then plot the results with this min and max values
for det in np.arange(len(detrending)):
    for vv in np.arange(len(variables)):
        for dd in range(len(model_dataset)):
            #load netcdf files containing the verification results
            if model_dataset[dd] == 'ecmwf51':
                #verification_results_season_tp_ecmwf51_vs_era5_medcof_corroutlier_no_detrended_no_1981_2022.nc
                filename_input = 'validation_results_season_'+variables[vv]+'_'+model_dataset[dd]+'_vs_'+ref_dataset[dd]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.nc'
            else:
                raise Exception('ERROR: unknown entry for <model_dataset> !')
            nc_results = xr.open_dataset(dir_netcdf+'/'+filename_input)

            #optionally apply land sea mask; set values of sea to nan
            if apply_mask == 'yes':
                print('Upon user request, values for sea grid-boxes are set to nan !')                
                #get mask label as a function of the requested sub-domain
                if sub_domain in ('medcof','medcof2'):
                    masklabel = 'Medcof'
                elif sub_domain == 'iberia':
                    masklabel = sub_domain[0].upper()+sub_domain[1:]
                else:
                    raise Excpetion('ERROR: Xheck entry for <sub_domain> input variable !')                
                mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                nc_mask = xr.open_dataset(mask_file)
                mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                nc_results = nc_results.where(mask_appended == 1) #retain grid-boxes marked with 1 in mask
                #nc_results = nc_results.where(nc_mask.mask.values == 1, nc_results, np.nan) #retain grid-boxes marked with 1 in mask
                #pdb.set_trace()
                nc_mask.close()
                del(nc_mask)
            elif apply_mask == 'no':
                print('As requested by the user, the verification results are not filtered by a land-sea mask !')
            else:
                raise Exception('ERROR ! Check entry for <apply_mask> input parameter !')
            
            #optionally cut out sub domain
            if sub_domain in ('iberia','medcof2'):
                nc_results = get_sub_domain(nc_results,sub_domain)
            elif sub_domain == 'medcof': #no sub-domain is chosen
                print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
            else:
                raise Exception('ERROR: unknown entry for <sub_domain> input parameter !')
            
            #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
            if det == 0 and vv == 0 and dd == 0:
                #get meshes for plotting the maps and init the output binary mask; halfres is used for plotting maps below
                y_coord = nc_results.y.values
                x_coord = nc_results.x.values
                xx,yy = np.meshgrid(x_coord,y_coord)
                binary_mask = np.zeros((len(detrending),len(variables),len(model_dataset),len(scores),len(nc_results.season),len(nc_results.lead),len(y_coord),len(x_coord)),dtype='single')
                binary_mask[:] = np.nan
                halfres = np.abs(np.diff(nc_results.x.values))[0]/2 #needed to plot the pcolormesh

            ##Get arrays to be shown as pcolor figures and maps (assigned as <pcolorme> and <mapme> respectively. In addition, retrieve a binary skill / no skill (1 / 0) named <binmask> below
            score_unit = np.zeros((len(scores))).tolist()
            score_info = score_unit.copy()
            for sc in np.arange(len(scores)):
                print('INFO: plotting '+scores[sc]+'...')
                score_ref = nc_results.reference_observations
                if os.path.isdir(dir_figs+'/'+variables[vv]+'/maps/'+scores[sc]) != True:
                    os.makedirs(dir_figs+'/'+variables[vv]+'/maps/'+scores[sc])
                if scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                    #pcolor for areal average of skill score values
                    savename_mean = dir_figs+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    savename_fraction = dir_figs+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy) #calculate spatial mean crps skill score
                    pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy) #calculate areal fraction with skill score > 0
                    units_pcolor_mean = 'skill score'
                    units_pcolor_fraction = '%'
                    label_pcolor_mean = 'areal mean '+scores[sc]
                    label_pcolor_fraction = 'areal fraction > '+str(critval_skillscore)+' '+scores[sc]                   
                    mapme = nc_results[scores[sc]].values
                    
                    binmask = np.zeros(mapme.shape)
                    binmask[:] = np.nan
                    mask1 = mapme > 0
                    mask0 = mapme <= 0
                    binmask[mask1] = 1
                    binmask[mask0] = 0
                    score_unit[sc] = 'binary'
                    score_info[sc] = 'Continuous Rank Probabililty Score with reference to climatological forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0); the shape of the continuous variable distribution is taken from the ensemble members'
                elif scores[sc] in ('pearson_r','spearman_r'):
                    if scores[sc] in ('pearson_r'):
                        score_pval = 'pearson_pval'
                    elif scores[sc] in ('spearman_r'):
                        score_pval = 'spearman_pval'
                    else:
                        raise Exception('ERROR: check entry in <scores[sc]> !')
                    #areal percentage of significant grid-box scale correlation coefficients is calculated and plotted
                    savename_fraction = dir_figs+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    savename_mean = dir_figs+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    pval = nc_results[score_pval].values
                    rho = nc_results[scores[sc]].values
                    pcolorme_fraction = get_spatial_aggregation(rho.copy(),critval_rho,pval_f=pval.copy(),mode_f='fraction_smaller_pos',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                    pcolorme_mean = get_spatial_aggregation(rho.copy(),mode_f='mean',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                    mapme = rho
                    units_pcolor_mean = scores[sc]
                    units_pcolor_fraction = '%'
                    label_pcolor_fraction = 'areal fraction of sig. positive '+scores[sc]
                    label_pcolor_mean = 'areal mean '+scores[sc]
                    
                    binmask = np.zeros(mapme.shape)
                    binmask[:] = np.nan
                    mask1 = (pval < critval_rho) & (rho > 0)
                    mask0 = (pval >= critval_rho) | (rho <= 0)
                    binmask[mask1] = 1
                    binmask[mask0] = 0
                    score_unit[sc] = 'binary'
                    score_info[sc] = 'significant '+scores[sc]+' at '+str(round(critval_rho*100))+' percent test-level and positive sign for the ensemble mean time series, yes (1) or no (0)'
                
                elif scores[sc] == 'rpc':
                    savename_mean = dir_figs+'/'+variables[vv]+'/pcolor_aerealmean_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    savename_fraction = dir_figs+'/'+variables[vv]+'/pcolor_aerealfraction_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                    pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                    mapme = nc_results[scores[sc]].values
                    label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                    label_pcolor_fraction = 'areal fraction whith '+nc_results[scores[sc]].name+' < 1'
                    units_pcolor_mean = nc_results[scores[sc]].units
                    units_pcolor_fraction = '%'                    
                    binmask = np.zeros(mapme.shape)
                    binmask[:] = np.nan
                    mask1 = mapme > critval_rpc
                    mask0 = mapme <= critval_rpc
                    binmask[mask1] = 1
                    binmask[mask0] = 0
                    score_unit[sc] = 'binary'
                    score_info[sc] = nc_results[scores[sc]].long_name +' following '+nc_results[scores[sc]].source+' 1 for rpc > 1, 0 for rpc <= 1'
 
                elif scores[sc] in ('bias','relbias'):
                    savename_mean = dir_figs+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    savename_fraction = dir_figs+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    pcolorme_mean = get_spatial_aggregation(np.abs(nc_results[scores[sc]].values),mode_f='mean',lat_f=yy) #get weighted spatial mean value
                    #pcolorme = nc_results[scores[sc]].stack(flat_dim=('x', 'y')).median(dim='flat_dim') #get spatial median
                    pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                    mapme = nc_results[scores[sc]].values
                    
                    label_pcolor_mean = 'areal mean absolute '+nc_results[scores[sc]].name
                    label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_bias)
                    units_pcolor_mean = nc_results[scores[sc]].units
                    units_pcolor_fraction = '%'
                    #add descriptive metadata
                    if scores[sc] == 'relbias':
                        info_string = 'relative bias of the ensemble mean time series in percent of the observed mean value below '+str(critval_relbias)+', yes (1) or no (0)'
                        threshold = critval_relbias #this is a percentage threshold
                    elif scores[sc] == 'bias':
                        info_string = 'bias of the ensemble mean time series below '+str(critval_bias)+', yes (1) or no (0)'
                        threshold = critval_bias
                    else:
                        raise Exception('ERROR: unknown entry for <scores[sc]> !')
                    score_info[sc] = info_string
                    #create binary mask (skill yes/no)
                    binmask = np.zeros(mapme.shape)
                    binmask[:] = np.nan
                    mask1 = np.abs(mapme) < threshold
                    mask0 = np.abs(mapme) >= threshold
                    binmask[mask1] = 1
                    binmask[mask0] = 0
                    score_unit[sc] = 'binary'
                elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                    savename_mean = dir_figs+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    savename_fraction = dir_figs+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+scores[sc]+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                    pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                    pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                    mapme = nc_results[scores[sc]].values
                    label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                    label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_reliability)
                    units_pcolor_mean = nc_results[scores[sc]].units
                    units_pcolor_fraction = '%'
                    if scores[sc] == 'reliability_lower_tercile':
                        info_string = 'reliability for the lower tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                        threshold = critval_reliability
                    elif scores[sc] == 'reliability_upper_tercile':
                        info_string = 'reliability for the upper tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                        threshold = critval_reliability
                    else:
                        raise Exception('ERROR: unknown entry for <scores[sc]> !')
                    score_info[sc] = info_string
                    #create binary mask (skill yes/no)
                    binmask = np.zeros(mapme.shape)
                    binmask[:] = np.nan
                    mask1 = np.abs(mapme) < threshold
                    mask0 = np.abs(mapme) >= threshold
                    binmask[mask1] = 1
                    binmask[mask0] = 0
                    score_unit[sc] = 'binary'
                else:                    
                    raise Exception('ERROR: '+scores[sc]+' are currently not supported by plot_seasonal_validation_results.py !')
                
                ## PLOT pcolor figures, x-axis: season / month the prediction is valid for and y-axis lead-time (1 season / month)
                #convert to xr dataArray and add metadata necessary for plotting
                pcolorme_mean = xr.DataArray(pcolorme_mean,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_mean)
                pcolorme_fraction = xr.DataArray(pcolorme_fraction,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_fraction)
                pcolorme_mean.attrs['units'] = units_pcolor_mean
                pcolorme_fraction.attrs['units'] = units_pcolor_fraction
                pcolorme_mean.attrs['season_label'] = nc_results.season.values
                pcolorme_fraction.attrs['season_label'] = nc_results.season.values
                pcolorme_mean.attrs['lead_label'] = nc_results.lead.values
                pcolorme_fraction.attrs['lead_label'] = nc_results.lead.values
                
                # if scores[sc] == 'relbias' and variables[vv] in manual_cbar_variables:
                # #if scores[sc] == 'relbias' and variables[vv] in ('tp','si10'):
                #     plot_pcolormesh_seasonal(pcolorme_mean,relbias_max*-1,relbias_max,savename,colormaps_mean[sc],dpival)            
                # elif scores[sc] in ('pearson_r','spearman_r'):
                #     #add additional xr data array for the areal mean correlation coefficient
                #     pcolorme_meanrho = xr.DataArray(pcolorme_meanrho,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name='areal_mean_'+scores[sc])
                #     pcolorme_meanrho.attrs = pcolorme.attrs #copy attributes from above
                #     pcolorme_meanrho.attrs['units'] = '-1 to 1' #and overwrite units
                #     #then plot both the fraction of significant rho and the areal mean rho
                #     plot_pcolormesh_seasonal(pcolorme,minvals_pcolor[sc],maxvals_pcolor[sc],savename,colormaps[sc],dpival)
                #     plot_pcolormesh_seasonal(pcolorme_meanrho,meanrho_max*-1,meanrho_max,savename_meanrho,colormap_div,dpival)
                # elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'): #for zero-bounded skill scores
                #     plot_pcolormesh_seasonal(pcolorme,0,maxvals_pcolor[sc],savename,colormaps[sc],dpival)
                # else:
                #     #plot_pcolormesh_seasonal(pcolorme,minvals_pcolor[det,sc],maxvals_pcolor[det,sc],savename,colormaps[sc],dpival) #colormap limits have been inferred from the score arrays above
                #     plot_pcolormesh_seasonal(pcolorme_mean,minvals_pcolor[sc],maxvals_pcolor[sc],savename,colormaps[sc],dpival)
                
                #make the pcolor plots
                plot_pcolormesh_seasonal(pcolorme_mean,minvals_pcolor_mean[sc],maxvals_pcolor_mean[sc],savename_mean,colormaps_meanvals_spatial[sc],dpival)
                plot_pcolormesh_seasonal(pcolorme_fraction,minvals_pcolor_fraction[sc],maxvals_pcolor_fraction[sc],savename_fraction,colormaps_fractions_spatial[sc],dpival)

                #produce a VERIFICATION MAP for each score, season and leadtime
                seasons = nc_results.season.values
                leads = nc_results.lead.values
                if scores[sc] in ('relbias','bias') and detrending[det] == 'yes':
                    print('INFO: '+scores[sc]+' is not plotted for detrended time series since the intercept/mean is also removed by the detrending function and the bias is thus 0 by definition.')
                else:
                    for sea in np.arange(len(seasons)):
                        for ll in np.arange(len(leads)):
                            if scores[sc] in ('pearson_r','spearman_r'):
                                critval_label = str(round(critval_rho*100))
                                agreeind = binmask[sea,ll,:,:] == 1
                            elif scores[sc] in ('relbias'):
                                critval_label = str(critval_relbias)
                                agreeind = binmask[sea,ll,:,:] == 1
                            elif scores[sc] in ('bias','reliability_lower_tercile','reliability_upper_tercile'):
                                critval_label = str(critval_bias)
                                agreeind = binmask[sea,ll,:,:] == 0 #if set to 0, no signficance layer is plotted upon the pclormesh in get_map_lowfreq_var() function
                            elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                critval_label = str(critval_skillscore)
                                agreeind = binmask[sea,ll,:,:] == 1
                            elif scores[sc] in ('rpc'):
                                critval_label = str(critval_rpc)
                                agreeind = binmask[sea,ll,:,:] == 1
                            else:
                                raise Exception('ERROR: '+scores[sc]+' is not yet supported by this function !')
                            title = variables[vv]+' '+seasons[sea]+' '+leads[ll]+' '+scores[sc]+' '+critval_label+' dtr'+detrending[det]+' '+sub_domain+' '+model_dataset[dd]+' vs '+score_ref+' '+str(file_years[0])+' '+str(file_years[1])
                            savename = dir_figs+'/'+variables[vv]+'/maps/'+scores[sc]+'/map_'+variables[vv]+'_'+seasons[sea]+'_'+leads[ll]+'_'+scores[sc]+'_'+critval_label+'_'+domain+'_'+sub_domain+'_'+model_dataset[dd]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[0])+str(file_years[1])+'_'+subperiod+'_'+vers+'.'+figformat
                            cbarlabel = scores[sc]
                            
                            #if scores[sc] == 'relbias' and variables[vv] in ('tp','si10','msl'):
                            if scores[sc] == 'relbias' and variables[vv] in manual_cbar_variables:
                                get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,relbias_max*-1,relbias_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                            elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                                get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,0,maxvals_map[sc],dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                            elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                abs_max = np.max((np.abs(minvals_map[sc]),np.abs(maxvals_map[sc])))# retain the maximum absolute value in the data, used to define the lower and upper limits of the colorbar in the next line
                                get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                            else:
                                #get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map[det,sc],maxvals_map[det,sc],dpival,title,savename,halfres,colormaps[sc],titlesize,cbarlabel) #colormap limits have been inferred from the score arrays above
                                get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map[sc],maxvals_map[sc],dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                
                #save a binary mask (significance or skill yes or no) in netcdf format
                binary_mask[det,vv,dd,sc,:,:,:,:] = binmask
            ##close input nc files and produced xr dataset
            pcolorme_mean.close()
            pcolorme_fraction.close()
        
        #bring the binary result masks into xarray data array format, one array per score. Then assign metadata to score / dataarray and stack them all as variables into a definite xarray dataset to be stored on netCDF
        for sc in np.arange(len(scores)):
            if scores[sc] in ('rpc','bias','relbias','pearson_r','spearman_r','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                print('INFO: saving validation results for '+scores[sc])
                binary_mask_score_i = binary_mask[:,:,:,sc,:,:,:,:]
                binary_mask_score_i = xr.DataArray(binary_mask_score_i,coords=[detrending,variables,model_dataset,nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['detrended','variable', 'model', 'season', 'lead', 'y', 'x'], name=scores[sc]+'_binary')
                binary_mask_score_i['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
                binary_mask_score_i['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
                binary_mask_score_i['model'].attrs['info'] = 'Name and version of the model / prediction system'
                binary_mask_score_i['season'].attrs['info'] = 'Season the forecast is valid for'
                binary_mask_score_i['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
                binary_mask_score_i['y'].attrs['name'] = 'latitude'
                binary_mask_score_i['y'].attrs['standard_name'] = 'latitude'
                binary_mask_score_i['x'].attrs['name'] = 'longitude'
                binary_mask_score_i['x'].attrs['standard_name'] = 'longitude'
                binary_mask_score_i.attrs['info'] = score_info[sc]
                binary_mask_score_i.attrs['unit'] = score_unit[sc]
                binary_mask_score_i.attrs['unit'] = score_unit[sc]
                if sc == 0:
                    ds_binary_mask = binary_mask_score_i.to_dataset()
                else:
                    ds_binary_mask[scores[sc]+'_binary'] = binary_mask_score_i
                binary_mask_score_i.close()
                del(binary_mask_score_i)
                ds_binary_mask.attrs['author'] = "Swen Brands (CSIC-UC, Instituto de Fisica de Cantabria), brandssf@ifca.unican.es or swen.brands@gmail.com"
                ds_binary_mask.attrs['validation_period'] = str(file_years[0])+' to '+str(file_years[1])
                
                # #set version of the netCDF output file
                # if vers == 'as_input_file':
                    # version_label = nc_results.version
                # else:
                    # version_label = vers
                
                if nc_results.version != vers:
                    raise Exception('ERROR: validation versions requested by the user in <vers> input variable does not match with metadata obtained from input file !')
                
                ds_binary_mask.attrs['version'] = vers
                ds_binary_mask.attrs['nan_criterion'] = 'A nan is set at a given grid-box if it is returned by xskillscore, e.g. due to a division by zero. It has been confirmed that this occcurs, e.g., if it does not rain at all either in the modelled or quasi-observed time-series.'
            else:
                print('WARNING: Validation results for '+scores[sc]+' are not yet saved to netCDF because the transition to binary format still has to be discussed with the other PTI members.')
                continue
        nc_results.close()
        savename_netcdf = dir_netcdf+'/binary_validation_results_pticlima_'+domain+'_'+sub_domain+'_'+str(file_years[0])+'_'+str(file_years[1])+'_'+subperiod+'_'+vers+'.nc'
        ds_binary_mask.to_netcdf(savename_netcdf)
        ds_binary_mask.close()
        print('INFO: plot_seasonal_validation_results.py has been run successfully and results have been stores in netCDF format at:')
        print(savename_netcdf)
