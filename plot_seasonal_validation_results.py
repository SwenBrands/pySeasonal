#!/usr/bin/env python

'''Plots verification results calculated before with get_skill_season.py and generates binary skill masks that are stored in netCDF format.
Author: Swen Brands, brandssf@ifca.unican.es
'''

#load packages
import math
import sys
import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import cartopy.crs as ccrs
import cartopy.feature as cf
import os
import pandas as pd
import xskillscore as xs
from math import radians, cos, sin, asin, sqrt #needed to calculate haversine distance
import pdb as pdb #then type <pdb.set_trace()> at a given line in the code below
import time
start_time = time.time()

if len(sys.argv) > 1:
    print("Reading from input parameters passed via bash")
    agg_label = [str(sys.argv[1])] # a list containing character strings
    plot_maps = str(sys.argv[2]) # a single character string
    vers = str(sys.argv[3]) # a single character string
else:
    # agg_label = ['1mon','3mon'] #list of strings used to label to aggregation period in the output files generated by this script; the length of this list defines the number of aggregation windows
    agg_label = ['5mon']
    plot_maps = 'no' #plot maps or not, yes or no; if set to no, the run time of this script is significantly reduced
    vers = 'v1p' #version of the validation results

file_system = 'lustre' #lustre or myLaptop; used to create the path structure to the input and output files

#set input parameters
models = ['cmcc4','eccc5','ecmwf51'] # ['cmcc35','ecmwf51'] list of models or reanalysis datasets: era5 or era5_land
file_years = [[1993,2022],[1993,2022],[1981,2022]] #[[1993,2022],[1981,2022]] list containing as many sub-lists as there are models to be validated; start and end years indicated in the input file name, [1982,2016] for mod2strong_Nino, [1984,2022] for mod2strong_Nina
variables = [['fwi','pvpot','tp','ssrd','si10','t2m','msl'],['fwi','pvpot','SPEI-3-M','tp','ssrd','si10','t2m','msl'],['fwi','pvpot','SPEI-3-M','tp','ssrd','si10','t2m','msl']] #variable names in CDS format
variables_out = [['fwi','pvpot','tp','ssrd','si10','t2m','msl'],['fwi','pvpot','SPEI-3-M','tp','ssrd','si10','t2m','msl'],['fwi','pvpot','SPEI-3-M','tp','ssrd','si10','t2m','msl']] #variable names of the binary skill mask generated by this script; these are the variable names used by Predictia
ref_dataset = [['era5','era5','era5','era5','era5','era5','era5'],['era5','era5','era5','era5','era5','era5','era5','era5'],['era5','era5','era5','era5','era5','era5','era5','era5']] # #list of models or reference observational dataset paired with <variables> input parameter below
subperiods = ['none','enso0init','enso1init','enso2init'] # a list of strings defining the modulating oscillations and their phase, constructed from the <modulator> and <phase> input arguments in get_skill_season.py; currently "none", "enso0init", "enso1init" or "enso2init"

domain = 'medcof' #the domain the verfication results have been save on by get_skill_season.py
sub_domain = 'medcof' #medcof (corresponds to no sub-domain), medcof2 or iberia; the domain the results are plotted for; if set to <medcof>, then no sub-selection will be applied and the results for the entire medcof domain will be plotted
masked_variables = ['fwi','SPEI-3-M'] #list of variables on which a land-sea mask will be applied, setting values over sea to nan
corr_outlier = 'no' #load the outlier-correted validation results; yes or no
detrending = ['no','yes'] #yes or no, linear detrending of the gcm and obs time series prior to validation
critval_rho = 0.05 #critical value used to define the signficance of the correlation measuere applied here (Pearon and Spearman)
critval_skillscore = 0 #threshold value above which the skill scores applied here indicate skill (is normally set to 0). Currently the climatological mean value of the reference dataset (e.g. ERA5) is used as naiv reference forecast: Skill Score = 1 - SCORE / SCORE_clim  
critval_relbias = 5 #percentage threshold beyond which the absolute relative bias is printed with a dot in the maps and thus assumed to be "important"
critval_bias = 10*8 # this is a dummy threshold so far, replace by p-value from a t-test for bias significantly distinct from zero in future versions
critval_reliability = 0.25
critval_rpc = 1
scores = ['rpc','bias','relbias','spearman_r','pearson_r','crps_ensemble_skillscore_rand','reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'] #skill measures to be plotted
cont_scores = ['roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore','crps_ensemble_skillscore_rand','pearson_r','spearman_r','bias'] #scores for which continuous values will be stored in the output files
relbias_max = 100 #magnitude of the upper and lower limit to be plotted in case of relbias and tp, this is a percentage value and it is used because the relbias can be very large in dry regions due to the near-to-zero climatological precip. there
manual_cbar_variables = ('SPEI-3-R','SPEI-3-M') #variables not participating in the colorbar adjustment made by the script due to excessive relative biases, the cbar for these variables is set to range from <relbias_max>*-1 to <relbias_max>
meanrho_max = 1.

precision = 'float32' #precision of the variable in the output netCDF files
dpival = 300 #resultion of the output figure in dpi
figformat = 'pdf' #format of the output figures: pdf, png, etc.
colormap_ascend = 'Spectral_r' #ascendig colormap used for plotting: Spectral_r 
colormap_div = 'seismic' #diverging (zero-centered) colormap used for plotting: seismic
titlesize = 6

##EXECUTE ##############################################################

#set directory tree as a function of the file system
if file_system == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    dir_flag = rundir+'/FLAG/plot'
    auxdir = home+'/Inventory/Scripts/pyPTIclima/pySolar'
    dir_netcdf = home+'/Results/seasonal/validation/'+vers #path to outupt netcdf files produced with this script, containing an xarray dataset with all verification results
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
else:
    raise ValueError('Unknown entry for <file_system> input parameter!')

#load custom functions of the pySeasonal and pySolar packages (to be merged in the future) and go to run directory
exec(open(rundir+'/functions_seasonal.py').read())
exec(open(auxdir+'/functions_radiation.py').read())
os.chdir(rundir)

print('INFO: Verfying '+str(models)+' against for '+str(variables)+' from '+str(ref_dataset)+' domain '+domain+' and sub-domain '+sub_domain+', detrending '+str(detrending)+' and outlier correction '+corr_outlier)
## check consistency of input parameters
for mm in np.arange(len(models)):
    if len(variables[mm]) != len(ref_dataset[mm]):
        raise ValueError('The two input lists <variables[mm]> and <ref_dataset[mm]> must have the same length !')
    if len(variables[mm]) != len(variables_out[mm]):
        raise ValueError('The two input lists <variables[mm]> and <variables_out[mm]> must have the same length !')

#create output directories needed by this script, if needed.
if os.path.isdir(dir_netcdf) != True:
    os.makedirs(dir_netcdf)
if os.path.isdir(dir_flag) != True:
    os.makedirs(dir_flag)

#init global minimum and maximum values
max_len_var = max(len(var_sub) for var_sub in variables) #get maximum length of all sublists in the <variables> list
minvals_map = np.zeros((len(agg_label),len(subperiods),len(detrending),max_len_var,len(models),len(scores))) #init array containing zero values
minvals_map[:] = np.nan # transform zero to nan
maxvals_map = minvals_map.copy()
minvals_pcolor_fraction = minvals_map.copy()
maxvals_pcolor_fraction = minvals_map.copy()
minvals_pcolor_mean = minvals_map.copy()
maxvals_pcolor_mean = minvals_map.copy()

#get the lead times per aggregation period and model
    #get maximum lead from files obtained with get_skill_season.py
lead_arr = np.zeros((len(agg_label),len(models)))
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/'+agg_label[ag]+'/scores' #set path to the directory containing the validation results
    for mm in range(len(models)):
        if models[mm] in ('ecmwf51','cmcc35','cmcc4','eccc5'):
            filename_input = 'validation_results_season_'+variables[mm][0]+'_'+agg_label[ag]+'_'+models[mm]+'_vs_'+ref_dataset[mm][0]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[0]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[0]+'_'+vers+'.nc'
        else:
            raise ValueError('Unknown entry for <models[mm]> !')
        nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input) #load the input dataset
        lead_arr[ag,mm] = len(nc_results.lead.values)
        nc_results.close()
lead_arr = xr.DataArray(lead_arr,coords=[agg_label,models],dims=['aggregation','model'], name='lead-time')

#get minimium and maximum values of the colormaps for 1) maps, 2) pcolors displaying areal fractions in percent and 3) pcolors displaying areal mean values
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/'+agg_label[ag]+'/scores' #set path to the directory containing the validation results

    for mm in range(len(models)):
        for su in np.arange(len(subperiods)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables[mm])):
                    colormaps_fractions_spatial = [] #one colormap per score
                    colormaps_meanvals_spatial = []
                    #load netcdf files containing the verification results
                    filename_input = 'validation_results_season_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+models[mm]+'_vs_'+ref_dataset[mm][vv]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.nc'
                    nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input) #load the input dataset
                    
                    #optionally apply land sea mask; set values of sea to nan
                    if variables[mm][vv] in masked_variables:
                        print('Upon user request, values for sea grid-boxes are set to nan for '+variables[mm][vv]+' !')               
                        #get mask label as a function of the requested sub-domain
                        if sub_domain in ('medcof','medcof2'):
                            masklabel = 'Medcof'
                        elif sub_domain == 'iberia':
                            masklabel = sub_domain[0].upper()+sub_domain[1:]
                        else:
                            raise Excpetion('ERROR: Xheck entry for <sub_domain> input variable !')                
                        mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'_ascending_lat.nc'
                        nc_mask = xr.open_dataset(mask_file)
                        mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                        nc_results = nc_results.where(mask_appended == 1, np.nan) #retain grid-boxes marked with 1 in mask
                        nc_mask.close()
                        del(nc_mask)
                    elif variables[mm][vv] not in masked_variables:
                        print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variables[mm][vv]+' !')
                    else:
                        ValueError('check whether <variables[mm][vv]> is in <masked_variables> !')
                        
                    #optionally cut out sub domain
                    if sub_domain in ('iberia','medcof2'):
                        nc_results = get_sub_domain(nc_results,sub_domain) #select sub-domain to be verified
                    elif sub_domain == 'medcof': #if set to <medcof>, then no sub-domain is chosen
                        print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
                    else:
                        raise ValueError('Unknown entry for <sub_domain> input parameter !')
                    
                    #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
                    if det == 0 and vv == 0 and mm == 0:
                        #get meshes for obtaining the areal average or areal percentage of significant hindcast correlation coefficient 
                        xx,yy = np.meshgrid(nc_results.x.values,nc_results.y.values)
                
                    #extract the min and max values for each score, <map> prefix points to values used for mapping at the grid-box scale and <pcolor> points to the values used in the pcolor figure
                    for sc in np.arange(len(scores)):
                        if scores[sc] in ('bias','relbias'):
                            if scores[sc] == 'relbias' and variables[mm][vv] in manual_cbar_variables:
                                print('INFO: for '+variables[mm][vv]+' and '+scores[sc]+', no min and max values are stored because they can be very large in dry regions due to the near-to-zero climatolologial precipitation.')
                            else:
                                maxvals_map[ag,su,det,vv,mm,sc] = np.abs(nc_results[scores[sc]]).max().values
                                minvals_map[ag,su,det,vv,mm,sc] = np.abs(nc_results[scores[sc]]).max().values*-1
                                meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                                fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()*-1
                                maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                                minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                        elif scores[sc] in ('mae','mape','rmse','crps_ensemble'):
                            maxvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].max().values
                            minvals_map[ag,su,det,vv,mm,sc] = 0
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                        elif scores[sc] in ('reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile'):
                            maxvals_map[ag,su,det,vv,mm,sc] = 0.5 #global maximum for the specific model, dataset, and variable, suggested by Jose Manuel Gutiérrez
                            minvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].min().values #global minimum for the specific model, dataset, and variable
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.min()
                            #minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                        elif scores[sc] in ('rpc','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy)
                            if scores[sc] == 'rpc':
                                maxvals_map[ag,su,det,vv,mm,sc] = 2
                                minvals_map[ag,su,det,vv,mm,sc] = 0
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 2
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            else:
                                maxvals_map[ag,su,det,vv,mm,sc] = 1
                                minvals_map[ag,su,det,vv,mm,sc] = -1
                                # maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()
                                # minvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()*-1
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0.85
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = -0.85

                            #pcolor colorbar limits for rpc and others are equal
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                        elif scores[sc] in ('pearson_r','spearman_r'):
                            if scores[sc] in ('pearson_r'):
                                score_pval = 'pearson_pval'
                            elif scores[sc] in ('spearman_r'):
                                score_pval = 'spearman_pval'
                            else:
                                raise ValueError('ERROR: check entry in <scores[sc]> !')
                            maxvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].max().values
                            minvals_map[ag,su,det,vv,mm,sc] = 0
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            # maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            # minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 1
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = -1
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rho,pval_f=nc_results[score_pval].values,mode_f='fraction_smaller_pos',lat_f=yy)
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                            del(score_pval)
                        else:
                            raise ValueError('Unknown value for <scores[sc]> !')
                    ##close file
                    nc_results.close()
                    del(nc_results)
        
#get minimum and maximum colorbar colours

minvals_pcolor_fraction = xr.DataArray(minvals_pcolor_fraction,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_pcolor_fraction = xr.DataArray(maxvals_pcolor_fraction,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

minvals_pcolor_mean = xr.DataArray(minvals_pcolor_mean,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_pcolor_mean = xr.DataArray(maxvals_pcolor_mean,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

minvals_map = xr.DataArray(minvals_map,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_map = xr.DataArray(maxvals_map,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

#then plot the results with this min and max values
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/'+agg_label[ag]+'/scores' #set path to the directory containing the validation results
    dir_netcdf_out = dir_netcdf+'/'+agg_label[ag]+'/skill_masks' #set path to the directory containing the validation results
    
    #create netCDF output directory if necessary
    if os.path.isdir(dir_netcdf_out) != True:
        os.makedirs(dir_netcdf_out)
    
    for mm in range(len(models)):
        dir_figs = dir_netcdf+'/'+agg_label[ag]+'/'+sub_domain+'/'+models[mm]+'/'+str(file_years[mm][0])+'_'+str(file_years[mm][1]) #path to output figures file generated by this script
        for su in np.arange(len(subperiods)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables[mm])):
                    #create output directories if they do not exist.
                    if os.path.isdir(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps') != True:
                        os.makedirs(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps')
                    
                    #load netcdf files containing the verification results
                    filename_input = 'validation_results_season_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+models[mm]+'_vs_'+ref_dataset[mm][vv]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.nc'
                    nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input)
                    lead_step = len(nc_results.lead.values) #length of the "lead" dimension

                    # #optionally apply land sea mask; set values of sea to nan
                    # if variables[mm][vv] in masked_variables:
                    #     print('Upon user request, values for sea grid-boxes are set to nan !')                
                    #     #get mask label as a function of the requested sub-domain
                    #     if sub_domain in ('medcof','medcof2'):
                    #         masklabel = 'Medcof'
                    #     elif sub_domain == 'iberia':
                    #         masklabel = sub_domain[0].upper()+sub_domain[1:]
                    #     else:
                    #         raise ValueError('Check entry for <sub_domain> input variable !')                
                    #     mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                    #     nc_mask = xr.open_dataset(mask_file)
                    #     mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                    #     nc_results = nc_results.where(mask_appended == 1) #retain grid-boxes marked with 1 in mask
                    #     #nc_results = nc_results.where(nc_mask.mask.values == 1, nc_results, np.nan) #retain grid-boxes marked with 1 in mask
                    #     nc_mask.close()
                    #     del(nc_mask)
                    # elif variables[mm][vv] not in masked_variables:
                    #     print('As requested by the user, the verification results are not filtered by a land-sea mask !')
                    # else:
                    #     raise ValueError('ERROR ! Check entry for <apply_mask> input parameter !')

                    #optionally apply land sea mask; set values of sea to nan
                    if variables[mm][vv] in masked_variables:
                        print('Upon user request, values for sea grid-boxes are set to nan for '+variables[mm][vv]+' !')               
                        #get mask label as a function of the requested sub-domain
                        if sub_domain in ('medcof','medcof2'):
                            masklabel = 'Medcof'
                        elif sub_domain == 'iberia':
                            masklabel = sub_domain[0].upper()+sub_domain[1:]
                        else:
                            raise Excpetion('ERROR: Xheck entry for <sub_domain> input variable !')                
                        mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                        nc_mask = xr.open_dataset(mask_file)
                        mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                        nc_results = nc_results.where(mask_appended == 1, np.nan) #retain grid-boxes marked with 1 in mask
                        nc_mask.close()
                        del(nc_mask)
                    elif variables[mm][vv] not in masked_variables:
                        print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variables[mm][vv]+' !')
                    else:
                        ValueError('check whether <variables[mm][vv]> is in <masked_variables> !')
                    
                    #optionally cut out sub domain
                    if sub_domain in ('iberia','medcof2'):
                        nc_results = get_sub_domain(nc_results,sub_domain)
                    elif sub_domain == 'medcof': #no sub-domain is chosen
                        print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
                    else:
                        raise ValueError('ERROR: unknown entry for <sub_domain> input parameter !')
                    
                    #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
                    if su == 0 and det == 0 and vv == 0:
                        #get meshes for plotting the maps and init the output binary mask; halfres is used for plotting maps below
                        y_coord = nc_results.y.values
                        x_coord = nc_results.x.values
                        xx,yy = np.meshgrid(x_coord,y_coord)
                        
                        #pdb.set_trace()
                        binary_mask = np.zeros((len(subperiods),len(detrending),len(variables_out[mm]),len(scores),len(nc_results.season),int(lead_arr.sel(aggregation=agg_label[ag],model=models[mm]).max().values),len(y_coord),len(x_coord)),dtype='single')
                        binary_mask[:] = np.nan
                        continuous_score = np.zeros((len(subperiods),len(detrending),len(variables_out[mm]),len(cont_scores),len(nc_results.season),int(lead_arr.sel(aggregation=agg_label[ag],model=models[mm]).max().values),len(y_coord),len(x_coord)),dtype='single')
                        continuous_score[:] = np.nan

                        halfres = np.abs(np.diff(nc_results.x.values))[0]/2 #needed to plot the pcolormesh

                    ##Get arrays to be shown as pcolor figures and maps (assigned as <pcolorme> and <mapme> respectively. In addition, retrieve a binary skill / no skill (1 / 0) named <binmask> below
                    score_unit = np.zeros((len(scores))).tolist()
                    score_info = score_unit.copy()
                    for sc in np.arange(len(scores)):
                        print('INFO: plotting '+scores[sc]+'...')
                        score_ref = nc_results.reference_observations
                        if os.path.isdir(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps/'+scores[sc]) != True:
                            os.makedirs(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps/'+scores[sc])
                        if scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                            #pcolor for areal average of skill score values
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy) #calculate spatial mean crps skill score
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy) #calculate areal fraction with skill score > 0
                            units_pcolor_mean = 'skill score'
                            units_pcolor_fraction = '%'
                            label_pcolor_mean = 'areal mean '+scores[sc]
                            label_pcolor_fraction = 'areal fraction > '+str(critval_skillscore)+' '+scores[sc]                   
                            mapme = nc_results[scores[sc]].values
                            
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = mapme > 0
                            mask0 = mapme <= 0
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            if scores[sc] == 'crps_ensemble_skillscore_clim':
                                score_info[sc] = 'Continuous Rank Probabililty Score with reference to a climatological forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0); the shape of the continuous variable distribution is taken from the ensemble members'
                            elif scores[sc] == 'crps_ensemble_skillscore_rand':
                                score_info[sc] = 'Continuous Rank Probabililty Score with reference to a random forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0); the shape of the continuous variable distribution is taken from the ensemble members'
                            elif scores[sc] in ('roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                score_info[sc] = 'ROC Area Under the Curve skill score with reference to a random forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0)'
                            else:
                                ValueError('Unexpected entry for <scores[sc] !')

                        elif scores[sc] in ('pearson_r','spearman_r'):
                            if scores[sc] in ('pearson_r'):
                                score_pval = 'pearson_pval'
                            elif scores[sc] in ('spearman_r'):
                                score_pval = 'spearman_pval'
                            else:
                                raise ValueError('Check entry in <scores[sc]> !')
                            
                            #areal percentage of significant grid-box scale correlation coefficients is calculated and plotted
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pval = nc_results[score_pval].values
                            rho = nc_results[scores[sc]].values
                            pcolorme_fraction = get_spatial_aggregation(rho.copy(),critval_rho,pval_f=pval.copy(),mode_f='fraction_smaller_pos',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                            pcolorme_mean = get_spatial_aggregation(rho.copy(),mode_f='mean',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                            mapme = rho
                            units_pcolor_mean = scores[sc]
                            units_pcolor_fraction = '%'
                            label_pcolor_fraction = 'areal fraction of sig. positive '+scores[sc]
                            label_pcolor_mean = 'areal mean '+scores[sc]
                            
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = (pval < critval_rho) & (rho > 0)
                            mask0 = (pval >= critval_rho) | (rho <= 0)
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = 'significant '+scores[sc]+' at '+str(round(critval_rho*100))+' percent test-level and positive sign for the ensemble mean time series, yes (1) or no (0)'
                        
                        elif scores[sc] == 'rpc':
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction whith '+nc_results[scores[sc]].name+' < 1'
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'                    
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = mapme > critval_rpc
                            mask0 = mapme <= critval_rpc
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = nc_results[scores[sc]].long_name +' following '+nc_results[scores[sc]].source+' 1 for rpc > 1, 0 for rpc <= 1'
        
                        elif scores[sc] in ('bias','relbias'):
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(np.abs(nc_results[scores[sc]].values),mode_f='mean',lat_f=yy) #get weighted spatial mean value
                            #pcolorme = nc_results[scores[sc]].stack(flat_dim=('x', 'y')).median(dim='flat_dim') #get spatial median
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            
                            label_pcolor_mean = 'areal mean absolute '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_bias)
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            #add descriptive metadata
                            if scores[sc] == 'relbias':
                                info_string = 'relative bias of the ensemble mean time series in percent of the observed mean value below '+str(critval_relbias)+', yes (1) or no (0)'
                                threshold = critval_relbias #this is a percentage threshold
                            elif scores[sc] == 'bias':
                                info_string = 'bias of the ensemble mean time series below '+str(critval_bias)+', yes (1) or no (0)'
                                threshold = critval_bias
                            else:
                                raise ValueError('Unknown entry for <scores[sc]> !')
                            
                            score_info[sc] = info_string
                            #create binary mask (skill yes/no)
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = np.abs(mapme) < threshold
                            mask0 = np.abs(mapme) >= threshold
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                        elif scores[sc] in ('reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile'):
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_reliability)
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            if scores[sc] == 'reliability_lower_tercile':
                                info_string = 'reliability for the lower tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            elif scores[sc] == 'reliability_center_tercile':
                                info_string = 'reliability for the center tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            elif scores[sc] == 'reliability_upper_tercile':
                                info_string = 'reliability for the upper tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            else:
                                raise ValueError('Unknown entry for <scores[sc]> !')
                            score_info[sc] = info_string
                            #create binary mask (skill yes/no)
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = np.abs(mapme) < threshold
                            mask0 = np.abs(mapme) >= threshold
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                        else:                    
                            raise ValueError(scores[sc]+' is currently not supported by plot_seasonal_validation_results.py !')
                        
                        ## PLOT pcolor figures, x-axis: season / month the prediction is valid for and y-axis lead-time (1 season / month)
                        #convert to xr dataArray and add metadata necessary for plotting
                        pcolorme_mean = xr.DataArray(pcolorme_mean,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_mean)
                        pcolorme_fraction = xr.DataArray(pcolorme_fraction,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_fraction)
                        pcolorme_mean.attrs['units'] = units_pcolor_mean
                        pcolorme_fraction.attrs['units'] = units_pcolor_fraction
                        pcolorme_mean.attrs['season_label'] = nc_results.season.values
                        pcolorme_fraction.attrs['season_label'] = nc_results.season.values
                        pcolorme_mean.attrs['lead_label'] = nc_results.lead.values
                        pcolorme_fraction.attrs['lead_label'] = nc_results.lead.values
                        
                        #make the pcolor plots
                        plot_pcolormesh_seasonal(pcolorme_mean,minvals_pcolor_mean.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).min().values,maxvals_pcolor_mean.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).max().values,savename_mean,colormaps_meanvals_spatial[sc],dpival)
                        plot_pcolormesh_seasonal(pcolorme_fraction,minvals_pcolor_fraction.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).min().values,maxvals_pcolor_fraction.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).max().values,savename_fraction,colormaps_fractions_spatial[sc],dpival)

                        #produce a VERIFICATION MAP for each score, season and leadtime
                        if plot_maps == 'yes':
                            ('As requested by the user, verification maps are plotted !')
                            seasons = nc_results.season.values
                            leads = nc_results.lead.values
                            if scores[sc] in ('relbias','bias') and detrending[det] == 'yes':
                                print('INFO: '+scores[sc]+' is not plotted for detrended time series since the intercept/mean is also removed by the detrending function and the bias is thus 0 by definition.')
                            else:
                                for sea in np.arange(len(seasons)):
                                    for ll in np.arange(len(leads)):
                                        if scores[sc] in ('pearson_r','spearman_r'):
                                            critval_label = str(round(critval_rho*100))
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        elif scores[sc] in ('relbias'):
                                            critval_label = str(critval_relbias)
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        elif scores[sc] in ('bias','reliability_lower_tercile','reliability_upper_tercile'):
                                            critval_label = str(critval_bias)
                                            agreeind = binmask[sea,ll,:,:] == 0 #if set to 0, no signficance layer is plotted upon the pclormesh in get_map_lowfreq_var() function
                                        elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                            critval_label = str(critval_skillscore)
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        elif scores[sc] in ('rpc'):
                                            critval_label = str(critval_rpc)
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        else:
                                            raise ValueError(scores[sc]+' is not yet supported by this function !')
                                        title = variables[mm][vv]+' '+seasons[sea]+' '+leads[ll]+' '+scores[sc]+' '+critval_label+' dtr'+detrending[det]+' '+sub_domain+' '+models[mm]+' vs '+score_ref+' '+str(file_years[mm][0])+' '+str(file_years[mm][1])
                                        savename = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps/'+scores[sc]+'/map_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+seasons[sea]+'_'+leads[ll]+'_'+scores[sc]+'_'+critval_label+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                                        cbarlabel = scores[sc]+' ('+str(nc_results[scores[sc]].units)+')'
                                        
                                        # set variables-specific limits for bias and relative bias
                                        # if scores[sc] in ('bias','relbias') and variables[mm][vv] in manual_cbar_variables:
                                        if scores[sc] in ('bias','relbias') and variables[mm][vv]:
                                            abs_max = np.max((np.abs(minvals_map.sel(variable=variables[mm][vv],score=scores[sc]).min().values),np.abs(maxvals_map.sel(variable=variables[mm][vv],score=scores[sc]).max().values)))
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                                        # elif scores[sc] == 'relbias' and variables[mm][vv] in manual_cbar_variables:
                                        #     get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,relbias_max*-1,relbias_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                                        elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,0,maxvals_map.sel(score=scores[sc]).max().values,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                        # Equal CRPS limits for all variables
                                        elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                            abs_max = np.max((np.abs(minvals_map.sel(score=scores[sc]).min().values),np.abs(maxvals_map.sel(score=scores[sc]).max().values)))# retain the maximum absolute value in the data, used to define the lower and upper limits of the colorbar in the next line
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                        # Equal limits for remaining scores and variables
                                        else:
                                            #get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map[det,sc],maxvals_map[det,sc],dpival,title,savename,halfres,colormaps[sc],titlesize,cbarlabel) #colormap limits have been inferred from the score arrays above
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map.sel(score=scores[sc]).min().values,maxvals_map.sel(score=scores[sc]).max().values,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                        elif plot_maps == 'no':
                            print('As requested by the user, no verification maps are plotted !')
                        else:
                            ValueError('Check entry for <plot_maps> !')
                        
                        #fill numpy array with binary mask
                        binary_mask[su,det,vv,sc,:,0:lead_step,:,:] = binmask                        
                    
                    #fill numpy array with continuous skill scores to be added to the above binary mask
                    for csc in np.arange(len(cont_scores)):
                        continuous_score[su,det,vv,csc,:,0:lead_step,:,:] = nc_results[cont_scores[csc]].values
                    
                    ##close input nc files and produced xr dataset
                    pcolorme_mean.close()
                    pcolorme_fraction.close()
            
        #bring the binary result masks into xarray data array format, one array per score. Then assign metadata to score / dataarray and stack them all as variables into a definite xarray dataset to be stored on netCDF
        for sc in np.arange(len(scores)):
            if scores[sc] in ('rpc','bias','relbias','pearson_r','spearman_r','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                print('INFO: saving binary validation mask for '+scores[sc])
                binary_mask_score_i = binary_mask[:,:,:,sc,:,:,:,:]
                # convert numpy array to xarray data array
                binary_mask_score_i = xr.DataArray(binary_mask_score_i,coords=[subperiods,detrending,variables_out[mm],nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['subperiod', 'detrended', 'variable', 'season', 'lead', 'y', 'x'], name=scores[sc]+'_binary')

                binary_mask_score_i.attrs['name'] = score_info[sc]
                binary_mask_score_i.attrs['units'] = score_unit[sc]
                binary_mask_score_i.attrs['info'] = score_info[sc]
                if sc == 0:
                    ds_binary_mask = binary_mask_score_i.to_dataset()
                else:
                    ds_binary_mask[scores[sc]+'_binary'] = binary_mask_score_i
                binary_mask_score_i.close()
                del(binary_mask_score_i)
                
                # #set version of the netCDF output file
                # if vers == 'as_input_file':
                    # version_label = nc_results.version
                # else:
                    # version_label = vers
                
                if nc_results.version != vers:
                    raise ValueError('Validation versions requested by the user in <vers> input variable does not match with metadata obtained from input file !')            
            else:
                print('WARNING: Validation results for '+scores[sc]+' are not yet saved to netCDF because the transition to binary format still has to be discussed with the other PTI members.')
                continue
            
        for csc in np.arange(len(cont_scores)):
            print('INFO: saving continuous validation results for '+cont_scores[csc])
            continuous_score_i = continuous_score[:,:,:,csc,:,:,:,:]
            # convert numpy array to xarray data array
            continuous_score_i = xr.DataArray(continuous_score_i,coords=[subperiods,detrending,variables_out[mm],nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['subperiod', 'detrended', 'variable', 'season', 'lead', 'y', 'x'], name=cont_scores[csc]+'_continuous')
            continuous_score_i.attrs['name'] = cont_scores[csc]
            continuous_score_i.attrs['units'] = 'continuous values'
            if csc == 0:
                ds_continuous_score = continuous_score_i.to_dataset()
            else:
                ds_continuous_score[cont_scores[csc]+'_continuous'] = continuous_score_i
            continuous_score_i.close()
            del(continuous_score_i)

        #merge binary masks and continuous verification results
        ds_mask_plus_cont = xr.merge([ds_binary_mask,ds_continuous_score])
        # add global attributes
        ds_mask_plus_cont.attrs['version'] = vers
        ds_mask_plus_cont.attrs['model'] = models[mm]
        ds_mask_plus_cont.attrs['accumulation_period'] = agg_label[ag]
        ds_mask_plus_cont.attrs['validation_period'] = str(file_years[mm]).replace('[','').replace(']','').replace(', ',' to ')+', grouped by subperiods as indicated by the <subperiod> coordinate'
        ds_mask_plus_cont.attrs['author'] = "Swen Brands (Instituto de Fisica de Cantabria, CSIC-UC), email: brandssf@ifca.unican.es"
        ds_mask_plus_cont.attrs['nan_criterion'] = 'A nan is set at a given grid-box if it is returned by xskillscore, e.g. due to a division by zero. It has been confirmed that this occcurs, e.g., if it does not rain at all either in the modelled or quasi-observed time-series.'

        # add dimension and variable attributes
        ds_mask_plus_cont['subperiod'].attrs['info'] = 'Verification subperiod: <none> for no subperiod, <enso0init> for neutral ENSO events, <enso1init> for warm / El Niño events and <enso2init> for cold / La Niña events. Condition is valid on the month the model is initialized and becomes available, which is indicated by the <init> suffix.'
        ds_mask_plus_cont['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
        ds_mask_plus_cont['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
        ds_mask_plus_cont['season'].attrs['info'] = 'Season the forecast is valid for'
        ds_mask_plus_cont['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
        ds_mask_plus_cont['y'].attrs['name'] = 'latitude'
        ds_mask_plus_cont['y'].attrs['standard_name'] = 'latitude'
        ds_mask_plus_cont['x'].attrs['name'] = 'longitude'
        ds_mask_plus_cont['x'].attrs['standard_name'] = 'longitude'

        #save the binary mask xarray dataset and close
        nc_results.close()
        savename_netcdf = dir_netcdf_out+'/skill_masks_pticlima_'+sub_domain+'_'+agg_label[ag]+'_'+models[mm]+'_'+vers+'.nc'
        ds_mask_plus_cont.to_netcdf(savename_netcdf)
        
        ds_binary_mask.close()
        ds_mask_plus_cont.close()
        del(nc_results,ds_binary_mask,ds_mask_plus_cont)
    
    print('INFO: saving results at:')
    print(savename_netcdf)

print('INFO: plot_seasonal_validation_results.py has been run successfully. A flag is written at '+dir_flag)
flagfile = dir_flag+'/plot_seasonal_valiations_results_'+str(vers)+'_'+str(models)+'_'+domain+'_'+sub_domain+'_'+str(agg_label)+'_'+str(subperiods)+'_mapping_'+plot_maps+'.flag'
flagfile = flagfile.replace("[","").replace("]","").replace("'","").replace(",","_").replace(" ","")
file = open(flagfile,'w')
file.write('plot_seasonal_validation_results.py has been run successfully for '+str(vers)+', '+str(models)+', '+str(variables)+', '+str(domain)+', '+str(sub_domain)+', '+str(agg_label)+', '+str(subperiods)+', mapping '+plot_maps)
file.close()
#print the elapsed time and close
end_time = time.time()
elapsed_time = (end_time - start_time)/60
print('The execution time of the entire script was: '+str(elapsed_time)+' minutes')

quit()
#sys.exit(0)