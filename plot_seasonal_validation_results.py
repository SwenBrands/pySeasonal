#!/usr/bin/env python

'''Plots verification results calculated before with get_skill_season.py and generates binary skill masks that are stored in netCDF format.
Author: Swen Brands, brandssf@ifca.unican.es
'''

#load packages
import math
import sys
import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import cartopy.crs as ccrs
import cartopy.feature as cf
import os
import pandas as pd
import xskillscore as xs
from math import radians, cos, sin, asin, sqrt #needed to calculate haversine distance
import pdb as pdb #then type <pdb.set_trace()> at a given line in the code below

#set input parameters
model = ['cmcc35','ecmwf51'] # ['cmcc35','ecmwf51'] list of model or reanalysis datasets: era5 or era5_land
corr_outlier = 'no' #load the outlier-correted validation results; yes or no
detrending = ['no','yes'] #yes or no, linear detrending of the gcm and obs time series prior to validation
file_years = [[1993,2022],[1981,2022]] #[[1993,2022],[1981,2022]] list containing as many sub-lists as there are models to be validated; start and end years indicated in the input file name, [1982,2016] for mod2strong_Nino, [1984,2022] for mod2strong_Nina
subperiods = ['none','enso0init','enso1init','enso2init'] # a list of strings defining the modulating oscillations and their phase, constructed from the <modulator> and <phase> input arguments in get_skill_season.py; currently "none", "enso0init", "enso1init" or "enso2init"
val_vers = 'v1l' #version of the validation results
#val_vers = 'as_input_file' # 'as_input_file' searches the version stored in the input files generated before with get_skill_season.py; other entries will be directly passed to the netCDF output file produced here
agg_label = ['1mon','3mon'] #list of strings used to label to aggregation period in the output files generated by this script; the length of this list defines the number of aggregation windows
file_system = 'lustre' #lustre or myLaptop; used to create the path structure to the input and output files

# variables = ['pvpot','SPEI-3-R','SPEI-3-M','fwi','tp','ssrd','si10','t2m','msl'] #variable names in CDS format
# ref_dataset = ['era5','era5','era5','era5','era5','era5','era5','era5','era5'] # #list of model or reference observational dataset paired with <variables> input parameter below

variables = ['SPEI-3-M','tp','ssrd','si10','t2m','msl'] #variable names in CDS format
variables_binary = ['SPEI-3-M','tp','ssrd','si10','t2m','msl'] #variable names of the binary skill mask generated by this script; these are the variable names used by Predictia
ref_dataset = ['era5','era5','era5','era5','era5','era5'] # #list of model or reference observational dataset paired with <variables> input parameter below

domain = 'medcof' #the domain the verfication results have been save on by get_skill_season.py
sub_domain = 'medcof' #medcof (corresponds to no sub-domain), medcof2 or iberia; the domain the results are plotted for; if set to <medcof>, then no sub-selection will be applied and the results for the entire medcof domain will be plotted
apply_mask = 'yes' #yes or no; apply land sea-mask generated by Maialen Iturbide; if set to "yes", then the verficiation results over the sea are set to nan
critval_rho = 0.05 #critical value used to define the signficance of the correlation measuere applied here (Pearon and Spearman)
critval_skillscore = 0 #threshold value above which the skill scores applied here indicate skill (is normally set to 0). Currently the climatological mean value of the reference dataset (e.g. ERA5) is used as naiv reference forecast: Skill Score = 1 - SCORE / SCORE_clim  
critval_relbias = 5 #percentage threshold beyond which the absolute relative bias is printed with a dot in the maps and thus assumed to be "important"
critval_bias = 10*8 # this is a dummy threshold so far, replace by p-value from a t-test for bias significantly distinct from zero in future versions
critval_reliability = 0.25
critval_rpc = 1
scores = ['rpc','bias','relbias','spearman_r','pearson_r','crps_ensemble_skillscore_rand','reliability_lower_tercile','reliability_upper_tercile','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'] #skill measures to be plotted
relbias_max = 100 #magnitude of the upper and lower limit to be plotted in case of relbias and tp, this is a percentage value and it is used because the relbias can be very large in dry regions due to the near-to-zero climatological precip. there
manual_cbar_variables = ('SPEI-3-R','SPEI-3-M') #variables not participating in the colorbar adjustment made by the script due to excessive relative biases, the cbar for these variables is set to range from <relbias_max>*-1 to <relbias_max>
meanrho_max = 1.

precision = 'float32' #precision of the variable in the output netCDF files
dpival = 300 #resultion of the output figure in dpi
figformat = 'pdf' #format of the output figures: pdf, png, etc.
colormap_ascend = 'Spectral_r' #ascendig colormap used for plotting: Spectral_r 
colormap_div = 'seismic' #diverging (zero-centered) colormap used for plotting: seismic
titlesize = 6

##EXECUTE ##############################################################

#set directory tree as a function of the file system
if file_system == 'myLaptop':
    home = os.getenv('HOME')
    rundir = home+'/datos/tareas/proyectos/pticlima/pyPTIclima/pySeasonal' #script directory, you should be there or point to this directory when running these scripts via python
    auxdir = home+'/datos/tareas/proyectos/pticlima/pyPTIclima/pySolar'
    dir_netcdf = home+'/datos/tareas/proyectos/pticlima/seasonal/results/validation/'+val_vers #path to outupt netcdf files produced with this script, containing an xarray dataset with all verification results
elif file_system == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    auxdir = home+'/Inventory/Scripts/pyPTIclima/pySolar'
    dir_netcdf = home+'/Results/seasonal/validation/'+val_vers #path to outupt netcdf files produced with this script, containing an xarray dataset with all verification results
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
else:
    raise Exception('ERROR: unknown entry for <file_system> input parameter!')

#load custom functions of the pySeasonal and pySolar packages (to be merged in the future) and go to run directory
exec(open(rundir+'/functions_seasonal.py').read())
exec(open(auxdir+'/functions_radiation.py').read())
os.chdir(rundir)

print('INFO: Verfying '+str(model)+' against for '+str(variables)+' from '+str(ref_dataset)+' domain '+domain+' and sub-domain '+sub_domain+', detrending '+str(detrending)+' and outlier correction '+corr_outlier)
## check consistency of input parameters
if len(variables) != len(ref_dataset):
    raise Exception('ERROR: The two input lists <variables> and <ref_dataset> must have the same length !')

#init global minimum and maximum values
minvals_map = np.zeros((len(agg_label),len(subperiods),len(detrending),len(variables),len(model),len(scores)))
minvals_map[:] = np.nan
maxvals_map = minvals_map.copy()
minvals_pcolor_fraction = minvals_map.copy()
maxvals_pcolor_fraction = minvals_map.copy()
minvals_pcolor_mean = minvals_map.copy()
maxvals_pcolor_mean = minvals_map.copy()

#get the lead times per aggregation period and model
    #get maximum lead from files obtained with get_skill_season.py
lead_arr = np.zeros((len(agg_label),len(model)))
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/'+agg_label[ag]+'/scores' #set path to the directory containing the validation results
    for mm in range(len(model)):
        if model[mm] in ('ecmwf51','cmcc35'):
            filename_input = 'validation_results_season_'+variables[0]+'_'+agg_label[ag]+'_'+model[mm]+'_vs_'+ref_dataset[0]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[0]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[0]+'_'+val_vers+'.nc'
        else:
            raise Exception('ERROR: unknown entry for <model[mm]> !')
        nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input) #load the input dataset
        lead_arr[ag,mm] = len(nc_results.lead.values)
        nc_results.close()
lead_arr = xr.DataArray(lead_arr,coords=[agg_label,model],dims=['aggregation','model'], name='lead-time')

#get minimium and maximum values of the colormaps for 1) maps, 2) pcolors displaying areal fractions in percent and 3) pcolors displaying areal mean values
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/'+agg_label[ag]+'/scores' #set path to the directory containing the validation results

    for mm in range(len(model)):
        for su in np.arange(len(subperiods)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables)):
                    colormaps_fractions_spatial = [] #one colormap per score
                    colormaps_meanvals_spatial = []
                    #load netcdf files containing the verification results
                    filename_input = 'validation_results_season_'+variables[vv]+'_'+agg_label[ag]+'_'+model[mm]+'_vs_'+ref_dataset[vv]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.nc'
                    nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input) #load the input dataset
                    
                    #optionally apply land sea mask; set values of sea to nan
                    if apply_mask == 'yes':
                        print('Upon user request, values for sea grid-boxes are set to nan !')                
                        #get mask label as a function of the requested sub-domain
                        if sub_domain in ('medcof','medcof2'):
                            masklabel = 'Medcof'
                        elif sub_domain == 'iberia':
                            masklabel = sub_domain[0].upper()+sub_domain[1:]
                        else:
                            raise Excpetion('ERROR: Xheck entry for <sub_domain> input variable !')                
                        mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                        nc_mask = xr.open_dataset(mask_file)
                        mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                        nc_results = nc_results.where(mask_appended == 1, np.nan) #retain grid-boxes marked with 1 in mask
                        #nc_results = nc_results.where(nc_mask.mask.values == 1, nc_results, np.nan) #retain grid-boxes marked with 1 in mask
                        nc_mask.close()
                        del(nc_mask)
                    elif apply_mask == 'no':
                        print('As requested by the user, the verification results are not filtered by a land-sea mask !')
                    else:
                        raise Exception('ERROR ! Check entry for <apply_mask> input parameter !')
                        
                    #optionally cut out sub domain
                    if sub_domain in ('iberia','medcof2'):
                        nc_results = get_sub_domain(nc_results,sub_domain) #select sub-domain to be verified
                    elif sub_domain == 'medcof': #if set to <medcof>, then no sub-domain is chosen
                        print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
                    else:
                        raise Exception('ERROR: unknown entry for <sub_domain> input parameter !')
                    
                    #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
                    if det == 0 and vv == 0 and mm == 0:
                        #get meshes for obtaining the areal average or areal percentage of significant hindcast correlation coefficient 
                        xx,yy = np.meshgrid(nc_results.x.values,nc_results.y.values)
                
                    #extract the min and max values for each score, <map> prefix points to values used for mapping at the grid-box scale and <pcolor> points to the values used in the pcolor figure
                    for sc in np.arange(len(scores)):
                        if scores[sc] in ('bias','relbias'):
                            if scores[sc] == 'relbias' and variables[vv] in manual_cbar_variables:
                                print('INFO: for '+variables[vv]+' and '+scores[sc]+', no min and max values are stored because they can be very large in dry regions due to the near-to-zero climatolologial precipitation.')
                            else:
                                maxvals_map[ag,su,det,vv,mm,sc] = np.abs(nc_results[scores[sc]]).max().values
                                minvals_map[ag,su,det,vv,mm,sc] = np.abs(nc_results[scores[sc]]).max().values*-1
                                meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                                fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()*-1
                                maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                                minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                        elif scores[sc] in ('mae','mape','rmse','crps_ensemble'):
                            maxvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].max().values
                            minvals_map[ag,su,det,vv,mm,sc] = 0
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                        elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                            maxvals_map[ag,su,det,vv,mm,sc] = 0.5 #global maximum for the specific model dataset and variable, suggested by Jose Manuel Gutiérrez
                            minvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].min().values #global minimum for the specific model dataset and variable
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.min()
                            #minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                        elif scores[sc] in ('rpc','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy)
                            if scores[sc] == 'rpc':
                                maxvals_map[ag,su,det,vv,mm,sc] = 2
                                minvals_map[ag,su,det,vv,mm,sc] = 0
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 2
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            else:
                                maxvals_map[ag,su,det,vv,mm,sc] = 1
                                minvals_map[ag,su,det,vv,mm,sc] = -1
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()*-1
                            
                            #pcolor colorbar limits for rpc and others are equal
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                        elif scores[sc] in ('pearson_r','spearman_r'):
                            if scores[sc] in ('pearson_r'):
                                score_pval = 'pearson_pval'
                            elif scores[sc] in ('spearman_r'):
                                score_pval = 'spearman_pval'
                            else:
                                raise Exception('ERROR: check entry in <scores[sc]> !')
                            maxvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].max().values
                            minvals_map[ag,su,det,vv,mm,sc] = 0
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rho,pval_f=nc_results[score_pval].values,mode_f='fraction_smaller_pos',lat_f=yy)
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                            del(score_pval)
                        else:
                            raise Exception('ERROR: unknown value for <scores[sc]> !')
                    ##close file
                    nc_results.close()
                    del(nc_results)
        
#get minimum and maximum colorbar colours

minvals_pcolor_fraction = xr.DataArray(minvals_pcolor_fraction,coords=[agg_label,subperiods,detrending,variables,model,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_pcolor_fraction = xr.DataArray(maxvals_pcolor_fraction,coords=[agg_label,subperiods,detrending,variables,model,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

minvals_pcolor_mean = xr.DataArray(minvals_pcolor_mean,coords=[agg_label,subperiods,detrending,variables,model,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_pcolor_mean = xr.DataArray(maxvals_pcolor_mean,coords=[agg_label,subperiods,detrending,variables,model,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

minvals_map = xr.DataArray(minvals_map,coords=[agg_label,subperiods,detrending,variables,model,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_map = xr.DataArray(maxvals_map,coords=[agg_label,subperiods,detrending,variables,model,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

#then plot the results with this min and max values
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/'+agg_label[ag]+'/scores' #set path to the directory containing the validation results
    for mm in range(len(model)):
        dir_figs = dir_netcdf+'/'+agg_label[ag]+'/'+sub_domain+'/'+model[mm]+'/'+str(file_years[mm][0])+'_'+str(file_years[mm][1]) #path to output figures file generated by this script
        for su in np.arange(len(subperiods)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables)):
                    #create output directories if they do not exist.
                    if os.path.isdir(dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/maps') != True:
                        os.makedirs(dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/maps')
                    
                    #load netcdf files containing the verification results
                    filename_input = 'validation_results_season_'+variables[vv]+'_'+agg_label[ag]+'_'+model[mm]+'_vs_'+ref_dataset[vv]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.nc'
                    nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input)
                    lead_step = len(nc_results.lead.values) #length of the "lead" dimension

                    #optionally apply land sea mask; set values of sea to nan
                    if apply_mask == 'yes':
                        print('Upon user request, values for sea grid-boxes are set to nan !')                
                        #get mask label as a function of the requested sub-domain
                        if sub_domain in ('medcof','medcof2'):
                            masklabel = 'Medcof'
                        elif sub_domain == 'iberia':
                            masklabel = sub_domain[0].upper()+sub_domain[1:]
                        else:
                            raise Excpetion('ERROR: Xheck entry for <sub_domain> input variable !')                
                        mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                        nc_mask = xr.open_dataset(mask_file)
                        mask_appended = np.tile(nc_mask.mask.values,(len(nc_results.season),len(nc_results.lead),1,1))
                        nc_results = nc_results.where(mask_appended == 1) #retain grid-boxes marked with 1 in mask
                        #nc_results = nc_results.where(nc_mask.mask.values == 1, nc_results, np.nan) #retain grid-boxes marked with 1 in mask
                        nc_mask.close()
                        del(nc_mask)
                    elif apply_mask == 'no':
                        print('As requested by the user, the verification results are not filtered by a land-sea mask !')
                    else:
                        raise Exception('ERROR ! Check entry for <apply_mask> input parameter !')
                    
                    #optionally cut out sub domain
                    if sub_domain in ('iberia','medcof2'):
                        nc_results = get_sub_domain(nc_results,sub_domain)
                    elif sub_domain == 'medcof': #no sub-domain is chosen
                        print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
                    else:
                        raise Exception('ERROR: unknown entry for <sub_domain> input parameter !')
                    
                    #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
                    if su == 0 and det == 0 and vv == 0 and mm == 0:
                        #get meshes for plotting the maps and init the output binary mask; halfres is used for plotting maps below
                        y_coord = nc_results.y.values
                        x_coord = nc_results.x.values
                        xx,yy = np.meshgrid(x_coord,y_coord)
                        #binary_mask = np.zeros((len(subperiods),len(detrending),len(variables),len(model),len(scores),len(nc_results.season),len(nc_results.lead),len(y_coord),len(x_coord)),dtype='single')
                        binary_mask = np.zeros((len(subperiods),len(detrending),len(variables),len(model),len(scores),len(nc_results.season),int(lead_arr.sel(aggregation=agg_label[ag]).max().values),len(y_coord),len(x_coord)),dtype='single')
                        binary_mask[:] = np.nan
                        halfres = np.abs(np.diff(nc_results.x.values))[0]/2 #needed to plot the pcolormesh

                    ##Get arrays to be shown as pcolor figures and maps (assigned as <pcolorme> and <mapme> respectively. In addition, retrieve a binary skill / no skill (1 / 0) named <binmask> below
                    score_unit = np.zeros((len(scores))).tolist()
                    score_info = score_unit.copy()
                    for sc in np.arange(len(scores)):
                        print('INFO: plotting '+scores[sc]+'...')
                        score_ref = nc_results.reference_observations
                        if os.path.isdir(dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/maps/'+scores[sc]) != True:
                            os.makedirs(dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/maps/'+scores[sc])
                        if scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                            #pcolor for areal average of skill score values
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy) #calculate spatial mean crps skill score
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy) #calculate areal fraction with skill score > 0
                            units_pcolor_mean = 'skill score'
                            units_pcolor_fraction = '%'
                            label_pcolor_mean = 'areal mean '+scores[sc]
                            label_pcolor_fraction = 'areal fraction > '+str(critval_skillscore)+' '+scores[sc]                   
                            mapme = nc_results[scores[sc]].values
                            
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = mapme > 0
                            mask0 = mapme <= 0
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = 'Continuous Rank Probabililty Score with reference to climatological forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0); the shape of the continuous variable distribution is taken from the ensemble members'
                        elif scores[sc] in ('pearson_r','spearman_r'):
                            if scores[sc] in ('pearson_r'):
                                score_pval = 'pearson_pval'
                            elif scores[sc] in ('spearman_r'):
                                score_pval = 'spearman_pval'
                            else:
                                raise Exception('ERROR: check entry in <scores[sc]> !')
                            #areal percentage of significant grid-box scale correlation coefficients is calculated and plotted
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            pval = nc_results[score_pval].values
                            rho = nc_results[scores[sc]].values
                            pcolorme_fraction = get_spatial_aggregation(rho.copy(),critval_rho,pval_f=pval.copy(),mode_f='fraction_smaller_pos',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                            pcolorme_mean = get_spatial_aggregation(rho.copy(),mode_f='mean',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                            mapme = rho
                            units_pcolor_mean = scores[sc]
                            units_pcolor_fraction = '%'
                            label_pcolor_fraction = 'areal fraction of sig. positive '+scores[sc]
                            label_pcolor_mean = 'areal mean '+scores[sc]
                            
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = (pval < critval_rho) & (rho > 0)
                            mask0 = (pval >= critval_rho) | (rho <= 0)
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = 'significant '+scores[sc]+' at '+str(round(critval_rho*100))+' percent test-level and positive sign for the ensemble mean time series, yes (1) or no (0)'
                        
                        elif scores[sc] == 'rpc':
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction whith '+nc_results[scores[sc]].name+' < 1'
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'                    
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = mapme > critval_rpc
                            mask0 = mapme <= critval_rpc
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = nc_results[scores[sc]].long_name +' following '+nc_results[scores[sc]].source+' 1 for rpc > 1, 0 for rpc <= 1'
        
                        elif scores[sc] in ('bias','relbias'):
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(np.abs(nc_results[scores[sc]].values),mode_f='mean',lat_f=yy) #get weighted spatial mean value
                            #pcolorme = nc_results[scores[sc]].stack(flat_dim=('x', 'y')).median(dim='flat_dim') #get spatial median
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            
                            label_pcolor_mean = 'areal mean absolute '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_bias)
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            #add descriptive metadata
                            if scores[sc] == 'relbias':
                                info_string = 'relative bias of the ensemble mean time series in percent of the observed mean value below '+str(critval_relbias)+', yes (1) or no (0)'
                                threshold = critval_relbias #this is a percentage threshold
                            elif scores[sc] == 'bias':
                                info_string = 'bias of the ensemble mean time series below '+str(critval_bias)+', yes (1) or no (0)'
                                threshold = critval_bias
                            else:
                                raise Exception('ERROR: unknown entry for <scores[sc]> !')
                            score_info[sc] = info_string
                            #create binary mask (skill yes/no)
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = np.abs(mapme) < threshold
                            mask0 = np.abs(mapme) >= threshold
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                        elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealmean_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/pcolor_arealfraction_'+variables[vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_reliability)
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            if scores[sc] == 'reliability_lower_tercile':
                                info_string = 'reliability for the lower tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            elif scores[sc] == 'reliability_upper_tercile':
                                info_string = 'reliability for the upper tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            else:
                                raise Exception('ERROR: unknown entry for <scores[sc]> !')
                            score_info[sc] = info_string
                            #create binary mask (skill yes/no)
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = np.abs(mapme) < threshold
                            mask0 = np.abs(mapme) >= threshold
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                        else:                    
                            raise Exception('ERROR: '+scores[sc]+' are currently not supported by plot_seasonal_validation_results.py !')
                        
                        ## PLOT pcolor figures, x-axis: season / month the prediction is valid for and y-axis lead-time (1 season / month)
                        #convert to xr dataArray and add metadata necessary for plotting
                        pcolorme_mean = xr.DataArray(pcolorme_mean,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_mean)
                        pcolorme_fraction = xr.DataArray(pcolorme_fraction,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_fraction)
                        pcolorme_mean.attrs['units'] = units_pcolor_mean
                        pcolorme_fraction.attrs['units'] = units_pcolor_fraction
                        pcolorme_mean.attrs['season_label'] = nc_results.season.values
                        pcolorme_fraction.attrs['season_label'] = nc_results.season.values
                        pcolorme_mean.attrs['lead_label'] = nc_results.lead.values
                        pcolorme_fraction.attrs['lead_label'] = nc_results.lead.values
                        
                        #make the pcolor plots
                        plot_pcolormesh_seasonal(pcolorme_mean,minvals_pcolor_mean.sel(aggregation=agg_label[ag],variable=variables[vv],score=scores[sc]).min().values,maxvals_pcolor_mean.sel(aggregation=agg_label[ag],variable=variables[vv],score=scores[sc]).max().values,savename_mean,colormaps_meanvals_spatial[sc],dpival)
                        plot_pcolormesh_seasonal(pcolorme_fraction,minvals_pcolor_fraction.sel(aggregation=agg_label[ag],variable=variables[vv],score=scores[sc]).min().values,maxvals_pcolor_fraction.sel(aggregation=agg_label[ag],variable=variables[vv],score=scores[sc]).max().values,savename_fraction,colormaps_fractions_spatial[sc],dpival)

                        #produce a VERIFICATION MAP for each score, season and leadtime
                        seasons = nc_results.season.values
                        leads = nc_results.lead.values
                        if scores[sc] in ('relbias','bias') and detrending[det] == 'yes':
                            print('INFO: '+scores[sc]+' is not plotted for detrended time series since the intercept/mean is also removed by the detrending function and the bias is thus 0 by definition.')
                        else:
                            for sea in np.arange(len(seasons)):
                                for ll in np.arange(len(leads)):
                                    if scores[sc] in ('pearson_r','spearman_r'):
                                        critval_label = str(round(critval_rho*100))
                                        agreeind = binmask[sea,ll,:,:] == 1
                                    elif scores[sc] in ('relbias'):
                                        critval_label = str(critval_relbias)
                                        agreeind = binmask[sea,ll,:,:] == 1
                                    elif scores[sc] in ('bias','reliability_lower_tercile','reliability_upper_tercile'):
                                        critval_label = str(critval_bias)
                                        agreeind = binmask[sea,ll,:,:] == 0 #if set to 0, no signficance layer is plotted upon the pclormesh in get_map_lowfreq_var() function
                                    elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                        critval_label = str(critval_skillscore)
                                        agreeind = binmask[sea,ll,:,:] == 1
                                    elif scores[sc] in ('rpc'):
                                        critval_label = str(critval_rpc)
                                        agreeind = binmask[sea,ll,:,:] == 1
                                    else:
                                        raise Exception('ERROR: '+scores[sc]+' is not yet supported by this function !')
                                    title = variables[vv]+' '+seasons[sea]+' '+leads[ll]+' '+scores[sc]+' '+critval_label+' dtr'+detrending[det]+' '+sub_domain+' '+model[mm]+' vs '+score_ref+' '+str(file_years[mm][0])+' '+str(file_years[mm][1])
                                    savename = dir_figs+'/'+subperiods[su]+'/'+variables[vv]+'/maps/'+scores[sc]+'/map_'+variables[vv]+'_'+agg_label[ag]+'_'+seasons[sea]+'_'+leads[ll]+'_'+scores[sc]+'_'+critval_label+'_'+sub_domain+'_'+model[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.'+figformat
                                    cbarlabel = scores[sc]+' ('+str(nc_results[scores[sc]].units)+')'
                                    
                                    # set variables-specific limits for bias and relative bias
                                    # if scores[sc] in ('bias','relbias') and variables[vv] in manual_cbar_variables:
                                    if scores[sc] in ('bias','relbias') and variables[vv]:
                                        abs_max = np.max((np.abs(minvals_map.sel(variable=variables[vv],score=scores[sc]).min().values),np.abs(maxvals_map.sel(variable=variables[vv],score=scores[sc]).max().values)))
                                        get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                                    # elif scores[sc] == 'relbias' and variables[vv] in manual_cbar_variables:
                                    #     get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,relbias_max*-1,relbias_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                                    elif scores[sc] in ('reliability_lower_tercile','reliability_upper_tercile'):
                                        get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,0,maxvals_map.sel(score=scores[sc]).max().values,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                    # Equal CRPS limits for all variables
                                    elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                        abs_max = np.max((np.abs(minvals_map.sel(score=scores[sc]).min().values),np.abs(maxvals_map.sel(score=scores[sc]).max().values)))# retain the maximum absolute value in the data, used to define the lower and upper limits of the colorbar in the next line
                                        get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                    # Equal limits for remaining scores and variables
                                    else:
                                        #get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map[det,sc],maxvals_map[det,sc],dpival,title,savename,halfres,colormaps[sc],titlesize,cbarlabel) #colormap limits have been inferred from the score arrays above
                                        get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map.sel(score=scores[sc]).min().values,maxvals_map.sel(score=scores[sc]).max().values,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                        
                        #save a binary mask (significance or skill yes or no) in netcdf format
                        binary_mask[su,det,vv,mm,sc,:,0:lead_step,:,:] = binmask
                        #binary_mask[su,det,vv,mm,sc,:,:,:,:] = binmask
                    ##close input nc files and produced xr dataset
                    pcolorme_mean.close()
                    pcolorme_fraction.close()
            
    #bring the binary result masks into xarray data array format, one array per score. Then assign metadata to score / dataarray and stack them all as variables into a definite xarray dataset to be stored on netCDF
    for sc in np.arange(len(scores)):
        if scores[sc] in ('rpc','bias','relbias','pearson_r','spearman_r','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
            print('INFO: saving validation results for '+scores[sc])
            binary_mask_score_i = binary_mask[:,:,:,:,sc,:,:,:,:]
            # binary_mask_score_i = xr.DataArray(binary_mask_score_i,coords=[subperiods,detrending,variables,model,nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['subperiod','detrended','variable', 'model', 'season', 'lead', 'y', 'x'], name=scores[sc]+'_binary')
            binary_mask_score_i = xr.DataArray(binary_mask_score_i,coords=[subperiods,detrending,variables_binary,model,nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['subperiod','detrended','variable', 'model', 'season', 'lead', 'y', 'x'], name=scores[sc]+'_binary')
            binary_mask_score_i['subperiod'].attrs['info'] = 'Verification subperiod: <none> for no subperiod, <enso0init> for neutral ENSO events, <enso1init> for warm / El Niño events and <enso2init> for cold / La Niña events. Condition is valid on the month the model is initialized and becomes available, which is indicated by the <init> suffix.'
            binary_mask_score_i['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
            binary_mask_score_i['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
            binary_mask_score_i['model'].attrs['info'] = 'Name and version of the model / prediction system'
            binary_mask_score_i['season'].attrs['info'] = 'Season the forecast is valid for'
            binary_mask_score_i['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
            binary_mask_score_i['y'].attrs['name'] = 'latitude'
            binary_mask_score_i['y'].attrs['standard_name'] = 'latitude'
            binary_mask_score_i['x'].attrs['name'] = 'longitude'
            binary_mask_score_i['x'].attrs['standard_name'] = 'longitude'
            binary_mask_score_i.attrs['info'] = score_info[sc]
            binary_mask_score_i.attrs['unit'] = score_unit[sc]
            binary_mask_score_i.attrs['unit'] = score_unit[sc]
            if sc == 0:
                ds_binary_mask = binary_mask_score_i.to_dataset()
            else:
                ds_binary_mask[scores[sc]+'_binary'] = binary_mask_score_i
            binary_mask_score_i.close()
            del(binary_mask_score_i)
            ds_binary_mask.attrs['author'] = "Swen Brands (CSIC-UC, Instituto de Fisica de Cantabria), brandssf@ifca.unican.es or swen.brands@gmail.com"
            ds_binary_mask.attrs['validation_period'] = str(file_years[mm][0])+' to '+str(file_years[mm][1])
            ds_binary_mask.attrs['accumulation_period'] = agg_label[ag]
            
            # #set version of the netCDF output file
            # if val_vers == 'as_input_file':
                # version_label = nc_results.version
            # else:
                # version_label = val_vers
            
            if nc_results.version != val_vers:
                raise Exception('ERROR: validation versions requested by the user in <val_vers> input variable does not match with metadata obtained from input file !')
            
            ds_binary_mask.attrs['version'] = val_vers
            ds_binary_mask.attrs['nan_criterion'] = 'A nan is set at a given grid-box if it is returned by xskillscore, e.g. due to a division by zero. It has been confirmed that this occcurs, e.g., if it does not rain at all either in the modelled or quasi-observed time-series.'
        else:
            print('WARNING: Validation results for '+scores[sc]+' are not yet saved to netCDF because the transition to binary format still has to be discussed with the other PTI members.')
            continue

    #save the binary mask xarray dataset and close
    nc_results.close()
    #savename_netcdf = dir_netcdf+'/binary_validation_results_pticlima_'+domain+'_'+agg_label[ag]+'_'+sub_domain+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+val_vers+'.nc'
    savename_netcdf = dir_netcdf_scores+'/binary_validation_results_pticlima_'+sub_domain+'_'+agg_label[ag]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+val_vers+'.nc'
    ds_binary_mask.to_netcdf(savename_netcdf)
    ds_binary_mask.close()
    print('INFO: plot_seasonal_validation_results.py has been run successfully and results have been stores in netCDF format at:')
    print(savename_netcdf)
