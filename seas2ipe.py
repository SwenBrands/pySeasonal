#!/usr/bin/env python
''' This scipts loads the tercile probabilities for a single model and forecast previously obtained with pred2tercile_operational.py, transforms them into categorical values (1,2,3) indicating the most probable tercile, adds its probability as well as a skill mask; these 3 data variables per variable are saved into a new netCDF file.'''

#load packages
from datetime import date
import numpy as np
import xarray as xr
import os
import pandas as pd
import dask
import sys
import pdb
exec(open('functions_seasonal.py').read()) #reads the <functions_seasonal.py> script containing a set of custom functions needed here

#the init of the forecast (year and month) can passed by bash; if nothing is passed these parameters will be set by python
if len(sys.argv) > 1:
    print("Reading from input parameters passed via bash")
    year_init = sys.argv[1]
    month_init = sys.argv[2]
    if len(year_init) != 4 or len(month_init) != 2:
        raise Exception('ERROR: check length of <year_month_init> input parameter !')
else:
    print("No input parameter have been provided by the user and the script will set the <year_init> and <month_init> variables for the year and month of the current date...")
    year_init = str(date.today().year)
    month_init = f"{date.today().month:02d}"
    print(date.today())
print(year_init, month_init)

year_init = 2024 #a list containing the years the forecast are initialized on, will be looped through with yy
month_init = 6 #a list containing the corresponding months the forecast are initialized on, will be called while looping through <year_init> (with yy), i.e. must have the same length

#set input parameters
vers = 'v1o' #version number of the validation results
model = ['ecmwf'] # ['cmcc','ecmwf'] list containing the acronyms of the models to be assessed
version = ['51'] # ['35','51'] list containgin the versions of these models
obs = 'era5' #string containing the observational reference
years_quantile = [[1993,2022],[1993,2022]] #years used to calculate the quantiles with get_skill_season.py; list containing as many sublists as they are models
# years_validation = [1981,2022] #years the verification has been done for using get_skill_season.py
season_length = 1 #length of the season in months, e.g. 3 for DJF, JFM, etc.
subperiod = 'none' # climate oscillation assumed to modulate the verification results; currently: "enso" or "none"
score = 'pearson_r_binary' #score of the binary skill mask that will be stored by this script
agg_labels = ['3mon'] #considered aggregation windows
nan_placeholder = 1000

variables_std = ['SPEI-3-M','pvpot','fwi','t2m','tp','si10','ssrd'] # standardized variable names used inside and outside the forecast file
variables_out = ['spei3','pvpot','fwi','gtg','rti','fg','ssrd'] # name of the output variables generated by this script, as defined in PTI-Clima table located at https://docs.google.com/spreadsheets/d/1K5n3aM0vGgnJEwlghjK1BtqJr0Ug0mQYlzZKQxB2wJU/edit?gid=0#gid=0
# masked_variables_std = ['fwi','SPEI-3-M'] #list of variables on which a land-sea mask will be applied, setting values over sea to nan
masked_variables_std = ['none']

datatype = 'float32' #data type of the variables in the output netcdf files
domain = 'medcof' #spatial domain
detrended = 'no' #yes or no, linear detrending of the gcm and obs time series prior to validation
corr_outlier = 'no'
nr_mem = [25] #considered ensemble members, not yet in use !

#visualization options
figformat = 'png' #format of output figures, pdf or png
dpival = 300 #resolution of output figures
south_ext_lambert = 0 #extend the southern limit of the box containing the Lambert Conformal Projection

#set basic path structure for observations and gcms
gcm_store = 'lustre' #argo, laptop, F, extdisk2 or lustre

## EXECUTE #############################################################
quantile_threshold = [0.33,0.67]

# #check consistency of input parameters
if len(variables_std) != len(variables_out):
    ValueError('<variables_std> and <variables_out> must have the same length !')

#set path to input gcm files
if gcm_store == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    path_gcm_base = home+'/DATA/SEASONAL/seasonal-original-single-levels' # head directory of the source files
    path_gcm_base_derived = home+'/DATA/SEASONAL/seasonal-original-single-levels_derived' # head directory of the source files
    path_gcm_base_masked = home+'/DATA/SEASONAL/seasonal-original-single-levels_masked' # head directory of the source files    
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    dir_validation = home+'/Results/seasonal/validation/'+vers
    dir_forecast = home+'/Results/seasonal/forecast'
    dir_output = home+'/Products/seasonal/seas2ipe'
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
elif gcm_store == 'argo':
    home = os.getenv("DATA_DIR", "")
    path_gcm_base = home+'seasonal-original-single-levels' # head directory of the source files
    path_gcm_base_derived = home+'seasonal-original-single-levels_derived' # head directory of the source files
    path_gcm_base_masked = home+'seasonal-original-single-levels_masked' # head directory of the source files
    dir_validation = '/tmp/terciles/'
    dir_forecast = home+'seasonal-original-single-levels_derived/medcof/forecast/terciles/'
    dir_output = dir_forecast
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
else:
    raise Exception('ERROR: unknown entry for <path_gcm_base> !')
print('The GCM files will be loaded from the base directory '+path_gcm_base+'...')

#go to rundir
os.chdir(rundir)

#create output directory of the forecasts generated here, if it does not exist.
if os.path.isdir(dir_output) != True:
    os.makedirs(dir_output)

for ag in np.arange(len(agg_labels)):

    #load the skill masks for a given aggregation window; multiple variables are and models located within the same file.
    filename_validation = dir_validation+'/'+agg_labels[ag]+'/scores/binary_validation_results_pticlima_'+domain+'_'+agg_labels[ag]+'_'+vers+'.nc'
    nc_val = xr.open_dataset(filename_validation)
    
    for mm in np.arange(len(model)):
        nc_forecast = xr.Dataset() #create empty xarray dataset to be filled with xr data arrays in the next loop
        for vv in np.arange(len(variables_std)):
            #load the forecast for a specific variable
            filename_forecast = dir_forecast+'/probability_'+agg_labels[ag]+'_'+model[mm]+version[mm]+'_'+variables_std[vv]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_dtr_'+detrended+'_refyears_'+str(years_quantile[mm][0])+'_'+str(years_quantile[mm][1])+'_'+vers+'.nc'
            nc_forecast_step = xr.open_dataset(filename_forecast) #get the xr data array containing the tercile probabilities for a specific variable
            
            #check whether the previously stored model and version thereof match those requested by this script
            if nc_forecast_step.model == model[mm]+version[mm]:
                print('The requested model '+model[mm]+' and its version '+version[mm]+' coincide with the entry previously stored in '+filename_forecast+' !')
            else:
                raise ValueError('The requested model '+model[mm]+' and its version '+version[mm]+' do NOT coincide with the entry previously stored in '+filename_forecast+' !')
                
            tercile_attrs = nc_forecast_step.tercile.attrs
            
            nc_forecast_step_prob = nc_forecast_step['probability'].sel(aggregation=agg_labels[ag],model=model[mm]+version[mm]).drop_vars(['aggregation','model'])
            
            # # #replace nan data wit <nan_placeholder>
            # tercile_index = nc_forecast_step_prob.dims.index('tercile') #get index of the tercile dimension
            
            # valid_data_bool = ~np.isnan(nc_forecast_step_prob)
            # pdb.set_trace()
            # nc_forecast_step_prob = nc_forecast_step_prob.where(valid_data_bool, other=nan_placeholder)

            # ## these two lines work since they modfiy only those array entries that are nan along the entire tercile dimension
            # mask = np.all(np.isnan(nc_forecast_step_prob), axis=tercile_index)
            # nc_forecast_step_prob = nc_forecast_step_prob.where(~mask, other=nan_placeholder)

            #get maximum probability and tercile position thereof (1,2,3)
            nc_forecast_step_maxprob= nc_forecast_step_prob.max(dim='tercile').astype(datatype)
            nc_forecast_step_argmax = nc_forecast_step_prob.notnull().argmax(dim='tercile')+1

            # #get maximum probability and tercile position thereof (1,2,3) with alternative method going down to numpy
            # nc_forecast_step_maxprob_np = np.nanmax(nc_forecast_step_prob,axis=tercile_index).astype(datatype)
            # nc_forecast_step_argmax_np = np.nanargmax(nc_forecast_step_prob,axis=tercile_index).astype(datatype)+1
            # nc_forecast_step_maxprob = xr.DataArray(nc_forecast_step_maxprob_np,coords=[nc_forecast_step_prob.rtime,nc_forecast_step_prob.season,nc_forecast_step_prob.y,nc_forecast_step_prob.x],dims=['rtime','season','y','x'], name='probability')
            # nc_forecast_step_argmax = xr.DataArray(nc_forecast_step_argmax_np,coords=[nc_forecast_step_prob.rtime,nc_forecast_step_prob.season,nc_forecast_step_prob.y,nc_forecast_step_prob.x],dims=['rtime','season','y','x'], name='probability')

            # #convert <nan_placeholder> to nan
            # nc_forecast_step_maxprob = nc_forecast_step_maxprob.where(nc_forecast_step_maxprob != nan_placeholder, other=np.nan)
            # nc_forecast_step_argmax = nc_forecast_step_argmax.where(nc_forecast_step_maxprob != nan_placeholder, other=np.nan)

            #clean
            nc_forecast_step_prob.close()
            del(nc_forecast_step_prob)

            # #optionally apply land sea mask; set values of sea to nan
            # if variables_std[vv] in masked_variables_std:
            #     print('Upon user request, values for sea grid-boxes are set to nan for '+variables_std[vv]+' ! ')                
            #     #get mask label as a function of the requested sub-domain
            #     if domain in ('medcof','medcof2'):
            #         masklabel = 'Medcof'
            #     elif domain == 'iberia':
            #         masklabel = domain[0].upper()+domain[1:]# mask name is Uppercase for iberian domain, i.e. "Iberia"
            #     else:
            #         ValueError('Check entry for <domain> input variable !')                
            #     mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'_ascending_lat.nc'
            #     nc_mask = xr.open_dataset(mask_file)                
            #     land_sea_4d = np.tile(nc_mask.mask,(len(nc_forecast_step_argmax.rtime),len(nc_forecast_step_argmax.season),1,1))
            #     nc_forecast_step_argmax = nc_forecast_step_argmax.where(land_sea_4d == 1, other=np.nan)
            #     nc_forecast_step_maxprob = nc_forecast_step_maxprob.where(land_sea_4d == 1, other=np.nan)
            #     nc_mask.close()
            #     del(nc_mask)
            # elif variables_std[vv] not in masked_variables_std:
            #     print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variables_std[vv]+' !')
            # else:
            #     ValueError('check whether <variables_std[vv]> is in <masked_variables_std> !')
            
            nc_forecast['mlt_'+variables_out[vv]] = nc_forecast_step_argmax
            nc_forecast['prob_'+variables_out[vv]] = nc_forecast_step_maxprob
            #add attributes
            nc_forecast['mlt_'+variables_out[vv]].attrs['long_name'] = 'Tercile category (1=lower, 2=middle, 3=upper) for '+variables_out[vv]
            nc_forecast['mlt_'+variables_out[vv]].attrs['units'] = '1'
            nc_forecast['prob_'+variables_out[vv]].attrs['long_name'] = 'probability_of_most_likely_tercile_for_'+variables_out[vv]
            nc_forecast['prob_'+variables_out[vv]].attrs['standard_name'] = 'probability_of_event_in_category'
            nc_forecast['prob_'+variables_out[vv]].attrs['units'] = '1'
            #clean
            nc_forecast_step_argmax.close()
            nc_forecast_step_maxprob.close()
            nc_forecast_step.close()
            del(nc_forecast_step_argmax,nc_forecast_step_maxprob,nc_forecast_step)
   
            #filter subperiod, detrending option, model and version, season, and variable from skill mask
            fc_season_length = nc_forecast.season.length_in_months

            #check whether the requested aggregation window matches the season length stored within the file
            if fc_season_length != int(agg_labels[ag][0]):
                ValueError('<fc_season_length> must equal <agg_labels[ag]> ! ')

            fc_seasons = nc_forecast.season.values
            nc_val_sub = nc_val.sel(subperiod=subperiod,detrended=detrended,model=model[mm]+version[mm],season=fc_seasons,variable=variables_std[vv])[score]
            val_leads = nc_val_sub.lead.values

            skill_mask = np.zeros((len(fc_seasons),len(nc_val.y),len(nc_val.x))) #a 3d array
            for sea in np.arange(len(fc_seasons)):
                skill_mask_step = nc_val_sub.sel(season=fc_seasons[sea],lead=val_leads[sea])
                skill_mask[sea,:,:] = skill_mask_step.values

            #bring numpy array into xarray data array format
            skill_mask = xr.DataArray(skill_mask.astype('float32'),coords=[fc_seasons,nc_val.y,nc_val.x],dims=['season','y','x'], name=variables_std[vv]+'_skill_mask')

            #cut down the forecast domain to the skill domain indicated in the <domain> input variable
            nc_forecast = nc_forecast.sel(y=skill_mask.y,x=skill_mask.x)
                        
            # apply land-sea mask to skill mask
            if variables_std[vv] in masked_variables_std:
                print('Upon user request, values for sea grid-boxes are set to nan in skill mask '+variables_std[vv]+' ! ') 
                land_sea_3d = np.squeeze(land_sea_4d)
                skill_mask = skill_mask.where(land_sea_3d == 1, other=np.nan)
            elif variables_std[vv] not in masked_variables_std:
                print('As requested by the user, the verification results are not filtered by a land-sea mask in skill mask for '+variables_std[vv]+' !')
            else:
                ValueError('check whether <variables_std[vv]> is in <masked_variables_std> !')

            # add attributes to skill mask
            skill_mask.attrs['long_name'] = 'binary_skill_mask_based_on_'+score+' for '+variables_out[vv]
            skill_mask.attrs['standard_name'] = 'binary_skill_mask'
            skill_mask.attrs['units'] = 'binary'

            # merge skill mask into the existing xarray dataset containing the most like tercile and its probability
            nc_forecast['skill_'+variables_out[vv]] = skill_mask #assign variable-specific skill mask to the newly generated xarray dataset produced by this script
            skill_mask.close()
            del(skill_mask)
        
        #add global attributes
        nc_forecast.season.attrs['standard_name'] = 'season'
        nc_forecast.season.attrs['long_name'] = 'season following the forecast initialization date specified in rtime'
        
        # save the mergerd output file
        savename = dir_output+'/seas2ipe_'+model[mm]+version[mm]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_'+str(fc_season_length)+'mon_dtr_'+detrended+'_refyears_'+str(tercile_attrs['tercile_period'][0])+'_'+str(tercile_attrs['tercile_period'][1])+'.nc'
        
        ## optionally encode the output netcdf file
        # chunks = (1, 1, 1, 1, len(nc_forecast.y), len(nc_forecast.y))
        # encoding = dict(tp=dict(chunksizes=chunks)) #https://docs.xarray.dev/en/stable/user-guide/io.html#writing-encoded-data
        # nc_forecast.to_netcdf(savename,encoding=encoding)
        
        nc_forecast.to_netcdf(savename)

        #clean up
        nc_val_sub.close()
        nc_forecast.close()
        # del(nc_forecast)

    #clean up
    nc_val.close()
    del(nc_val)

print('INFO: seas2ipe.py has been run successfully ! The netcdf output file has been stored at '+savename)
quit()
