#!/usr/bin/env python
''' This scipts loads the tercile probabilities for a single model and forecast previously obtained with pred2tercile_operational.py, transforms them into categorical values (1,2,3) indicating the most probable tercile, adds its probability as well as a skill mask; these 3 data variables per variable are saved into a new netCDF file.'''

#load packages
from datetime import date
import numpy as np
import xarray as xr
import os
import pandas as pd
import dask
import sys
import pdb
exec(open('functions_seasonal.py').read()) #reads the <functions_seasonal.py> script containing a set of custom functions needed here

#the init of the forecast (year and month) can passed by bash; if nothing is passed these parameters will be set by python
if len(sys.argv) > 1:
    print("Reading from input parameters passed via bash")
    year_init = sys.argv[1]
    month_init = sys.argv[2]
    if len(year_init) != 4 or len(month_init) != 2:
        raise Exception('ERROR: check length of <year_month_init> input parameter !')
else:
    print("No input parameter have been provided by the user and the script will set the <year_init> and <month_init> variables for the year and month of the current date...")
    year_init = str(date.today().year)
    month_init = f"{date.today().month:02d}"
    print(date.today())
print(year_init, month_init)

year_init = 2024 #a list containing the years the forecast are initialized on, will be looped through with yy
month_init = 6 #a list containing the corresponding months the forecast are initialized on, will be called while looping through <year_init> (with yy), i.e. must have the same length

#set input parameters
vers = 'v1n' #version number of the validation results
model = ['ecmwf'] # ['cmcc','ecmwf'] list containing the acronyms of the models to be assessed
version = ['51'] # ['35','51'] list containgin the versions of these models
obs = 'era5' #string containing the observational reference
years_quantile = [[1993,2022],[1993,2022]] #years used to calculate the quantiles with get_skill_season.py; list containing as many sublists as they are models
# years_validation = [1981,2022] #years the verification has been done for using get_skill_season.py
season_length = 1 #length of the season in months, e.g. 3 for DJF, JFM, etc.
subperiod = 'none' # climate oscillation assumed to modulate the verification results; currently: "enso" or "none"
score = 'pearson_r_binary' #score of the binary skill mask that will be stored by this script
agg_labels = ['3mon'] #considered aggregation windows

variables_std = ['pvpot','SPEI-3-M','fwi','t2m','tp','si10','ssrd'] # standardized variable names used inside and outside the forecast file
variables_out = ['pvpot','spei3','fwi','gtg','rti','fg','ssrd'] # name of the output variables generated by this script, as defined in PTI-Clima table located at https://docs.google.com/spreadsheets/d/1K5n3aM0vGgnJEwlghjK1BtqJr0Ug0mQYlzZKQxB2wJU/edit?gid=0#gid=0
masked_variables_std = ['fwi','SPEI-3-M'] #list of variables on which a land-sea mask will be applied, setting values over sea to nan

datatype = 'float32' #data type of the variables in the output netcdf files
domain = 'medcof' #spatial domain
detrended = 'no' #yes or no, linear detrending of the gcm and obs time series prior to validation
corr_outlier = 'no'
nr_mem = [25] #considered ensemble members, not yet in use !

#visualization options
figformat = 'png' #format of output figures, pdf or png
dpival = 300 #resolution of output figures
south_ext_lambert = 0 #extend the southern limit of the box containing the Lambert Conformal Projection

#set basic path structure for observations and gcms
gcm_store = 'lustre' #argo, laptop, F, extdisk2 or lustre

## EXECUTE #############################################################
quantile_threshold = [0.33,0.67]

# #check consistency of input parameters
if len(variables_std) != len(variables_out):
    ValueError('<variables_std> and <variables_out> must have the same length !')

#set path to input gcm files
if gcm_store == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    path_gcm_base = home+'/DATA/SEASONAL/seasonal-original-single-levels' # head directory of the source files
    path_gcm_base_derived = home+'/DATA/SEASONAL/seasonal-original-single-levels_derived' # head directory of the source files
    path_gcm_base_masked = home+'/DATA/SEASONAL/seasonal-original-single-levels_masked' # head directory of the source files    
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    dir_validation = home+'/Results/seasonal/validation/'+vers
    dir_forecast = home+'/Results/seasonal/forecast'
    dir_output = home+'/Products/seasonal/seas2ipe'
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
elif gcm_store == 'argo':
    home = os.getenv("DATA_DIR", "")
    path_gcm_base = home+'seasonal-original-single-levels' # head directory of the source files
    path_gcm_base_derived = home+'seasonal-original-single-levels_derived' # head directory of the source files
    path_gcm_base_masked = home+'seasonal-original-single-levels_masked' # head directory of the source files
    dir_validation = '/tmp/terciles/'
    dir_forecast = home+'seasonal-original-single-levels_derived/medcof/forecast/terciles/'
    dir_output = dir_forecast
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
else:
    raise Exception('ERROR: unknown entry for <path_gcm_base> !')
print('The GCM files will be loaded from the base directory '+path_gcm_base+'...')

#go to rundir
os.chdir(rundir)

#create output directory of the forecasts generated here, if it does not exist.
if os.path.isdir(dir_output) != True:
    os.makedirs(dir_output)

for ag in np.arange(len(agg_labels)):

    #load the skill masks for a given aggregation window; multiple variables are and models located within the same file.
    filename_validation = dir_validation+'/'+agg_labels[ag]+'/scores/binary_validation_results_pticlima_'+domain+'_'+agg_labels[ag]+'_'+vers+'.nc'
    nc_val = xr.open_dataset(filename_validation)
    
    for mm in np.arange(len(model)):

        #merge the single-variable files into a single one
        nc_forecast = xr.Dataset() #create empty xarray dataset to be filled with xr data arrays in the next loop
        for vv in np.arange(len(variables_std)):
            #load the forecast for a specific variable
            filename_forecast = dir_forecast+'/probability_'+agg_labels[ag]+'_'+model[mm]+version[mm]+'_'+variables_std[vv]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_dtr_'+detrended+'_refyears_'+str(years_quantile[mm][0])+'_'+str(years_quantile[mm][1])+'_'+vers+'.nc'
            nc_forecast_step = xr.open_dataset(filename_forecast) #get the xr data array containing the tercile probabilities for a specific variable
            tercile_attrs = nc_forecast_step.tercile.attrs
            nc_forecast_step_argmax = nc_forecast_step['probability'].argmax(dim='tercile').astype(datatype)+1 

            # valid_data_bool = nc_forecast_step['probability'].notnull() #filter out non-nan data; argmax() does not work for variabels which are nan along the entire length of a coordinate dimension
            valid_data_bool = ~np.isnan(nc_forecast_step['probability'])
            # nan_data_bool = np.isnan(nc_forecast_step['probability'])
            masked_data = nc_forecast_step['probability'].where(valid_data_bool, other=-1e20) #replace nan indices with largely negative values to get argmax() working; then apply argmax() in the next line
            masked_data_argmax = masked_data.argmax(dim='tercile').astype(datatype)+1 #fills the most likely tercile for this variables into the newly created xr dataset, 1,2,3 for lower, middle and upper tercile
            pdb.set_trace()
            
            #optionally apply land sea mask; set values of sea to nan
            if variables_std[vv] in masked_variables_std:
                print('Upon user request, values for sea grid-boxes are set to nan for '+variables_std[vv]+' ! ')                
                #get mask label as a function of the requested sub-domain
                if domain in ('medcof','medcof2'):
                    masklabel = 'Medcof'
                elif domain == 'iberia':
                    masklabel = domain[0].upper()+domain[1:]# mask name is Uppercase for iberian domain, i.e. "Iberia"
                else:
                    ValueError('Check entry for <domain> input variable !')                
                mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                nc_mask = xr.open_dataset(mask_file)
                mask_appended = np.tile(nc_mask.mask.values,(len(nc_fc.time),len(nc_fc.member),1,1))
                nc_fc = nc_fc.where(mask_appended == 1, np.nan) #retain grid-boxes marked with 1 in mask
                #nc_fc = nc_fc.where(mask_appended == 1, nc_fc, np.nan) #retain grid-boxes marked with 1 in mask
                nc_mask.close()
                del(nc_mask)
            elif variables_std[vv] not in masked_variables_std:
                print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variables_std[vv]+' !')
            else:
                ValueError('check whether <variables_std[vv]> is in <masked_variables_std> !')
            
            # masked_data_argmax = masked_data_argmax.where(valid_data_bool.isel(tercile=0), other=np.nan) # brings back the nans, not that the tercile dimension must be removed from valid_data_bool
            masked_data_argmax = masked_data_argmax.where(valid_data_bool.isel(tercile=0).drop_vars('tercile'), masked_data_argmax, np.nan())
            # if variables_std[vv] == 'SPEI-3-M':
            #     pdb.set_trace()
            nc_forecast['mlt_'+variables_out[vv]] = masked_data_argmax
            nc_forecast['prob_'+variables_out[vv]] = nc_forecast_step['probability'].max(dim='tercile')
            #add attributes
            nc_forecast['mlt_'+variables_out[vv]].attrs['long_name'] = 'Tercile category (1=lower, 2=middle, 3=upper) for '+variables_out[vv]
            nc_forecast['mlt_'+variables_out[vv]].attrs['units'] = '1'
            nc_forecast['prob_'+variables_out[vv]].attrs['long_name'] = 'probability_of_most_likely_tercile_for_'+variables_out[vv]
            nc_forecast['prob_'+variables_out[vv]].attrs['standard_name'] = 'probability_of_event_in_category'
            nc_forecast['prob_'+variables_out[vv]].attrs['units'] = '1'
            #clean
            masked_data.close()
            masked_data_argmax.close()
            del(masked_data,masked_data_argmax)
            nc_forecast_step.close()
            del(nc_forecast_step)

        # nc_forecast = nc_forecast.transpose('aggregation', 'model', 'variable', 'rtime', 'tercile', 'season', 'y', 'x')

        #check whether the previously stored model and version thereof match those requested by this script
        if nc_forecast.model == model[mm]+version[mm]:
            print('The requested model '+model[mm]+' and its version '+version[mm]+' coincide with the entry previously stored in '+filename_forecast+' !')
        else:
            raise ValueError('The requested model '+model[mm]+' and its version '+version[mm]+' do NOT coincide with the entry previously stored in '+filename_forecast+' !')
        
        #filter subperiod, detrending option, model and version, season, and variable from skill mask
        fc_season_length = nc_forecast.season.length_in_months

        #check whether the requested aggregation window matches the season length stored within the file
        if fc_season_length != int(agg_labels[ag][0]):
            ValueError('<fc_season_length> must equal <agg_labels[ag]> ! ')

        fc_seasons = nc_forecast.season.values
        nc_val_sub = nc_val.sel(subperiod=subperiod,detrended=detrended,model=model[mm]+version[mm],season=fc_seasons,variable=variables_std)[score]
        val_leads = nc_val_sub.lead.values

        # #check whether the number of seasons provided by the forrecast files matches the number of lead-times provided by the skill file 
        # if len(fc_seasons) != len(versleads):
        #     raise ValueError('the <seasons> and <leads> variables_std must have the same lenght !')    
        
        skill_mask = np.zeros((len(variables_std),len(fc_seasons),len(nc_val.y),len(nc_val.x)))
        for sea in np.arange(len(fc_seasons)):
            skill_mask_step = nc_val_sub.sel(season=fc_seasons[sea],lead=val_leads[sea])
            skill_mask[:,sea,:,:] = skill_mask_step.values

        #bring numpy array into xarray data array format
        skill_mask = xr.DataArray(skill_mask.astype('float32'),coords=[variables_std,fc_seasons,nc_val.y,nc_val.x],dims=['variable','season','y','x'], name='skill_mask')

        #cut down the forecast domain to the skill domain indicated in the <domain> input variable
        nc_forecast = nc_forecast.sel(y=skill_mask.y,x=skill_mask.x)
        
        # #merge probabilies and skill mask containting all variables
        # nc_forecast['skill_mask'] = skill_mask

        #generate variable-specific skill masks and merge with the variable specific most likely tercile
        for vv in np.arange(len(variables_std)):
            skill_mask_step = skill_mask.sel(variable=variables_std[vv]).drop('variable') #select skill mask for a given variable and drop "variable" coordinate since it is no longer needed
            skill_mask_step.attrs['long_name'] = 'binary_skill_mask_based_on_'+score+' for '+variables_out[vv]
            skill_mask_step.attrs['standard_name'] = 'binary_skill_mask'
            skill_mask_step.attrs['units'] = 'binary'            
            nc_forecast['skill_'+variables_out[vv]] = skill_mask_step #assign variable-specific skill mask to the newly generated xarray dataset produced by this script
            skill_mask_step.close()
            del(skill_mask_step)
        
        # save the mergerd output file
        # savename = dir_forecast+'/probability_plus_skill_'+model[mm]+version[mm]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_'+str(fc_season_length)+'mon_dtr_'+detrended+'_refyears_'+str(nc_forecast.tercile.tercile_period[0])+'_'+str(nc_forecast.tercile.tercile_period[1])+'.nc'
        savename = dir_output+'/seas2ipe_'+model[mm]+version[mm]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_'+str(fc_season_length)+'mon_dtr_'+detrended+'_refyears_'+str(tercile_attrs['tercile_period'][0])+'_'+str(tercile_attrs['tercile_period'][1])+'.nc'
        
        ## optionally encode the output netcdf file
        # chunks = (1, 1, 1, 1, len(nc_forecast.y), len(nc_forecast.y))
        # encoding = dict(tp=dict(chunksizes=chunks)) #https://docs.xarray.dev/en/stable/user-guide/io.html#writing-encoded-data
        # nc_forecast.to_netcdf(savename,encoding=encoding)
        
        nc_forecast.to_netcdf(savename)

        #clean up
        nc_val_sub.close()
        skill_mask.close()
        nc_forecast.close()
        del(nc_val_sub,skill_mask,nc_forecast)

    #clean up
    nc_val.close()
    del(nc_val)

print('INFO: seas2ipe.py has been run successfully ! The netcdf output file has been stored at '+dir_output)
quit()
