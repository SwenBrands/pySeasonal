#!/usr/bin/env python
''' This is the operational verions of pred2tercile.py, which is called from bash via <generate_forecast.sh>.
The script loads a forecast at a given init passed via the <year_init> and <month_init> input parameters, aggregates the raw values to seasonal averages and transforms them into tercile probabilities.
The main difference to pred2tercile.py is that only one init is processed, meaning that the yy loop has been deleted here.'''

#load packages
from datetime import date
import numpy as np
import xarray as xr
import os
import pandas as pd
import dask
import sys
import pdb
import time

#the init of the forecast (year and month) can passed by bash; if nothing is passed these parameters will be set by python
if len(sys.argv) == 2:
    print("Reading from input parameters passed via bash")
    year_init = str(sys.argv[1])[0:4]
    month_init = str(sys.argv[1])[-2:]
    if len(year_init) != 4 or len(month_init) != 2:
        raise Exception('ERROR: check length of <year_month_init> input parameter !')
else:
    print("No input parameter have been provided by the user and the script will set the <year_init> and <month_init> variables for the year and month of the current date...")
    year_init = str(date.today().year)
    month_init = f"{date.today().month:02d}"
    print(date.today())
print(year_init, month_init)

#overwrite the aformentioned variables for develompment purposes
year_init = 2024 #a list containing the years the forecast are initialized on, will be looped through with yy
month_init = 6 #a list containing the corresponding months the forecast are initialized on, will be called while looping through <year_init> (with yy), i.e. must have the same length

#set input parameters
quantile_version = 'v1n' #version of the validation results
agg_label = ['1mon','2mon','3mon','4mon','5mon'] # ['1mon','3mon'] list of strings used to label to aggregation period in the output files generated by this script; the length of this list defines the number of aggregation windows

model = ['cmcc','ecmwf'] # ['cmcc','ecmwf'] models to be assessed
version = ['35','51'] # version of these models

years_quantile = [[1993,2022],[1993,2022]] #years used to calculate the quantiles with get_skill_season.py; list containing as many sublists as they are models

variable_std = ['pvpot','SPEI-3-M','fwi','msl','t2m','tp','si10','ssrd'] # standard model variable names used by the pySeasonal package. Here used to load the quantile threshold files and to write the output netCDF files generated by this script
variable_fc = ['pvpot','SPEI-3-M','fwi','psl','tas','pr','sfcWind','rsds'] # variable name used in the file name, i.e. outside the file, ask collegues for data format harmonization
variable_fc_nc = ['pvpot','SPEI-3-M','FWI','psl','tas','pr','sfcWind','rsds'] # variable name within the model netcdf file, may vary depending on source
time_name = ['time','time','time','forecast_time','forecast_time','forecast_time','forecast_time','forecast_time'] #name of the time dimension within the model netcdf file, may vary depending on source
lon_name = ['lon','lon','lon','x','x','x','x','x']
lat_name = ['lat','lat','lat','y','y','y','y','y']
file_start = ['seasonal-original-single-levels_derived','seasonal-original-single-levels_masked','seasonal-original-single-levels_derived','seasonal-original-single-levels','seasonal-original-single-levels','seasonal-original-single-levels','seasonal-original-single-levels','seasonal-original-single-levels'] #start string of the file names

# variable_std = ['SPEI-3-M','msl','t2m','tp','si10','ssrd'] # variable name used inside and outside of the quantile file. This is my work and is thus homegeneous.
# variable_fc = ['SPEI-3-M','psl','tas','pr','sfcWind','rsds'] # variable name used in the file name, i.e. outside the file, ask collegues for data format harmonization
# variable_fc_nc = ['SPEI-3-M','psl','tas','pr','sfcWind','rsds'] # variable name within the model netcdf file, may vary depending on source
# time_name = ['time','forecast_time','forecast_time','forecast_time','forecast_time','forecast_time'] #name of the time dimension within the model netcdf file, may vary depending on source
# lon_name = ['lon','x','x','x','x','x']
# lat_name = ['lat','y','y','y','y','y']
# file_start = ['seasonal-original-single-levels_masked','seasonal-original-single-levels','seasonal-original-single-levels','seasonal-original-single-levels','seasonal-original-single-levels','seasonal-original-single-levels'] #start string of the file names

precip_threshold_quotient = 30 #seasonal mean daily precipitation threshold in mm below which the modelled and quasi-observed monthly precipitation amount is set to 0. Bring this in exact agreement with get_skill_season.py in future versions
datatype = 'float32' #data type of the variables in the output netcdf files
domain = 'medcof' #spatial domain
masked_variable_std = ['fwi','SPEI-3-M'] #list of variables on which a land-sea mask will be applied, setting values over sea to nan
detrended = 'no' #yes or no, linear detrending of the gcm and obs time series prior to validation
nr_mem = [25] #considered ensemble members, not yet in use !

#visualization options
figformat = 'png' #format of output figures, pdf or png
dpival = 300 #resolution of output figures
south_ext_lambert = 0 #extend the southern limit of the box containing the Lambert Conformal Projection

#set basic path structure for observations and gcms
gcm_store = os.getenv('GCM_STORE', 'lustre') #argo, laptop, F, extdisk2 or lustre
product = 'forecast'

## EXECUTE #############################################################
quantile_threshold = [0.33,0.67]
# #check consistency of input parameters
# if (lon_name[-1] != 'x') | (lat_name[-1] != 'y'):
    # raise Exception('ERROR: the last entries of the <lon_name> and <lat_name> input lists must be "x" and "y" respectively to ensure that the output netCDF file is consistent!')

#set path to input gcm files
if gcm_store == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    path_gcm_base = home+'/DATA/SEASONAL/seasonal-original-single-levels' # head directory of the source files
    path_gcm_base_derived = home+'/DATA/SEASONAL/seasonal-original-single-levels_derived' # head directory of the source files
    path_gcm_base_masked = home+'/DATA/SEASONAL/seasonal-original-single-levels_masked' # head directory of the source files    
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    dir_quantile = home+'/Results/seasonal/validation'
    dir_forecast = home+'/Results/seasonal/forecast'
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
elif gcm_store == 'argo':
    home = os.getenv("DATA_DIR", "")
    path_gcm_base = home+'seasonal-original-single-levels' # head directory of the source files
    path_gcm_base_derived = home+'seasonal-original-single-levels_derived' # head directory of the source files
    path_gcm_base_masked = home+'seasonal-original-single-levels_masked' # head directory of the source files
    rundir = '/app/terciles'
    dir_quantile = '/mnt/vol'
    dir_forecast = home+'seasonal-original-single-levels_derived/medcof/forecast/terciles/'
    mask_dir = '/lustre/gmeteo/PTICLIMA/Auxiliary-material/Masks' #path to the land-sea masks
else:
    raise Exception('ERROR: unknown entry for <path_gcm_base> !')
print('The GCM files will be loaded from the base directory '+path_gcm_base+'...')

#go to rundir
os.chdir(rundir)
exec(open('functions_seasonal.py').read()) #reads the <functions_seasonal.py> script containing a set of custom functions needed here

#create output directory of the forecasts generated here, if it does not exist.
if os.path.isdir(dir_forecast) != True:
    os.makedirs(dir_forecast)

#make forecast for each aggregation window, model and variable
for ag in np.arange(len(agg_label)):
    precip_threshold = 1 / (precip_threshold_quotient*int(agg_label[ag][0]))
    season_length = int(agg_label[ag][0])
    for mm in np.arange(len(model)):

        # #load the quantiles file
        # filename_quantiles = dir_quantile+'/'+quantile_version+'/'+agg_label[ag]+'/quantiles/quantiles_pticlima_'+agg_label[ag]+'_'+model[mm]+version[mm]+'_'+domain+'_'+str(years_quantile[mm][0])+'_'+str(years_quantile[mm][1])+'_'+quantile_version+'.nc'
        
        # #check whether the previously stored model and version thereof match those requested by this script
        # nc_quantile = xr.open_dataset(filename_quantiles)
        # if nc_quantile.model == model[mm]+version[mm]:
        #     print('The requested model '+model[mm]+' and its version '+version[mm]+' coincide with the entry previously stored in <nc_quantile.model>: '+str(nc_quantile.model)+'!')
        # else:
        #     raise ValueError('The requested model '+model[mm]+' and its version '+version[mm]+' do NOT coincide with the entry previously stored in <nc_quantile.model>: '+str(nc_quantile.model)+'!')
        
        for vv in np.arange(len(variable_fc)):

            # #load the quantiles file
            filename_quantiles = dir_quantile+'/'+quantile_version+'/'+agg_label[ag]+'/quantiles/quantiles_pticlima_'+agg_label[ag]+'_'+model[mm]+version[mm]+'_'+variable_std[vv]+'_'+domain+'_'+str(years_quantile[mm][0])+'_'+str(years_quantile[mm][1])+'_'+quantile_version+'.nc'

            # check whether the previously stored model and version thereof match those requested by this script
            nc_quantile = xr.open_dataset(filename_quantiles)
            if nc_quantile.model == model[mm]+version[mm]:
                print('The requested model '+model[mm]+' and its version '+version[mm]+' coincide with the entry previously stored in <nc_quantile.model>: '+str(nc_quantile.model)+'!')
            else:
                raise ValueError('The requested model '+model[mm]+' and its version '+version[mm]+' do NOT coincide with the entry previously stored in <nc_quantile.model>: '+str(nc_quantile.model)+'!')

            #load forecast file
            if variable_fc[vv] in ('SPEI-3','SPEI-3-M','SPEI-3-R'):
                filename_forecast = path_gcm_base_masked+'/'+domain+'/'+product+'/'+variable_fc[vv]+'/'+model[mm]+'/'+version[mm]+'/coefs_pool_members/'+str(year_init)+str(month_init).zfill(2)+'/'+file_start[vv]+'_'+domain+'_'+product+'_'+variable_fc[vv]+'_'+model[mm]+'_'+version[mm]+'_'+str(year_init)+str(month_init).zfill(2)+'.nc'
            elif variable_fc[vv] in ('fwi','pvpot'):
                filename_forecast = path_gcm_base_derived+'/'+domain+'/'+product+'/'+variable_fc[vv]+'/'+str(year_init)+str(month_init).zfill(2)+'/'+file_start[vv]+'_'+domain+'_'+product+'_'+variable_fc[vv]+'_'+model[mm]+'_'+version[mm]+'_'+str(year_init)+str(month_init).zfill(2)+'.nc'
            elif variable_fc[vv] in ('psl','sfcWind','tas','pr','rsds'):
                filename_forecast = path_gcm_base+'/'+domain+'/'+product+'/'+variable_fc[vv]+'/'+model[mm]+'/'+version[mm]+'/'+str(year_init)+str(month_init).zfill(2)+'/'+file_start[vv]+'_'+domain+'_'+product+'_'+variable_fc[vv]+'_'+model[mm]+'_'+version[mm]+'_'+str(year_init)+str(month_init).zfill(2)+'.nc'
            else:
                raise Exception('ERROR: check entry for variables[vv] !')
            
            #filename_forecast = path_gcm_base+'/'+product+'/'+variable_fc[vv]+'/'+model[mm]+'/'+version[mm]+'/'+str(year_init)+str(month_init).zfill(2)+'/'+file_start[vv]+'_'+domain+'_'+product+'_'+variable_fc[vv]+'_'+model[mm]+'_'+version[mm]+'_'+str(year_init)+str(month_init).zfill(2)+'.nc'
            nc_fc = xr.open_dataset(filename_forecast)

            #optionally apply land sea mask; set values of sea to nan
            if variable_std[vv] in masked_variable_std:
                print('Upon user request, values for sea grid-boxes are set to nan for '+variable_std[vv]+' ! ')                
                #get mask label as a function of the requested sub-domain
                if domain in ('medcof','medcof2'):
                    masklabel = 'Medcof'
                elif domain == 'iberia':
                    masklabel = domain[0].upper()+domain[1:]# mask name is Uppercase for iberian domain, i.e. "Iberia"
                else:
                    ValueError('Check entry for <domain> input variable !')                
                mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc'
                nc_mask = xr.open_dataset(mask_file)
                mask_appended = np.tile(nc_mask.mask.values,(len(nc_fc.time),len(nc_fc.member),1,1))
                nc_fc = nc_fc.where(mask_appended == 1, np.nan) #retain grid-boxes marked with 1 in mask
                #nc_fc = nc_fc.where(mask_appended == 1, nc_fc, np.nan) #retain grid-boxes marked with 1 in mask
                nc_mask.close()
                del(nc_mask)
            elif variable_std[vv] not in masked_variable_std:
                print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variable_std[vv]+' !')
            else:
                ValueError('check whether <variable_std[vv]> is in <masked_variable_std> !')

            #a seventh forecast months was erroneously added to the SPEI-3-M from cmcc35. This is corrected here
            if model[mm] == 'cmcc' and version[mm] == '35' and variable_fc[vv] == 'SPEI-3-M':
                print('Removing 7th forecast months from '+model[mm]+version[mm]+' and '+variable_fc[vv])
                time_ind = np.arange(len(nc_fc.time)-1) #get time index with the last month removed
                nc_fc = nc_fc.isel(time=time_ind)
            else:
                print('No correction is necessary for '+model[mm]+version[mm]+' and '+variable_fc[vv]+'. The forecast data will be processed as it is.')
            
            #check if the latitudes are in the right order or must be flipped to be consistent with the obserations used for validation
            if nc_fc[lat_name[vv]][0].values < nc_fc[lat_name[vv]][-1].values:
                print('WARNING: the latitudes in '+filename_forecast+' come in ascending order and are inverted to be consistent with the order of the remaining datasets / variables (descending) !')
                if lat_name[vv] == 'lat':
                    nc_fc = nc_fc.reindex(lat=list(reversed(nc_fc.lat)))
                elif lat_name[vv] == 'y':
                    nc_fc = nc_fc.reindex(y=list(reversed(nc_fc.y)))
                else:
                    raise Exception('ERROR: unexpected entry for <lat_name[vv]> !')

            #transform GCM variables and units, if necessary
            nc_fc, file_valid = transform_gcm_variable(nc_fc,variable_fc[vv],variable_std[vv],model[mm],version[mm])
            #check whether there is a problem with the variable units as revealed in transform_gcm_variable()
            if file_valid == 0:
                raise Exception('ERROR: There is a problem with the expected variable units in '+filename_forecast+' !')
            
            #get forecast seasons from file
            dates_fc = pd.DatetimeIndex(nc_fc.time.values)
            #check whether the model input data is monthly, otherwise daily is assumed and this must be improved in future versions
            if len(dates_fc.month) == len(np.unique(dates_fc.month)):
                print('INFO: the model input data for '+variable_fc[vv]+' is monthly !')
                months_fc_uni = dates_fc.month
            else:
                months_fc_uni = dates_fc[15::30].month #get unique forecast month in the right order, i.e. as appears in the file
            
            season = []
            season_label = []
            season_start_month = np.arange(len(months_fc_uni)-season_length+1) #index of the first month of each 3-month period
            
            #init final output array
            if vv == 0:
                out_arr = np.zeros((len(variable_fc),len(quantile_threshold)+1,len(season_start_month),len(nc_fc[lat_name[vv]]),len(nc_fc[lon_name[vv]])),dtype=datatype)
                out_arr[:] = np.nan
            for mo in season_start_month:
                season_i = months_fc_uni[mo:mo+season_length].to_list()
                season_i_label = assign_season_label(season_i)
                season_ind = np.where(np.isin(dates_fc.month,season_i))[0]
                if time_name[vv] == 'forecast_time':
                    seas_mean = nc_fc[variable_fc_nc[vv]].isel(forecast_time=season_ind).mean(dim=time_name[vv])
                elif time_name[vv] == 'time':
                    seas_mean = nc_fc[variable_fc_nc[vv]].isel(time=season_ind).mean(dim=time_name[vv])
                else:
                    raise Exception('ERROR: unkwnown entry for <time_name[vv]> input parameter!')
                
                #precipitation correction, is here done on seasonal timescale, but must be done on montly timescale in the future to be consistent with get_skill_season.py!
                if variable_fc[vv] == 'pr':
                    print('INFO: setting seasonal mean '+variable_fc[vv]+' values from '+model[mm]+version[mm]+' < '+str(precip_threshold)+' to 0...')
                    #zero_mask = seas_mean[variable_fc[vv]].values < precip_threshold
                    #seas_mean[variable_fc[vv]].values[zero_mask] = 0.
                    zero_mask = seas_mean.values < precip_threshold
                    seas_mean.values[zero_mask] = 0.

                # get the ensemble terciles for this season and leadtime (note that the season and leadtime have the same index !)
                
                # # option to load quantile files containing multiple variables without the singleton dimensions <aggregation> and <model> requested by front-end.
                # lower_xr = nc_quantile.sel(detrended=detrended,quantile_threshold=quantile_threshold[0],variable=variable_std[vv],season=season_i_label).quantile_ensemble.isel(lead=mo) #is a 2D xarray data array
                # upper_xr = nc_quantile.sel(detrended=detrended,quantile_threshold=quantile_threshold[1],variable=variable_std[vv],season=season_i_label).quantile_ensemble.isel(lead=mo)
                
                # #  option to load quantile files containing single variables with the singleton dimensions <aggregation> and <model> requested by front-end.
                lower_xr = nc_quantile.sel(aggregation=agg_label[ag],model=model[mm]+version[mm],detrended=detrended,quantile_threshold=quantile_threshold[0],season=season_i_label).quantile_ensemble.isel(lead=mo) #is a 2D xarray data array
                upper_xr = nc_quantile.sel(aggregation=agg_label[ag],model=model[mm]+version[mm],detrended=detrended,quantile_threshold=quantile_threshold[1],season=season_i_label).quantile_ensemble.isel(lead=mo)

                # calculate the forecast probabilities with these terciles
                nr_mem,upper_prob,center_prob,lower_prob = get_forecast_prob(seas_mean,lower_xr,upper_xr)

                ##set ocean points to nan
                # upper_prob = upper_prob.where(~np.isnan(lower_xr.values))
                # center_prob = center_prob.where(~np.isnan(lower_xr.values))
                # lower_prob = lower_prob.where(~np.isnan(lower_xr.values))
                
                #stack and turn to numpy format
                probab = np.stack((lower_prob.values,center_prob.values,upper_prob.values),axis=0)
                probab_nan = np.zeros((probab.shape))
                probab_nan[:] = np.nan
                #get index of the tercile having the maximum forecast probability at each grid box; save this probability at the given tercile; at the other terciles the nan value will be kept.
                for ii in np.arange(probab.shape[1]):
                    for jj in np.arange(probab.shape[2]):
                        maxind = np.argmax(probab[:,ii,jj])
                        probab_nan[maxind,ii,jj] = probab[maxind,ii,jj]
                        probab_nan[probab_nan == 0] = np.nan #set 0 probabilities to nan
                #probab_nan[maxprob_ind] = probab[maxprob_ind,:,:]
                out_arr[vv,:,mo,:,:] = probab_nan
                season.append(season_i)
                season_label.append(season_i_label)

        #create xarray data array and save to netCDF format
        date_init = [nc_fc.time[0].values.astype(str)]
        out_arr = np.expand_dims(out_arr,axis=0) #add "rtime" dimension to add the date of the forecast init

        # output file format option without singleton dimensions for aggregation and model
        # out_arr = xr.DataArray(out_arr, coords=[date_init,variable_std,np.array((1,2,3)),season_label,nc_fc[lat_name[-1]],nc_fc[lon_name[-1]]], dims=['rtime','variable','tercile','season','y','x'], name='probability')
        
        # output file format option with singleton dimensions for aggregation and model, as requested by Jaime.
        out_arr = np.expand_dims(out_arr,axis=0)
        out_arr = np.expand_dims(out_arr,axis=0)
        out_arr = xr.DataArray(out_arr, coords=[[agg_label[ag]],[model[mm]+version[mm]],date_init,variable_std,np.array((1,2,3)),season_label,nc_fc[lat_name[-1]],nc_fc[lon_name[-1]]], dims=['aggregation','model','rtime','variable','tercile','season','y','x'], name='probability')
        out_arr = out_arr.to_dataset()
        
        #set dimension attributes
        out_arr['rtime'].attrs['standard_name'] = 'forecast_reference_time'
        out_arr['rtime'].attrs['long_name'] = 'initialization date of the forecast'
        out_arr['tercile'].attrs['long_name'] = 'terciles in ascending order, 1 = lower, 2 = center, 3 = upper'
        out_arr['tercile'].attrs['tercile_period'] = years_quantile[mm]
        out_arr['tercile'].attrs['tercile_version'] = nc_quantile.version[mm]
        out_arr['variable'].attrs['long_name'] = 'name of the meteorological variable'
        out_arr['season'].attrs['long_name'] = 'season the forecast is valid for'
        out_arr['season'].attrs['length_in_months'] = season_length
        #set variable attributes
        out_arr['probability'].attrs['units'] = 'forecast probability ('+str(np.round(out_arr['probability'].min().values,3))+' - '+str(np.round(out_arr['probability'].max().values,3))+') for the most probable tercile, otherwise nan'
        out_arr['probability'].attrs['detrended'] = detrended
        #set global attributes
        out_arr.attrs['model'] = model[mm]+version[mm]
        out_arr.attrs['temporal_aggregation'] = agg_label[ag]
        out_arr.attrs['init'] = str(date_init[0])
        out_arr.attrs['file_author'] = nc_quantile.author

        ##set chunking and save the file
        #out_arr = out_arr.chunk({"variable":1, "tercile":1, "season":1, "y":len(nc_fc[lat_name[-1]]), "x":len(nc_fc[lon_name[-1]])})        

        # options to save multiple variables per file
        # encoding for output file format option without singleton dimensions for aggregation and model
        # encoding = dict(probability=dict(chunksizes=(1, 1, 1, 1, len(nc_fc[lat_name[-1]]), len(nc_fc[lon_name[-1]])))) #https://docs.xarray.dev/en/stable/user-guide/io.html#writing-encoded-data
        
        # # encoding for output file format option with singleton dimensions for aggregation and model
        # encoding = dict(probability=dict(chunksizes=(1, 1, 1, 1, 1, 1, len(nc_fc[lat_name[-1]]), len(nc_fc[lon_name[-1]])))) #https://docs.xarray.dev/en/stable/user-guide/io.html#writing-encoded-data
        # savename = dir_forecast+'/probability_'+agg_label[ag]+'_'+model[mm]+version[mm]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_'+str(season_length)+'mon_dtr_'+detrended+'_refyears_'+str(years_quantile[mm][0])+'_'+str(years_quantile[mm][1])+'_'+quantile_version+'.nc'
        # out_arr.to_netcdf(savename,encoding=encoding)

        # option to save one variable per file
        for vvv in np.arange(len(variable_std)):
            out_arr_singlevar = out_arr.sel(variable=variable_std[vvv]).drop_vars("variable")
            out_arr_singlevar.attrs['variable'] = variable_std[vvv]
            encoding = dict(probability=dict(chunksizes=(1, 1, 1, 1, 1, len(nc_fc[lat_name[-1]]), len(nc_fc[lon_name[-1]])))) #https://docs.xarray.dev/en/stable/user-guide/io.html#writing-encoded-data
            savename_out_arr_singlevar = dir_forecast+'/probability_'+agg_label[ag]+'_'+model[mm]+version[mm]+'_'+variable_std[vvv]+'_init_'+str(year_init)+str(month_init).zfill(2)+'_dtr_'+detrended+'_refyears_'+str(years_quantile[mm][0])+'_'+str(years_quantile[mm][1])+'_'+quantile_version+'.nc'
            out_arr_singlevar.to_netcdf(savename_out_arr_singlevar,encoding=encoding)
            out_arr_singlevar.close()
            del(out_arr_singlevar)
            time.sleep(1)

        # close all xarray objects
        lower_xr.close()
        upper_xr.close()
        seas_mean.close()
        nc_fc.close()
        out_arr.close()
        # del(lower_xr,upper_xr,seas_mean,nc_fc,out_arr)
            
        nc_quantile.close()
        del(nc_quantile)

print('INFO: pred2tercile_operational.py has been run successfully ! The netcdf output file has been stored at '+dir_forecast)

quit()
#sys.exit(0)
