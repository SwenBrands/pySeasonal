#!/usr/bin/env python

'''calculates skill scores for each season and lead over the overlapping time period indicated in <years_model> and <years_obs>.
Also calculates and stores the model quantiles over this period, which are used by pred2tercile.py .'''

#load packages
import sys
import numpy as np
import xarray as xr
import xskillscore as xs
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cf
import os
import xesmf
import pandas as pd
import dask
import time
from scipy.signal import detrend
from scipy.stats import linregress
import pdb #then type <pdb.set_trace()> at a given line in the code below
start_time = time.time()

# take input variables from bash
#optionally take input variables set in launch_get_skill_season.sh, which are passed via get_skill_season.sh
if len(sys.argv) > 1:
    print("Reading from input parameters passed via bash")
    vers = str(sys.argv[1]) #string format
    models = [str(sys.argv[2])] #list format
    variables_gcm = [str(sys.argv[3])] #list format
    agg_labels = [str(sys.argv[4])] #list format
    modulators = [str(sys.argv[5])] #list format
    phases = [str(sys.argv[6])] #list format
    FLAGDIR = str(sys.argv[7]) #string containing the path the flag directory

    #make sure that the list <variables_gcm> only contains a single character string in this mode
    if len(models) !=1 or len(variables_gcm) !=1 or len(agg_labels) !=1 or len(modulators) !=1 or len(phases) !=1:
        ValueError('If input parameters are ingested from the overhead bash script <get_skill_season.sh>, each of these must be a single character string !')

    #pair model variable with observed variable
    if variables_gcm[0] in ('SPEI-3-M','SPEI-3-R','SPEI-3-R-C1'):
        variables_obs = ['SPEI-3']
    elif variables_gcm[0] in ('pvpot','fwi','SPEI-3-M','t2m','tp','msl','si10','ssrd'):
        variables_obs = variables_gcm
    else:
        ValueError('Unknown entry for variables_gcm !')

else:
    # # set standard input parameters
    # vers = 'v1m_test' #version number of the output netCDF file to be sent to Predictia; will be extended by "_mon" or "_seas" depending on whether 1-month or 3-month values will be verified
    # models = ['eccc5','cmcc35','ecmwf51'] #['cmcc35','ecmwf51'] list of models and versions thereof
    # variables_gcm = ['pvpot','fwi','SPEI-3-M','t2m','tp','msl','si10','ssrd'] #model variable names in CDS format  GCM variable names have been set to ERA5 variable names from CDS in <aggregate_hindcast.py> except for <SPEI-3-M> and <SPEI-3-R>, which are paired with <SPEI-3> in <variables_obs>)
    # variables_obs = ['pvpot','fwi','SPEI-3','t2m','tp','msl','si10','ssrd'] #variable names in observations; are identical to <variables_gcm> except for <SPEI-3>, which is referred to as <SPEI-3-M> or <SPEI-3-R> in the model depending on whether past values are taken from the model or reanalysis (i.e. quasi-observations)
    # agg_labels = ['1mon','3mon'] #list of strings used to label to aggregation period in the output files generated by this script; the length of this list defines the number of aggregation windows
    # modulators = ['none','enso','enso','enso'] # list containing modulators climate oscillation assumed to modulate the verification results; currently: "enso" or "none"
    # phases = ['none','0','1','2'] #changed to string format for all entries in the new version

    vers = 'v1o' #version number of the output netCDF file to be sent to Predictia; will be extended by "_mon" or "_seas" depending on whether 1-month or 3-month values will be verified
    models = ['cmcc4'] #['cmcc35','ecmwf51'] list of models and versions thereof
    variables_gcm = ['t2m'] #model variable names in CDS format  GCM variable names have been set to ERA5 variable names from CDS in <aggregate_hindcast.py> except for <SPEI-3-M> and <SPEI-3-R>, which are paired with <SPEI-3> in <variables_obs>)
    variables_obs = ['t2m'] #variable names in observations; are identical to <variables_gcm> except for <SPEI-3>, which is referred to as <SPEI-3-M> or <SPEI-3-R> in the model depending on whether past values are taken from the model or reanalysis (i.e. quasi-observations)
    agg_labels = ['5mon'] #list of strings used to label to aggregation period in the output files generated by this script; the length of this list defines the number of aggregation windows
    modulators = ['none'] # list containing modulators climate oscillation assumed to modulate the verification results; currently: "enso" or "none"
    phases = ['none'] #changed to string format for all entries in the new version
    FLAGDIR = '/lustre/gmeteo/PTICLIMA/Scripts/SBrands/pyPTIclima/pySeasonal/FLAG/get_skill'

# set the remaining (fixed) input variables
obs = ['era5'] #list of observational datasets used as reference for verification. Currently, only ERA5 is admitted, i.e. the list has a single item.
years_obs = [1981,2022] #years used in label of obs netCDF file; if they differ from <years_model>, then the common intersection of years will be validated.
modulator_ref = 'init' #init or valid; the time instance the modulation in valid for. If set to 'init', then the time series are modulated with the teleconnection index valid at the initalization month. If set to 'valid', they are modulated with the index valid at the time the forecast is valid.
min_nr_events = 3 # the minimum number of events that must be reached for each modulator and events to permit the verification; if this threshold is not reached, the script returns a ValueError
years_quantile = [1993,2022] #start and end years of the time series used to calculate the quantiles from obserations and model data
file_system = 'lustre' #lustre or myLaptop; used to create the path structure to the input and output files
precision = 'float32' #data type of the variables in the output netcdf files
compression_level = 1
precip_threshold = 1/30 #1/30; monthly mean daily precipitation threshold in mm below which the modelled and quasi-observed monthly precipitation amount is set to 0; Bring the parameter in pred2tercile.py in exact agreement with this script in future versions
#bin_edges_reliability = np.linspace(0, 1, 4) # probability edges used to calculate the reliability, either <None> in which case the default of xs.reliability() is used (currently 5 bins) or, which should return the same, manually pass 5 bins with np.linspace(0, 1, 6); or 3 bins with np.linspace(0, 1, 4)
bin_edges_reliability = None
corr_outlier = 'no'
aggreg = 'mon' #temporal aggregation of the input files
domain = 'medcof' #spatial domain
int_method = 'conservative_normed' #'conservative_normed', interpolation method used before in <regrid_obs.py>
quantiles = [1/3,1/3*2] #quantiles of the year-to-year time series to be calculated and stored
skillscore_reference = 'rand' #'clim' or 'rand'; use either the climatological mean or randomly reshuffled observed time series as reference forcast for calculating the CPRSS
nr_pseudo_mem = 25 #number of times the climatological mean or randomly reshuffled observarions are replicated along the "member" dimension to mimic a model ensemble representing the naiv climatological forecasts used as reference for calculating the CRPS Skill Score. Results are insensitive to variations in this value; the script has been tested for value=2 and 4.

#options for methods estimating hindcast skill
testlevel = 0.05
detrending = ['yes','no'] #yes or no, linear detrending of the gcm and obs time series prior to validation

#visualization options
figformat = 'png' #format of output figures, pdf or png
dpival = 300 #resolution of output figures
south_ext_lambert = 0 #extend the southern limit of the box containing the Lambert Conformal Projection

## EXECUTE #############################################################

#set basic path structure for observations and gcms
if file_system == 'lustre':
    home = '/lustre/gmeteo/PTICLIMA'
    rundir = home+'/Scripts/SBrands/pyPTIclima/pySeasonal'
    path_obs_base = home+'/Results/seasonal/obs/regridded'
    path_gcm_base = home+'/Results/seasonal/gcm/aggregated' 
    dir_netcdf = home+'/Results/seasonal/validation/'
    dir_telcon = home+'/Results/seasonal/indices' #directory of the netCDF file containing the phases of known teleconnection indices; currently ENSO only, as generated with oni2enso.py
    filename_telcon = 'oni2enso_195001_202505.nc' #name of the file located in <dir_telcon>
else:
    raise Exception('ERROR: unknown entry for <file_system> input parameter!')

#load custom functions and configuraiton files
exec(open(rundir+'/functions_seasonal.py').read()) #reads the <functions_seasonal.py> script containing a set of custom functions needed here
exec(open(rundir+'/config/config_for_get_skill_season.py').read()) #reads additional input variables (or arguments) used in this script

#load the season configurations depending on the aggregation periods specified in <agg_labels>
season_label = []
season = []
for ag in np.arange(len(agg_labels)):
    season_label_step = eval(eval("'season_label_'+seas", {"seas": agg_labels[ag]}))
    season_step = eval(eval("'season_'+seas", {"seas": agg_labels[ag]}))
    season_label.append(season_label_step)
    season.append(season_step)

#load the model-specific configuration previously set in the rundir+/config_for_get_skill_season.py file
lead = [] #init list containing the lead-time configuration for each model and aggregation window
nr_mem = [] #init list containing the number of members per model; this list contains as many sub-lists as there are models to be validated
years_model = [] #init list containing the start and end years of period to be evaluated for each model (may contain the combined hindcasts and forecasts); this list contains as many sub-lists as there are models to be validated
for mm in np.arange(len(models)):
    nr_mem_step = eval(eval("'nr_mem_'+mod", {"mod": models[mm]}))
    years_model_step = eval(eval("'years_'+mod", {"mod": models[mm]}))
    nr_mem.append(nr_mem_step)
    years_model.append(years_model_step)
    
    leads_per_model = [] #init lead-times per model
    for ag in np.arange(len(agg_labels)):
        lead_step = eval(eval("'lead_'+mod+'_'+aggr", {"mod": models[mm],"aggr": agg_labels[ag]}))
        leads_per_model.append(lead_step)
    lead.append(leads_per_model)

#print the variables built from the configuration files
print('------------------------------------------------')
print('THE FOLLOWNG CONFIGURATION HAS BEEN LOADED:')
print('version: '+str(vers))
print('agg_labels: '+str(agg_labels))
print('modulators: '+str(modulators))
print('phases: '+str(phases))
print('season_label: '+str(season_label))
print('season: '+str(season))
print('models: '+str(models))
print('nr_mem: '+str(nr_mem))
print('years_model: '+str(years_model))
print('lead: '+str(lead))
print('model variables: '+str(variables_gcm))
print('obs. variables: '+str(variables_obs))
print('------------------------------------------------')

#go to working directory and load custom functions
os.chdir(rundir)
#import functions_seasonal
print('The script will be run in '+rundir+' !')
    
#check consistency of some input parameters
if len(season) != len(season_label):
    raise Exception('ERROR: the length of the list <season> does not equal the length of the list <season_label> !')

if len(season) != len(agg_labels):
    raise Exception('ERROR: the length of the list <season> does not equal the length of the list <agg_labels> !')

print('Starting verification for '+str(variables_gcm)+' from '+str(models)+' vs. '+str(obs)+', model years '+str(years_model)+', obs years '+str(years_obs)+', quantile years '+str(years_quantile)+' for modulation with '+str(modulators)+' in phase '+str(phases)+'...')

dir_netcdf = dir_netcdf+'/'+vers #dir_netcdf is extended with the version directory

#create output directories needed by this script, if needed.
if os.path.isdir(dir_netcdf) != True:
    os.makedirs(dir_netcdf)
if os.path.isdir(FLAGDIR) != True:
    os.makedirs(FLAGDIR)

#read the file containing the different phases of known climate oscillation such as ENSO, this file has to be previously generated with oni2enso.py
indices = xr.open_dataset(dir_telcon+'/'+filename_telcon)

#xr.set_options(file_cache_maxsize=1)
for mo in np.arange(len(modulators)):
    for ag in np.arange(len(agg_labels)):
        #create output final output directory if it does not exist.
        dir_netcdf_scores = dir_netcdf+'/'+agg_labels[ag]+'/scores'
        dir_netcdf_terciles = dir_netcdf+'/'+agg_labels[ag]+'/tercile_probabilities'
        dir_netcdf_quantiles = dir_netcdf+'/'+agg_labels[ag]+'/quantiles'
        if os.path.isdir(dir_netcdf_scores) != True:
            os.makedirs(dir_netcdf_scores)
        if os.path.isdir(dir_netcdf_terciles) != True:
            os.makedirs(dir_netcdf_terciles)
        if os.path.isdir(dir_netcdf_quantiles) != True:
            os.makedirs(dir_netcdf_quantiles)

        for mm in np.arange(len(models)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables_gcm)):       
                    #create a numpy array containing all lead-months for models[mm]
                    lead_arr = np.arange(np.array(lead[ag][mm]).min(),np.array(lead[ag][mm]).max()+1)
                    #get label describing the considered lead-time
                    lead_label = [str(lead[ag][mm][ll]).replace(',','').replace('[','').replace(']','').replace(' ','') for ll in np.arange(len(lead[ag][mm]))]
                    #get numpy array for the years considered for quantile calculation
                    years_quantile_vec = np.arange(years_quantile[0],years_quantile[1]+1,1)

                    if models[mm] == 'ecmwf51' and lead_arr[-1] > 6: #if leadtime > 6 for ecmwf51, the return an error because the 7th forecast month is composed of a few days only in this gcm
                        raise Exception('ERROR: the maximum lead requested for '+models[mm]+' ('+str(lead_arr[-1])+') is not valid ! Please check the entries of the input parameter <lead>.')        
                    elif models[mm] == 'cmcc35' and lead_arr[-1] > 5:
                        raise Exception('ERROR: the maximum lead requested for '+models[mm]+' ('+str(lead_arr[-1])+') is not valid ! Please check the entries of the input parameter <lead>.')        
                    else:
                        print('Maximum lead-month = '+str(lead_arr[-1])+' for '+models[mm]+' has been set correctly. Proceed to verification....')
                    
                    path_gcm = path_gcm_base+'/'+models[mm]+'/'+variables_gcm[vv]+'_'+aggreg+'_'+models[mm]+'_'+str(nr_mem[mm])+'m_'+domain+'_'+str(years_model[mm][0])+'_'+str(years_model[mm][-1])+'.nc'
                    nc_gcm = xr.open_dataset(path_gcm)
                    #nc_gcm = xr.open_dataset(path_gcm, chunks = {'member' : 1})
                    nc_gcm[variables_gcm[vv]] = nc_gcm[variables_gcm[vv]].astype(precision)
                    #leads = np.arange(lead[ag][mm])
                    members = nc_gcm.member.values
                    nc_gcm = nc_gcm.isel(lead=lead_arr) #filter out the necessary leads only
                    
                    #set modelled precip. < precip_threshold to nan; note that slightly negative values are present in the monthly precipiation accumulations of ECMWF51
                    if variables_gcm[vv] == 'tp':
                        print('INFO: setting '+variables_gcm[vv]+' values from '+models[mm]+ '< '+str(precip_threshold)+' 0 !')
                        zero_mask = nc_gcm[variables_gcm[vv]].values < precip_threshold
                        nc_gcm[variables_gcm[vv]].values[zero_mask] = 0.
                        #nc_gcm[variables_gcm[vv]].values[zero_mask] = np.nan
                        del(zero_mask)

                    leads = nc_gcm.lead.values
                    dates_gcm = pd.DatetimeIndex(nc_gcm.time.values)

                    for oo in np.arange(len(obs)):
                        # path_obs = path_obs_base+'/'+obs[oo]+'/'+variables_obs[vv]+'_'+aggreg+'_'+obs[oo]+'_on_'+models[mm]+'_grid_'+int_method+'_'+domain+'_'+str(years_obs[0])+'_'+str(years_obs[-1])+'.nc'
                        path_obs = path_obs_base+'/'+obs[oo]+'/'+variables_obs[vv]+'_'+aggreg+'_'+obs[oo]+'_on_ecmwf51_grid_'+int_method+'_'+domain+'_'+str(years_obs[0])+'_'+str(years_obs[-1])+'.nc'
                        nc_obs = xr.open_dataset(path_obs)
                        nc_obs[variables_obs[vv]] = nc_obs[variables_obs[vv]].astype(precision)
                        
                        #set observed precip. < precip_threshold to nan
                        if variables_obs[vv] == 'tp':
                            print('INFO: setting '+variables_obs[vv]+' values from '+obs[oo]+ '< '+str(precip_threshold)+' to 0 !')
                            zero_mask = nc_obs[variables_obs[vv]].values < precip_threshold
                            nc_obs[variables_obs[vv]].values[zero_mask] = 0.
                            #nc_obs[variables_obs[vv]].values[zero_mask] = np.nan
                            del(zero_mask)

                        dates_obs = pd.DatetimeIndex(nc_obs.time.values)
                        dates_bool_obs = dates_obs.isin(dates_gcm)
                        dates_bool_gcm = dates_gcm.isin(dates_obs)
                        dates_obs = dates_obs[dates_bool_obs]
                        dates_gcm = dates_gcm[dates_bool_gcm]
                        
                        #select common time period in gcm and obs data
                        nc_obs = nc_obs.isel(time = dates_bool_obs)
                        nc_gcm = nc_gcm.isel(time = dates_bool_gcm)                
                        #redefined date vectors for common time period
                        dates_obs = pd.DatetimeIndex(nc_obs.time.values)
                        dates_gcm = pd.DatetimeIndex(nc_gcm.time.values)

                        #check whether the observed and model dates are identical; if yes then get common years to label the netcdf output files generated by this script
                        if np.all(dates_gcm.isin(dates_obs)) == True and np.all(dates_obs.isin(dates_gcm)) == True:
                            print('INFO: The dates from observations and the model are identical.')
                            years_common2label = dates_obs.year.values
                        else:
                            raise Exception('ERROR: The dates from observations do not agree whith those obtained from the model !')
                    
                        #set observed precip. < precip_threshold to 0
                        if variables_obs[vv] == 'tp':
                            print('INFO: setting '+variables_obs[vv]+' values from '+obs[oo]+ '< '+str(precip_threshold)+' to 0...')
                            zero_mask = nc_obs[variables_obs[vv]].values < precip_threshold
                            nc_obs[variables_obs[vv]].values[zero_mask] = 0.
                    
                        #loop through each season
                        for sea in np.arange(len(season[ag])):
                            #loop through list of monthly lead times
                            for ll in np.arange(len(lead[ag][mm])):
                                print('INFO: validating agg. window '+str(agg_labels[ag])+' for '+variables_obs[vv]+' from '+models[mm]+' vs '+obs[oo]+' in '+str(season[ag][sea])+' and lead-time '+str(lead[ag][mm])+' with detrending '+detrending[det])

                                #get dates for the inter-annual time series containing the requested seasons
                                seasind_obs = np.where(np.isin(dates_obs.month,season[ag][sea]))[0] #get time indices pointing to all months forming the requested season
                                nc_obs_isea = nc_obs.isel(time = seasind_obs)
                                dates_isea = pd.DatetimeIndex(nc_obs_isea.time.values)
                                #retain only one date entry per year to pair with seaonal mean averages calculated below
                                seasind_obs_for_dates = np.where(dates_isea.month == season[ag][sea][0])[0]
                                dates_isea = dates_isea[seasind_obs_for_dates]
                                
                                #init numpy array which will be filled with seasonal mean values (time x season x lead x member x lat x lon)
                                if sea == 0 and ll == 0:
                                    nr_years = len(dates_isea) #length of the year-to-year time vector for a specific season
                                    nr_seas = len(season[ag])
                                    nr_leads = len(lead[ag][mm])
                                    nr_mems =  len(nc_gcm['member'])                        
                                    nr_lats = len(nc_gcm['y'])
                                    nr_lons = len(nc_gcm['x'])
                                    obs_seas_mn_5d = np.zeros((nr_years,nr_seas,nr_leads,nr_lats,nr_lons))
                                    obs_seas_mn_5d[:] = np.nan
                                    gcm_seas_mn_6d = np.zeros((nr_years,nr_seas,nr_leads,nr_mems,nr_lats,nr_lons))
                                    gcm_seas_mn_6d[:] = np.nan
                                    #these inits are for the non weighted (nw) seasonal mean values which will be calculated alongside the weighted values below for comparison
                                    obs_seas_mn_5d_nw = np.copy(obs_seas_mn_5d)
                                    gcm_seas_mn_6d_nw = np.copy(gcm_seas_mn_6d)

                                    # pdb.set_trace()
                                    # if oo == 0 and vv == 0:
                                    #     #init numpy arrays to store forecast probabilities per tercile
                                    #     tercile_prob_gcm_6d = np.zeros((nr_years,nr_seas,nr_leads,len(quantiles)+1,nr_lats,nr_lons))
                                    #     tercile_bin_obs_5d = np.zeros((nr_years,nr_seas,nr_leads,nr_lats,nr_lons))
                                
                                #init numpy array which will be filled with quantile values (detrending x variables_gcm x quantiles x season x lead x member x lat x lon)
                                #if det == 0 and vv == 0 and mm == 0 and sea == 0 and ll == 0:
                                if det == 0 and vv == 0 and sea == 0 and ll == 0:
                                    print('Initializing numpy arrays to be filled with quantiles '+str(quantiles)+'...')
                                    # gcm_quantile_vals = np.zeros((len(detrending),len(variables_gcm),len(models),len(quantiles),nr_seas,nr_leads,nr_mems,nr_lats,nr_lons),dtype=precision)
                                    gcm_quantile_vals = np.zeros((len(detrending),len(variables_gcm),len(quantiles),nr_seas,nr_leads,nr_mems,nr_lats,nr_lons),dtype=precision)
                                    gcm_quantile_vals[:] = np.nan
                                    # quantile_vals_ens = np.zeros((len(detrending),len(variables_gcm),len(models),len(quantiles),nr_seas,nr_leads,nr_lats,nr_lons),dtype=precision)
                                    quantile_vals_ens = np.zeros((len(detrending),len(variables_gcm),len(quantiles),nr_seas,nr_leads,nr_lats,nr_lons),dtype=precision)
                                    quantile_vals_ens[:] = np.nan
                                    obs_quantile_vals = np.copy(quantile_vals_ens)

                                    #init arrays to be filled with the binary observed terciles
                                    lower_tercile_obs = np.zeros((len(detrending),len(variables_gcm),nr_years,nr_seas,nr_leads,nr_lats,nr_lons),dtype=precision)
                                    lower_tercile_obs[:] = np.nan
                                    center_tercile_obs = np.copy(lower_tercile_obs)
                                    upper_tercile_obs = np.copy(lower_tercile_obs)
                                
                                #and loop through each month of this season to calculate the seasonal mean values in both the model and observations
                                for mon in np.arange(len(season[ag][sea])):
                                    print('INFO: get values for month '+str(season[ag][sea][mon])+' and leadtime '+str(lead[ag][mm][ll][mon])+'...')
                                    monthind_gcm = np.where(np.isin(dates_gcm.month,season[ag][sea][mon]))[0]
                                    monthind_obs = np.where(np.isin(dates_obs.month,season[ag][sea][mon]))[0]
                                    #check for consistent indices pointing the target month
                                    if np.sum(monthind_obs - monthind_gcm) != 0:
                                        raise Exception('ERROR: the indices indicating the target month in the observed and model data do not agree !')                    
                                    
                                    #select the target months/seasons and work with xarray data arrays and numpy arrays from here on instead of working with xr datasets
                                    nc_gcm_mon = nc_gcm[variables_gcm[vv]].isel(time=monthind_gcm) #get the requested calendar month from the model
                                    nc_gcm_mon = nc_gcm_mon.sel(lead=lead[ag][mm][ll][mon]) #get the requested lead from the model
                                    nc_obs_mon = nc_obs[variables_obs[vv]].isel(time=monthind_obs) #get the requested calendar month from the observations / reanalysis, there is no lead time in this case
                                    gcm_mon = nc_gcm_mon.values #retain the numpy arrays with in the xr dataarrays
                                    obs_mon = nc_obs_mon.values #retain the numpy arrays with in the xr dataarrays
                                    
                                    #set values to nan for first January and Feburary values in the time series forming the DJF-mean value. The J and F values have no D pair at the start of fhe time series.
                                    # option for 2 mon
                                    if season[ag][sea] == [12,1] and str(season[ag][sea][mon]) in ('1'):
                                        print('INFO: target season is '+str(season[ag][sea])+', target month is '+str(season[ag][sea][mon])+'. The first value is thus set to NaN!')
                                        gcm_mon[0,:,:,:] = np.nan
                                        obs_mon[0,:,:] = np.nan
                                    # option for 3mon
                                    elif (season[ag][sea] == [12,1,2] and str(season[ag][sea][mon]) in ('1','2')) or (season[ag][sea] == [11,12,1] and str(season[ag][sea][mon]) in ('1')):
                                        print('INFO: target season is '+str(season[ag][sea])+', target month is '+str(season[ag][sea][mon])+'. The first value is thus set to NaN!')
                                        gcm_mon[0,:,:,:] = np.nan
                                        obs_mon[0,:,:] = np.nan
                                    # option for 4 mon
                                    elif (season[ag][sea] == [10,11,12,1] and str(season[ag][sea][mon]) in ('1')) or (season[ag][sea] == [11,12,1,2] and str(season[ag][sea][mon]) in ('1','2')) or (season[ag][sea] == [12,1,2,3] and str(season[ag][sea][mon]) in ('1','2','3')):
                                        print('INFO: target season is '+str(season[ag][sea])+', target month is '+str(season[ag][sea][mon])+'. The first value is thus set to NaN!')
                                        gcm_mon[0,:,:,:] = np.nan
                                        obs_mon[0,:,:] = np.nan
                                    # option for 5 mon
                                    elif (season[ag][sea] == [9,10,11,12,1] and str(season[ag][sea][mon]) in ('1')) or (season[ag][sea] == [10,11,12,1,2] and str(season[ag][sea][mon]) in ('1','2')) or (season[ag][sea] == [11,12,1,2,3] and str(season[ag][sea][mon]) in ('1','2','3')) or (season[ag][sea] == [12,1,2,3,4] and str(season[ag][sea][mon]) in ('1','2','3','4')):
                                        print('INFO: target season is '+str(season[ag][sea])+', target month is '+str(season[ag][sea][mon])+'. The first value is thus set to NaN!')
                                        gcm_mon[0,:,:,:] = np.nan
                                        obs_mon[0,:,:] = np.nan
                                    else:
                                        print('INFO: target season is '+str(season[ag][sea])+', target month is '+str(season[ag][sea][mon]))

                                    ##init numpy array with additional dimension <month> whose lenght equals the number of months in season[sea]
                                    if mon == 0:
                                        gcm_allmon = np.zeros((gcm_mon.shape[0],gcm_mon.shape[1],gcm_mon.shape[2],gcm_mon.shape[3],len(season[ag][sea])))
                                        gcm_allmon[:] = np.nan
                                        obs_allmon = np.zeros((obs_mon.shape[0],obs_mon.shape[1],obs_mon.shape[2],len(season[ag][sea])))
                                        obs_allmon[:] = np.nan
                                    #close temporary xarray objects
                                    nc_gcm_mon.close()
                                    nc_obs_mon.close()
                                    nc_obs_isea.close()
                                    
                                    #fill the initialized arrays
                                    gcm_allmon[:,:,:,:,mon] = gcm_mon
                                    obs_allmon[:,:,:,mon] = obs_mon
                                #calculate weighted seasonal mean values
                                weights = nc_obs_isea.time.dt.days_in_month #get number of days per month for all months of all years forming the time series
                                seasind = np.arange(len(season[ag][sea])) #get index to cut out the n months of the first year, where n is the season length in months, i.e. typically 3
                                weights = weights[seasind] #cut ot the number of days for these months and replicate to match the dimensions of obs_allmon and gcm_allmon
                                weights_obs = np.tile(weights,(nr_years,nr_lats,nr_lons,1))
                                weights_gcm = np.tile(weights,(nr_years,nr_mems,nr_lats,nr_lons,1))
                                obs_seas_mn_5d[:,sea,ll,:,:] = np.sum(obs_allmon * weights_obs, axis = 3) / weights_obs.sum(axis=3)
                                gcm_seas_mn_6d[:,sea,ll,:,:] = np.sum(gcm_allmon * weights_gcm, axis = 4) / weights_gcm.sum(axis=4)
                                #calculate and store unweighted seasonal mean values for comparison
                                obs_seas_mn_5d_nw[:,sea,ll,:,:] = obs_allmon.mean(axis=-1)
                                gcm_seas_mn_6d_nw[:,sea,ll,:,:,:] = gcm_allmon.mean(axis=-1)
                        
                        #convert numpy array into xarray data arrays
                        obs_seas_mn_5d = xr.DataArray(obs_seas_mn_5d,coords=[dates_isea,season_label[ag],lead_label,nc_obs.y,nc_obs.x],dims=['time', 'season', 'lead', 'y', 'x'], name=variables_obs[vv]) #convert to xarray data array
                        #obs_seas_mn_6d = xr.DataArray(obs_seas_mn_6d,coords=[dates_isea,season_label[ag],lead_label,members,nc_obs.y,nc_obs.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_obs[vv])
                        gcm_seas_mn_6d = xr.DataArray(gcm_seas_mn_6d,coords=[dates_isea,season_label[ag],lead_label,members,nc_gcm.y,nc_gcm.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_gcm[vv]) #convert to xarray data array
                        gcm_seas_mn_5d = gcm_seas_mn_6d.mean(dim='member') #get ensemble mean values
                        
                        #optionally apply linear detrending to the time-series, see https://gist.github.com/rabernat/1ea82bb067c3273a6166d1b1f77d490f
                        if detrending[det] == 'yes':
                            print('INFO: As requested by the user, the gcm and obs time series are linearly detrended.')
                            obs_seas_mn_5d = lin_detrend(obs_seas_mn_5d,'no')
                            start_time = time.time()
                            gcm_seas_mn_6d = lin_detrend(gcm_seas_mn_6d,'no')
                            end_time = time.time()
                            print(f"the execution time for detrending was {end_time - start_time} seconds")

                            # #alternative loop
                            # start_time = time.time()
                            # gcm_seas_mn_6d_np = gcm_seas_mn_6d.values
                            # gcm_seas_mn_6d_np2fill = np.zeros(gcm_seas_mn_6d_np.shape)
                            # gcm_seas_mn_6d_np2fill[:] = np.nan
                            # for s in np.arange(len(gcm_seas_mn_6d.season)):
                            #     for l in np.arange(len(gcm_seas_mn_6d.lead)):
                            #         for m in np.arange(len(gcm_seas_mn_6d.member)):
                            #             for la in np.arange(len(gcm_seas_mn_6d.y)):
                            #                 for lo in np.arange(len(gcm_seas_mn_6d.x)):
                            #                     ts = gcm_seas_mn_6d_np[:,s,l,m,la,lo]
                            #                     time_axis = np.arange(len(ts))
                            #                     mask = ~np.isnan(ts)
                            #                     fit1 = linregress(time_axis[mask], ts[mask])
                            #                     trend = fit1.slope*time_axis
                            #                     ts_dt = ts - trend
                            #                     #ts_dt = detrend(ts[mask], axis=-1, type='linear', bp=0, overwrite_data=False)
                            #                     gcm_seas_mn_6d_np2fill[:,s,l,m,la,lo] = ts_dt
                            #                     #slope, intercept, r_value, p_value, std_err = stats.linregress(varx[mask], vary[mask])
                            # end_time = time.time()
                            # print(f"the Execution time for detrending was {end_time - start_time} seconds")                    
                            # gcm_seas_mn_6d = xr.DataArray(gcm_seas_mn_6d_np2fill,coords=[dates_isea,season_label[ag],lead_label,members,nc_gcm.y,nc_gcm.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_gcm[vv]) #convert to xarray data array
                            
                            gcm_seas_mn_5d = lin_detrend(gcm_seas_mn_5d,'no')
                            
                        elif detrending[det] == 'no':
                            print('INFO: As requested by the user, the gcm and obs time series are not detrended.')
                        else:
                            raise Exception('ERROR: check entry for <detrending[det]>')
                                        
                        #calculate the quantiles along the time dimension and put them into the pre-initialized numpy arrays
                        bool_obs_quantile_years = pd.DatetimeIndex(obs_seas_mn_5d.time).year.isin(years_quantile_vec) #get boolean for obs
                        bool_gcm_quantile_years = pd.DatetimeIndex(gcm_seas_mn_5d.time).year.isin(years_quantile_vec) #get boolean for gcm
                        
                        #then calculate the member-wise quantiles
                        obs_quantile_vals_step = obs_seas_mn_5d.isel(time = bool_obs_quantile_years).quantile(quantiles, dim='time')
                        gcm_quantile_vals_step = gcm_seas_mn_6d.isel(time = bool_gcm_quantile_years).quantile(quantiles, dim='time')
                        # gcm_quantile_vals[det,vv,mm,:,:,:,:,:,:] = gcm_quantile_vals_step.values #here numpy arrays are filled
                        gcm_quantile_vals[det,vv,:,:,:,:,:,:] = gcm_quantile_vals_step.values #here numpy arrays are filled
                        obs_quantile_vals[det,vv,:,:,:,:,:] = obs_quantile_vals_step.values #and here too

                        #get observed tercile thresholds
                        t1_obs = np.expand_dims(obs_quantile_vals_step.sel(quantile=0.33,method='nearest').values,axis=0).repeat(obs_seas_mn_5d.shape[0],axis=0)
                        t2_obs = np.expand_dims(obs_quantile_vals_step.sel(quantile=0.66,method='nearest').values,axis=0).repeat(obs_seas_mn_5d.shape[0],axis=0)

                        #get binary arrays
                        lower_tercile_obs_step = (obs_seas_mn_5d < t1_obs).astype(precision)
                        center_tercile_obs_step = ((obs_seas_mn_5d >= t1_obs) & (obs_seas_mn_5d < t2_obs)).astype(precision)
                        upper_tercile_obs_step = (obs_seas_mn_5d >= t2_obs).astype(precision)

                        #recover nans lost in the former 3 lines
                        nanmask = np.isnan(obs_seas_mn_5d)
                        lower_tercile_obs_step.values[nanmask] = np.nan
                        center_tercile_obs_step.values[nanmask] = np.nan
                        upper_tercile_obs_step.values[nanmask] = np.nan

                        #fill the pre-initialized numpy arrays
                        lower_tercile_obs[det,vv,:,:,:,:,:] = lower_tercile_obs_step
                        center_tercile_obs[det,vv,:,:,:,:,:] = center_tercile_obs_step
                        upper_tercile_obs[det,vv,:,:,:,:,:] = upper_tercile_obs_step

                        dates_obs = pd.DatetimeIndex(obs_seas_mn_5d.time.values)
                        dates_gcm_5d = pd.DatetimeIndex(gcm_seas_mn_5d.time.values)
                        dates_gcm_6d = pd.DatetimeIndex(gcm_seas_mn_6d.time.values)
                        nr_years = len(dates_obs)

                        #check whether the 5d and 6d model arrays have the same time dimension
                        if np.all(dates_gcm_5d.isin(dates_gcm_6d)) == True and np.all(dates_gcm_6d.isin(dates_gcm_5d)) == True:
                            print('INFO: The 5d and 6d data arrays from the model are identical.')
                        else:
                            raise Exception('ERROR: The 5d and 6d data arrays from the model are not identical !')
                        #continue with a single dates_gcm pandas datetime index and delete the unnecessary ones
                        dates_gcm = dates_gcm_5d
                        del(dates_gcm_5d,dates_gcm_6d)

                        #check whether the modelled and observed dates are identical
                        if np.all(dates_obs.isin(dates_gcm)) == True and np.all(dates_gcm.isin(dates_obs)) == True:
                            print('INFO: the modelled and observed date vectors are identical.')
                            years_common = dates_gcm.year.values
                            print('INFO: the common time period used for verification is '+str(years_common)+' !')
                        else:
                            raise Exception('ERROR: the modelled and observed date vectors are not identical !')
                        
                        #get overall / ensemble quantiles calculated upon the array with flattened "member" dimension, thereby mimicing a n member times longer time series
                        gcm_seas_mn_5d_flat_mems = gcm_seas_mn_6d.transpose('time','member','season','lead','y','x') #change order of the dimensions
                        shape_gcm = gcm_seas_mn_5d_flat_mems.shape #get new shape
                        gcm_seas_mn_5d_flat_mems = gcm_seas_mn_5d_flat_mems.values.reshape((shape_gcm[0]*shape_gcm[1],shape_gcm[2],shape_gcm[3],shape_gcm[4],shape_gcm[5])) #reshape to concatenate the members along the first / time axis
                        quantile_vals_ens_step = np.nanquantile(gcm_seas_mn_5d_flat_mems,quantiles,axis=0)
                        # quantile_vals_ens[det,vv,mm,:,:,:,:,:] = quantile_vals_ens_step
                        quantile_vals_ens[det,vv,:,:,:,:,:] = quantile_vals_ens_step

                        # turn numpy array into xarray data array
                        quantile_vals_ens_step = xr.DataArray(quantile_vals_ens_step, coords=[quantiles,gcm_seas_mn_6d.season,gcm_seas_mn_6d.lead,gcm_seas_mn_6d.y,gcm_seas_mn_6d.x], dims=['quantile_threshold','season','lead','y','x'], name='quantile_ensemble')
                        
                        #get year-to-year tercile probability forecasts for the non conditioned time series
                        if modulators[mo] == 'none':
                            print('Calculating tercile probability forecasts for temporal aggregation '+agg_labels[ag]+', '+models[mm]+', variable '+variables_gcm[vv]+' and modulator '+modulators[mo])
                            lower_xr = quantile_vals_ens_step.sel(quantile_threshold=0.33,method='nearest')
                            upper_xr = quantile_vals_ens_step.sel(quantile_threshold=0.66,method='nearest')
                            time_ind = gcm_seas_mn_6d.dims.index('time')
                            mem_ind = gcm_seas_mn_6d.dims.index('member')

                            lower_np = np.expand_dims(np.expand_dims(lower_xr.values,axis=0),axis=-3)
                            lower_np = lower_np.repeat(repeats=gcm_seas_mn_6d.shape[time_ind], axis=time_ind).repeat(repeats=gcm_seas_mn_6d.shape[mem_ind], axis=mem_ind)

                            upper_np = np.expand_dims(np.expand_dims(upper_xr.values,axis=0),axis=-3)
                            upper_np = upper_np.repeat(repeats=gcm_seas_mn_6d.shape[time_ind], axis=time_ind).repeat(repeats=gcm_seas_mn_6d.shape[mem_ind], axis=mem_ind)

                            upper_ind = (gcm_seas_mn_6d > upper_np) & (~np.isnan(upper_np))
                            # center_ind = (gcm_seas_mn_6d >= lower_np) & (gcm_seas_mn_6d <= upper_np) & (~np.isnan(upper_np))
                            center_ind = (gcm_seas_mn_6d >= lower_np) & (gcm_seas_mn_6d <= upper_np) & (~np.isnan(lower_np)) & (~np.isnan(upper_np))
                            lower_ind = (gcm_seas_mn_6d < lower_np) & (~np.isnan(lower_np))
                        
                            #sum members in each category and devide by the number of members, thus obtaining the probability
                            nr_mem_step = len(gcm_seas_mn_6d.member)
                            lower_prob = (lower_ind.sum(dim='member')/nr_mem_step).rename('lower_tercile_probability')
                            center_prob = (center_ind.sum(dim='member')/nr_mem_step).rename('center_tercile_probability')
                            upper_prob = (upper_ind.sum(dim='member')/nr_mem_step).rename('upper_tercile_probability')                            

                            #initialize numpy arrays to be filled with probability forecasts per tercile
                            if det == 0 and vv == 0 and oo == 0:
                                lower_prob_np = np.zeros((len(detrending),len(variables_gcm),lower_prob.shape[0],lower_prob.shape[1],lower_prob.shape[2],lower_prob.shape[3],lower_prob.shape[4]))
                                center_prob_np = np.copy(lower_prob_np)
                                upper_prob_np = np.copy(lower_prob_np)
                            
                            lower_prob_np[det,vv,:,:,:,:,:] = lower_prob.values
                            center_prob_np[det,vv,:,:,:,:,:] = center_prob.values
                            upper_prob_np[det,vv,:,:,:,:,:] = upper_prob.values                            

                        #generate 6d numpy array with observations replicated along the <member dimension>; will be used as reference for the member-wise GCM verification
                        if skillscore_reference == 'clim': #use climatological mean observations as reference forecast
                            print('As requested by the user, climatological-mean time series are used as reference forecasts')
                            ref_forecast = obs_seas_mn_5d.mean(dim='time').values
                            ref_forecast = np.expand_dims(np.expand_dims(ref_forecast,axis=0),axis=3)
                            ref_forecast = np.tile(ref_forecast,(nr_years,1,1,nr_pseudo_mem,1,1)) #get 6d numpy array containing the naiv climatological forecasts
                            # ref_forecast = xr.DataArray(ref_forecast,coords=[dates_isea,season_label[ag],lead_label,members[0:nr_pseudo_mem],nc_obs.y,nc_obs.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_obs[vv]+'_'+skillscore_reference)
                            ref_forecast = xr.DataArray(ref_forecast,coords=[dates_isea,season_label[ag],lead_label,np.arange(nr_pseudo_mem),nc_obs.y,nc_obs.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_obs[vv]+'_'+skillscore_reference)
                        elif skillscore_reference == 'rand': #use randomly reshuffled observed time series as reference forecast
                            print('As requested by the user, randomly reshuffled time series are used as reference forecasts. '+str(nr_pseudo_mem)+' random time series will be generated to this end.')
                            #init the output array of randomly resuffled time series and fill
                            ref_forecast = np.zeros((obs_seas_mn_5d.shape[0],obs_seas_mn_5d.shape[1],obs_seas_mn_5d.shape[2],nr_pseudo_mem,obs_seas_mn_5d.shape[3],obs_seas_mn_5d.shape[4]))
                            ref_forecast[:] = np.nan
                            ntime = len(years_common) #number of years
                            for ii in np.arange(nr_pseudo_mem):
                                rand1 = np.random.randint(0,ntime,ntime)
                                ref_forecast[:,:,:,ii,:,:] = obs_seas_mn_5d[rand1,:,:,:,:]
                                del(rand1)
                            # ref_forecast = xr.DataArray(ref_forecast,coords=[dates_isea,season_label[ag],lead_label,members[0:nr_pseudo_mem],nc_obs.y,nc_obs.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_obs[vv]+'_'+skillscore_reference)
                            ref_forecast = xr.DataArray(ref_forecast,coords=[dates_isea,season_label[ag],lead_label,np.arange(nr_pseudo_mem),nc_obs.y,nc_obs.x],dims=['time', 'season', 'lead', 'member', 'y', 'x'], name=variables_obs[vv]+'_'+skillscore_reference)
                        else:
                            raise Exception('ERROR: check entry for <skillscore_reference> input parameter !')
                        
                        #get name of the output file containing the verification results
                        if modulators[mo] == 'enso':
                            savename_results = dir_netcdf_scores+'/validation_results_season_'+variables_gcm[vv]+'_'+agg_labels[ag]+'_'+models[mm]+'_vs_'+obs[oo]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(years_common2label[0])+'_'+str(years_common2label[-1])+'_'+modulators[mo]+str(phases[mo])+modulator_ref+'_'+vers+'.nc'
                        elif modulators[mo] == 'none':
                            savename_results = dir_netcdf_scores+'/validation_results_season_'+variables_gcm[vv]+'_'+agg_labels[ag]+'_'+models[mm]+'_vs_'+obs[oo]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(years_common2label[0])+'_'+str(years_common2label[-1])+'_'+modulators[mo]+'_'+vers+'.nc'
                        else:
                            raise Exception('ERROR: unknown entry for <modulators[mo]> input parameter !')

                        ##start verification
                        #init numpy arrays to be filled along the "lead" dimension
                        pearson_r_np = np.zeros((len(season[ag]),len(lead[ag][mm]),len(gcm_seas_mn_5d.y),len(gcm_seas_mn_5d.x)))
                        pearson_pval_np = np.copy(pearson_r_np)
                        pearson_pval_effn_np = np.copy(pearson_r_np)
                        spearman_r_np = np.copy(pearson_r_np)
                        spearman_pval_np = np.copy(pearson_r_np)
                        spearman_pval_effn_np = np.copy(pearson_r_np)
                        bias_np = np.copy(pearson_r_np)
                        relbias_np = np.copy(pearson_r_np)
                        crps_ensemble_np = np.copy(pearson_r_np)
                        reliability_lower_np = np.copy(pearson_r_np)
                        reliability_upper_np = np.copy(pearson_r_np)
                        roc_auc_lower_np = np.copy(pearson_r_np)
                        roc_auc_upper_np = np.copy(pearson_r_np)
                        rpc_np = np.copy(pearson_r_np)

                        #get conditional verficiation results per lead-time
                        for ll in np.arange(len(lead_label)):
                            if modulators[mo] == 'enso':
                                #check where the modulation is valid and shift the indices time series in case it is valid at the time of model initialization. Then get the time period common to the teleconnection index and the modelled and observed time series
                                if modulator_ref == 'init':
                                    # indices_sub = indices.shift(time=int(lead_label[ll])) #shift the values in indices towards the future by lead_label[ll] months
                                    indices_sub = indices.shift(time=int(lead_label[ll][0])) #shift the values in indices towards the future by lead_label[ll] months
                                    indices_sub = indices_sub.isel(time=np.isin(indices_sub.time,obs_seas_mn_5d.time)) #get common time period with observations, which in turn was syncronized with model data above
                                elif modulator_ref == 'valid':
                                    indices_sub = indices.isel(time=np.isin(indices.time,obs_seas_mn_5d.time)) #get common time period with observations, which in turn was syncronized with model data above
                                else:
                                    raise Exception('ERROR: check entry for <modulator_ref> input parameter !')
                                # phase_ind = (indices_sub.oni2enso == phases[mo]).values
                                phase_ind = (indices_sub.oni2enso == int(phases[mo])).values
                                #check whether the minumum number of events set in <min_nr_events> is reached
                                if sum(phase_ind==False) < min_nr_events:
                                     ValueError('<phase_ind> must at least contain '+str(min_nr_events)+' True values !')
                            elif modulators[mo] == 'none':
                                indices_sub = indices.isel(time=np.isin(indices.time,obs_seas_mn_5d.time)) #is not used below any more if modulators[mo] = 'none'
                                phase_ind = np.array([True]*len(obs_seas_mn_5d.time)) #set all indices to True
                            else:
                                raise Exception('ERROR: unknown entry for <modulators[mo]> input parameter !')
                            
                            #get xarray data array for each lead time
                            pearson_r = xs.pearson_r(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('pearson_r')
                            pearson_pval = xs.pearson_r_p_value(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('pearson_pval')
                            pearson_pval_effn = xs.pearson_r_eff_p_value(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('pearson_pval_effn')
                            spearman_r = xs.spearman_r(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('spearman_r')
                            spearman_pval = xs.spearman_r_p_value(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('spearman_pval')
                            spearman_pval_effn = xs.spearman_r_eff_p_value(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('spearman_pval_effn')
                            bias = xs.me(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('bias') #in xskillscore the bias is termed me
                            relbias = (bias/obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]).mean(dim='time')*100).rename('relbias')
                            
                            crps_ensemble = xs.crps_ensemble(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]),member_weights=None,issorted=False,member_dim='member',dim='time',weights=None,keep_attrs=False).rename('crps_ensemble')
                            reliability_lower = get_reliability_or_roc(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]),obs_quantile_vals_step.sel(lead=lead_label[ll]),gcm_quantile_vals_step.sel(lead=lead_label[ll]),1/3,score_f = 'reliability',bin_edges_f = bin_edges_reliability).rename('reliability_lower_tercile') #calculate reliability for the first tercile
                            reliability_upper = get_reliability_or_roc(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]),obs_quantile_vals_step.sel(lead=lead_label[ll]),gcm_quantile_vals_step.sel(lead=lead_label[ll]),2/3,score_f = 'reliability',bin_edges_f = bin_edges_reliability).rename('reliability_upper_tercile') #calculate reliability for the third tercile
                            roc_auc_lower = get_reliability_or_roc(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]),obs_quantile_vals_step.sel(lead=lead_label[ll]),gcm_quantile_vals_step.sel(lead=lead_label[ll]),1/3,score_f = 'roc_auc').rename('roc_auc_lower_tercile') #calculate roc area under the curve for the first tercile
                            roc_auc_upper = get_reliability_or_roc(obs_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]),obs_quantile_vals_step.sel(lead=lead_label[ll]),gcm_quantile_vals_step.sel(lead=lead_label[ll]),2/3,score_f = 'roc_auc').rename('roc_auc_upper_tercile') #calculate roc area under the curve for the third tercile
                            
                            ## calculate ratio of predictable components following Cottrell et al. 2024, https://doi.org/10.1002/asl.1212
                            pearson_r_mod = xs.pearson_r(gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]),gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]),dim='time',skipna=True).rename('pearson_r_mod')
                            #rpc = (pearson_r / np.sqrt(gcm_seas_mn_5d.isel(time=phase_ind).sel(lead=lead_label[ll]).var(dim='time') / gcm_seas_mn_6d.isel(time=phase_ind).sel(lead=lead_label[ll]).var(dim='time').mean(dim='member'))).rename('rpc')
                            rpc = (pearson_r / pearson_r_mod.mean(dim='member')).rename('rpc')

                            #transform to nump and fill the full dimensional numpy data arrays    
                            pearson_r_np[:,ll,:,:] = pearson_r.values
                            pearson_pval_np[:,ll,:,:] = pearson_pval.values
                            pearson_pval_effn_np[:,ll,:,:] = pearson_pval_effn.values
                            spearman_r_np[:,ll,:,:] = spearman_r.values
                            spearman_pval_np[:,ll,:,:] = spearman_pval.values
                            spearman_pval_effn_np[:,ll,:,:] = spearman_pval_effn.values
                            bias_np[:,ll,:,:] = bias.values
                            relbias_np[:,ll,:,:] = relbias.values
                            crps_ensemble_np[:,ll,:,:] = crps_ensemble.values
                            reliability_lower_np[:,ll,:,:] = reliability_lower.values
                            reliability_upper_np[:,ll,:,:] = reliability_upper.values
                            roc_auc_lower_np[:,ll,:,:] = roc_auc_lower.values
                            roc_auc_upper_np[:,ll,:,:] = roc_auc_upper.values
                            rpc_np[:,ll,:,:] = rpc.values

                            #close the temporary xarray data arrays
                            pearson_r.close()
                            pearson_pval.close()
                            pearson_pval_effn.close()
                            spearman_r.close()
                            spearman_pval.close()
                            spearman_pval_effn.close()
                            bias.close()
                            relbias.close()
                            crps_ensemble.close()
                            reliability_lower.close()
                            reliability_upper.close()
                            roc_auc_lower.close()
                            roc_auc_upper.close()
                            pearson_r_mod.close()
                            rpc.close()
                            del(phase_ind,pearson_r,pearson_pval,pearson_pval_effn,spearman_r,spearman_pval,spearman_pval_effn,bias,relbias,crps_ensemble,reliability_lower,reliability_upper,roc_auc_lower,roc_auc_upper,pearson_r_mod,rpc)

                        #transform numpy arrays to xarray data arrays
                        pearson_r = xr.DataArray(pearson_r_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='pearson_r')
                        pearson_pval = xr.DataArray(pearson_pval_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='pearson_pval')
                        pearson_pval_effn = xr.DataArray(pearson_pval_effn_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='pearson_pval_effn')
                        spearman_r = xr.DataArray(spearman_r_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='spearman_r')
                        spearman_pval = xr.DataArray(spearman_pval_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='spearman_pval')
                        spearman_pval_effn = xr.DataArray(spearman_pval_effn_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='spearman_pval_effn')
                        bias = xr.DataArray(bias_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='bias')
                        relbias = xr.DataArray(relbias_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='relbias')
                        crps_ensemble = xr.DataArray(crps_ensemble_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='crps_ensemble')
                        reliability_lower = xr.DataArray(reliability_lower_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='reliability_lower_tercile')
                        reliability_upper = xr.DataArray(reliability_upper_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='reliability_upper_tercile')
                        roc_auc_lower = xr.DataArray(roc_auc_lower_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='roc_auc_lower_tercile')
                        roc_auc_upper = xr.DataArray(roc_auc_upper_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='roc_auc_upper_tercile')
                        rpc = xr.DataArray(rpc_np, coords=[obs_seas_mn_5d.season,obs_seas_mn_5d.lead,obs_seas_mn_5d.y,obs_seas_mn_5d.x], dims=['season','lead','y','x'], name='rpc')
                        
                        #set possible infinite values in relbias to nan
                        infmask = np.isinf(relbias.values)
                        relbias.values[infmask] = np.nan
                        del(infmask) #delete to save memory

                        ##Continuous Ranked Probability Score and respective skill score
                        crps_ensemble_clim = xs.crps_ensemble(obs_seas_mn_5d,ref_forecast,member_weights=None,issorted=False,member_dim='member',dim='time',weights=None,keep_attrs=False).rename('crps_ensemble_'+skillscore_reference)
                        crps_ensemble_skillscore = 1 - (crps_ensemble/crps_ensemble_clim)
                        #close and delete unnecesarry objects to save mem
                        crps_ensemble_clim.close()
                        del(crps_ensemble_clim)

                        # close and delete xarray objects not needed any more 
                        obs_quantile_vals_step.close()
                        gcm_quantile_vals_step.close()
                        del(obs_quantile_vals_step,gcm_quantile_vals_step)
                        
                        #calc. roc auc skill scores, see https://doi.org/10.1007/s00382-019-04640-4
                        roc_auc_lower_skillscore = (roc_auc_lower - 0.5) / 0.5 #roc auc lower tercile skill score
                        roc_auc_upper_skillscore = (roc_auc_upper - 0.5) / 0.5 #roc auc upper tercile skill score
                        
                        #set name of all 3 skill scores
                        crps_ensemble_skillscore = crps_ensemble_skillscore.rename('crps_ensemble_skillscore_'+skillscore_reference)
                        roc_auc_lower_skillscore = roc_auc_lower_skillscore.rename('roc_auc_lower_tercile_skillscore')
                        roc_auc_upper_skillscore = roc_auc_upper_skillscore.rename('roc_auc_upper_tercile_skillscore')
                        
                        #set infinite values to nan for all 3 skill scores
                        infmask_crps = np.isinf(crps_ensemble_skillscore.values)
                        crps_ensemble_skillscore.values[infmask_crps] = np.nan
                        del(infmask_crps)
                        infmask_roc_auc_lower = np.isinf(roc_auc_lower_skillscore.values)
                        roc_auc_lower_skillscore.values[infmask_roc_auc_lower] = np.nan
                        del(infmask_roc_auc_lower)
                        infmask_roc_auc_upper = np.isinf(roc_auc_upper_skillscore.values)
                        roc_auc_upper_skillscore.values[infmask_roc_auc_upper] = np.nan
                        del(infmask_roc_auc_upper)
                        
                        #add attribures
                        pearson_r.attrs['units'] = 'dimensionless'
                        pearson_pval.attrs['units'] = 'probability'
                        pearson_pval_effn.attrs['units'] = 'probability'
                        spearman_r.attrs['units'] = 'dimensionless'
                        spearman_pval.attrs['units'] = 'probability'
                        spearman_pval_effn.attrs['units'] = 'probability'
                        spearman_pval_effn.attrs['units'] = 'probability'
                        crps_ensemble.attrs['units'] = 'cummulative probability error'
                        crps_ensemble_skillscore.attrs['units'] = 'bound between -1 and 1, positive values indicate more skill than the reference climatological forecast'
                        crps_ensemble_skillscore.attrs['reference'] = 'Wilks (2006), pages 281 and 302-304'
                        bias.attrs['units'] = nc_obs[variables_obs[vv]].units
                        relbias.attrs['units'] = 'percent'
                        reliability_lower.attrs['units'] = 'probability'
                        reliability_upper.attrs['units'] = 'probability'
                        roc_auc_lower.attrs['units'] = 'area under the curve'
                        roc_auc_upper.attrs['units'] = 'area under the curve'
                        roc_auc_lower_skillscore.attrs['units'] = 'bound between -1 and 1, positive values indicate more skill than the reference climatological forecast'
                        roc_auc_upper_skillscore.attrs['units'] = 'bound between -1 and 1, positive values indicate more skill than the reference climatological forecast'
                        rpc.attrs['source'] = 'Eade et al. 2014, GRL, doi:10.1002/2014GL061146, equation 1'
                        rpc.attrs['long_name'] = 'Ratio of Predictabile Components'
                        rpc.attrs['standard_name'] = 'Ratio of Predictabile Components'
                        rpc.attrs['units'] = 'ratio'
                        rpc.attrs['info'] = 'An RPC value of 1 refers to a forecast system that perfectly reflects the actual predictability (Eade et al. 2014).'

                        #join xarray dataArrays containing the verification results into a single xarray dataset, set attributes and save to netCDF format
                        results = xr.merge((pearson_r,pearson_pval,pearson_pval_effn,spearman_r,spearman_pval,spearman_pval_effn,bias,relbias,crps_ensemble,crps_ensemble_skillscore,reliability_lower,reliability_upper,roc_auc_lower,roc_auc_upper,roc_auc_lower_skillscore,roc_auc_upper_skillscore,rpc)) #merge xr dataarrays into a single xr dataset
                        del results.attrs['units'] #delete global attributge <units>, which is unexpectedly created by xr.merge() in the previous line; <units> are preserved as variable attribute. 
                        #set global and variable attributes
                        start_year = str(dates_isea[0])[0:5].replace('-','') #start year considered in the skill assessment
                        end_year = str(dates_isea[-1])[0:5].replace('-','') #end year considered in the skill assessment
                        results.x['standard_name'] = 'longitude'
                        results.y['standard_name'] = 'latitude'
                        results.attrs['variable'] = variables_gcm[vv]
                        results.attrs['prediction_system'] = models[mm]
                        results.attrs['reference_observations'] = obs[oo]
                        results.attrs['domain'] = domain
                        results.attrs['validation_period'] = start_year+' to '+end_year
                        results.attrs['modulation'] = modulators[mo]+' in phase '+str(phases[mo])+' as defined in oni2enso.py'
                        
                        #set attributes related to modulation through low-frequency climate oscillations
                        if modulators[mo] == 'none':
                            results.attrs['modulation'] = modulators[mo]
                        else:
                            results.attrs['modulation'] = modulators[mo]+' in phase '+str(phases[mo])+' as defined in oni2enso.py'
                            results.attrs['modulation_time'] = 'model initializtion' #refers to the fact that the forecasts are conditioned on climate oscillation phases valid for the initialization month 

                        results.attrs['time_series_detrending'] = detrending[det]
                        results.attrs['outlier_correction'] = corr_outlier
                        results.attrs['version'] = vers
                        results.attrs['author'] = 'Swen Brands, brandssf@ifca.unican.es or swen.brands@gmail.com'
                        
                        #save the results
                        results.to_netcdf(savename_results)
                        
                        #retain dimensions used to store quantiles before deleting and closing the respective objects
                        print('retain dimension attributes for storing the quantiles....')
                        season2quan = results.season
                        lead2quan = results.lead
                        y2quan = results.y.astype(precision)
                        x2quan = results.x.astype(precision)
                        
                        #close and delete remaining temporary xarray objects to free memory
                        results.close()
                        pearson_r.close()
                        pearson_pval.close()
                        pearson_pval_effn.close()
                        spearman_r.close()
                        spearman_pval.close()
                        spearman_pval_effn.close()
                        bias.close()
                        relbias.close()
                        crps_ensemble.close()
                        crps_ensemble_skillscore.close()
                        obs_seas_mn_5d.close()
                        #obs_seas_mn_6d.close()
                        gcm_seas_mn_5d.close()
                        gcm_seas_mn_6d.close()
                        reliability_lower.close()
                        reliability_upper.close()
                        roc_auc_lower.close()
                        roc_auc_upper.close()
                        #roc_auc_lower_clim.close()
                        #roc_auc_upper_clim.close()
                        roc_auc_lower_skillscore.close()
                        roc_auc_upper_skillscore.close()
                        rpc.close()
                        indices_sub.close()
                        del(results,pearson_r,pearson_pval,pearson_pval_effn,spearman_r,spearman_pval,spearman_pval_effn,bias,relbias,crps_ensemble,crps_ensemble_skillscore,obs_seas_mn_5d,obs_seas_mn_5d_nw,gcm_seas_mn_5d,gcm_seas_mn_6d,gcm_seas_mn_6d_nw,reliability_lower,reliability_upper,roc_auc_lower,roc_auc_upper,roc_auc_lower_skillscore,roc_auc_upper_skillscore,rpc,indices_sub)
                    
                    #close nc files containing observations
                    nc_obs.close()
                    del(nc_obs)
                #retain attributes and then close and delete nc files containing model data
                x_attrs = nc_gcm.x.attrs
                y_attrs = nc_gcm.y.attrs
                nc_gcm.close()
                del(nc_gcm)
            
            #save tercile probabilities and quantiles into an xarray data arrays; do this separately for each aggregation time and model, but only for the entire time series, i.e. modulator=='none'
            if modulators[mo] == 'none':
                #merge and save model terciles
                upper_prob = xr.DataArray(upper_prob_np, coords=[detrending,variables_gcm,upper_prob.time,upper_prob.season,upper_prob.lead,upper_prob.y,upper_prob.x], dims=['detrended','variable',upper_prob.dims[0],upper_prob.dims[1],upper_prob.dims[2],upper_prob.dims[3],upper_prob.dims[4]],name='upper_tercile_probability')
                center_prob = xr.DataArray(center_prob_np, coords=[detrending,variables_gcm,center_prob.time,center_prob.season,center_prob.lead,center_prob.y,center_prob.x], dims=['detrended','variable',center_prob.dims[0],center_prob.dims[1],center_prob.dims[2],center_prob.dims[3],center_prob.dims[4]],name='center_tercile_probability')
                lower_prob = xr.DataArray(lower_prob_np, coords=[detrending,variables_gcm,lower_prob.time,lower_prob.season,lower_prob.lead,lower_prob.y,lower_prob.x], dims=['detrended','variable',lower_prob.dims[0],lower_prob.dims[1],lower_prob.dims[2],lower_prob.dims[3],lower_prob.dims[4]],name='lower_tercile_probability')
                
                #optionally apply land-sea mask to variable specific output file
                if variables_gcm[vv] in masked_variable_std: # <masked_variable_std> is defined in ./config/config_for_get_skill_season.py
                    print('Upon user request set in ./config/config_for_get_skill_season.py, values above the Sea are set to NAN for '+variables_gcm[vv]+' in the arrays containing modelled tercile probability time-series ! ')            
                    #get mask label as a function of the requested sub-domain
                    if domain in ('medcof','medcof2'):
                        masklabel = 'Medcof'
                    elif domain == 'iberia':
                        masklabel = domain[0].upper()+domain[1:]# mask name is Uppercase for iberian domain, i.e. "Iberia"
                    else:
                        ValueError('Check entry for <domain> input variable !')                
                    
                    # mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'_ascending_lat.nc' # <mask_dir> is defined in ./config/config_for_get_skill_season.py
                    mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc' #here, descending lats are needed (check why the DataArrays behave distinct concerning ascending or descending lats in pySeasonal)
                    
                    #apply the mask on the model probabilities of each tercile
                    upper_prob = apply_sea_mask(upper_prob,mask_file)
                    center_prob = apply_sea_mask(center_prob,mask_file)
                    lower_prob = apply_sea_mask(lower_prob,mask_file)
                else:
                    print('Upon user request set in ./config/config_for_get_skill_season.py, values above the Sea are RETAINED for '+variables_gcm[vv]+' in the arrays containing modelled tercile probability time-series ! ')

                tercile_prob = xr.merge((lower_prob,center_prob,upper_prob))

                #add singeton dimensions for visualization purposes
                tercile_prob = tercile_prob.expand_dims(aggregation=[agg_labels[ag]])
                tercile_prob = tercile_prob.expand_dims(model=[models[mm]])

                tercile_prob['x'].attrs = x_attrs
                tercile_prob['y'].attrs = y_attrs
                tercile_prob['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
                tercile_prob['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
                tercile_prob['season'].attrs['info'] = 'Season the forecast is valid for'
                tercile_prob['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
                #global attributes
                tercile_prob.attrs['model'] = models[mm]
                tercile_prob.attrs['description'] = 'observed tercile probabilities obtained from '+models[mm]
                tercile_prob.attrs['reference_period'] = str(years_quantile[0])+' to '+str(years_quantile[-1])
                tercile_prob.attrs['version'] = vers
                tercile_prob.attrs['author'] = "Swen Brands (CSIC-UC, Instituto de Fisica de Cantabria), brandssf@ifca.unican.es or swen.brands@gmail.com"
                
                #reformat the time dimension to only retain the years for the model terciles (continuous probability values)
                datevec_years = pd.DatetimeIndex(tercile_prob.time).year.astype(str)
                tercile_prob['time'] = pd.date_range(start=datevec_years[0], end=datevec_years[-1], freq="YS")
                del(datevec_years)

                # option to save one variable per file
                for vvv in np.arange(len(variables_gcm)):
                    tercile_prob_singlevar = tercile_prob.sel(variable=variables_gcm[vvv]).drop_vars("variable")
                    tercile_prob_singlevar.attrs['variable'] = variables_gcm[vvv]
                    savename_tercile_prob_singlevar = dir_netcdf_terciles+'/tercile_prob_pticlima_'+agg_labels[ag]+'_'+models[mm]+'_'+variables_gcm[vvv]+'_'+domain+'_'+str(years_common2label[0])+'_'+str(years_common2label[-1])+'_'+vers+'.nc'
                    encoding = {'upper_tercile_probability': {'zlib': True, 'complevel': compression_level}, 'center_tercile_probability': {'zlib': True, 'complevel': compression_level}, 'lower_tercile_probability': {'zlib': True, 'complevel': compression_level}}
                    tercile_prob_singlevar.to_netcdf(savename_tercile_prob_singlevar,encoding=encoding)
                    tercile_prob_singlevar.close()
                    del(tercile_prob_singlevar)
                
                # # option to save various variables per file 
                # savename_tercile_prob = dir_netcdf_terciles+'/tercile_prob_pticlima_'+agg_labels[ag]+'_'+models[mm]+'_'+domain+'_'+str(years_common2label[0])+'_'+str(years_common2label[-1])+'_'+vers+'.nc'
                # encoding = {'upper_tercile_probability': {'zlib': True, 'complevel': compression_level}, 'center_tercile_probability': {'zlib': True, 'complevel': compression_level}, 'lower_tercile_probability': {'zlib': True, 'complevel': compression_level}}
                # tercile_prob.to_netcdf(savename_tercile_prob,encoding=encoding)

                #merge and save observed terciles
                lower_tercile_obs = xr.DataArray(lower_tercile_obs, coords=[detrending,variables_obs,lower_prob.time,lower_prob.season,lower_prob.lead,lower_prob.y,lower_prob.x], dims=['detrended','variable',lower_prob.dims[2],lower_prob.dims[3],lower_prob.dims[4],lower_prob.dims[5],lower_prob.dims[6]],name='lower_tercile_binary')
                center_tercile_obs = xr.DataArray(center_tercile_obs, coords=[detrending,variables_obs,center_prob.time,center_prob.season,center_prob.lead,center_prob.y,center_prob.x], dims=['detrended','variable',center_prob.dims[2],center_prob.dims[3],center_prob.dims[4],center_prob.dims[5],center_prob.dims[6]],name='center_tercile_binary')
                upper_tercile_obs = xr.DataArray(upper_tercile_obs, coords=[detrending,variables_obs,upper_prob.time,upper_prob.season,upper_prob.lead,upper_prob.y,upper_prob.x], dims=['detrended','variable',upper_prob.dims[2],upper_prob.dims[3],upper_prob.dims[4],upper_prob.dims[5],upper_prob.dims[6]],name='upper_tercile_binary')
                
                if variables_gcm[vv] in masked_variable_std: # <masked_variable_std> is defined in ./config/config_for_get_skill_season.py
                    print('Upon user request set in ./config/config_for_get_skill_season.py, values above the Sea are set to NAN for '+variables_gcm[vv]+' in the arrays containing observed tercile occurrence time-series ! ')
                    mask_file = mask_dir+'/ECMWF_Land_'+masklabel+'.nc' #here, descending lats are needed (check why the DataArrays behave distinct concerning ascending or descending lats in pySeasonal)
                    lower_tercile_obs = apply_sea_mask(lower_tercile_obs,mask_file)
                    center_tercile_obs = apply_sea_mask(center_tercile_obs,mask_file)
                    upper_tercile_obs = apply_sea_mask(upper_tercile_obs,mask_file)
                else:
                    print('Upon user request set in ./config/config_for_get_skill_season.py, values above the Sea are RETAINED for '+variables_gcm[vv]+' in the arrays containing observed tercile occurrence time-series ! ')

                tercile_bin_obs = xr.merge((lower_tercile_obs,center_tercile_obs,upper_tercile_obs)) #merge the observed tercile occurrence time series into a single xarray dataset
                
                #check whether there are two 1 values for the same year
                merger = xr.concat([lower_tercile_obs,center_tercile_obs,upper_tercile_obs], dim='tercile').assign_coords(tercile=('tercile', [1,2,3]))
                if np.any(merger.sum(dim='tercile') > 1):
                    ValueError('Binary value 1 has been found in <merger> for more than 1 tercile per year ! It should only appear in one specific tercile !')
                merger.close()
                del(merger)

                #add singeton dimensions for visualization purposes
                tercile_bin_obs = tercile_bin_obs.expand_dims(aggregation=[agg_labels[ag]])
                tercile_bin_obs = tercile_bin_obs.expand_dims(obs=[obs[oo]])
                
                #dimension attributes
                tercile_bin_obs['x'].attrs = x_attrs
                tercile_bin_obs['y'].attrs = y_attrs
                tercile_bin_obs['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
                tercile_bin_obs['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
                tercile_bin_obs['season'].attrs['info'] = 'Season the forecast is valid for'
                tercile_bin_obs['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
                #global attributes
                tercile_bin_obs.attrs['observation'] = obs[oo]
                tercile_bin_obs.attrs['description'] = 'observed terciles in binary format obtained from '+obs[oo]
                tercile_bin_obs.attrs['reference_period'] = str(years_quantile[0])+' to '+str(years_quantile[-1])
                tercile_bin_obs.attrs['version'] = vers
                tercile_bin_obs.attrs['author'] = "Swen Brands (CSIC-UC, Instituto de Fisica de Cantabria), brandssf@ifca.unican.es or swen.brands@gmail.com"
                
                # reformat the time dimension to only retain the years for the observed terciles in binary format
                datevec_years = pd.DatetimeIndex(tercile_bin_obs.time).year.astype(str)
                tercile_bin_obs['time'] = pd.date_range(start=datevec_years[0], end=datevec_years[-1], freq="YS")
                del(datevec_years)
                
                # option to save one variable per file
                for vvv in np.arange(len(variables_obs)):
                    tercile_bin_obs_singlevar = tercile_bin_obs.sel(variable=variables_obs[vvv]).drop_vars("variable")
                    tercile_bin_obs_singlevar.attrs['variable'] = variables_obs[vvv]
                    savename_tercile_bin_obs_singlevar = dir_netcdf_terciles+'/tercile_bin_pticlima_'+agg_labels[ag]+'_'+obs[oo]+'_'+variables_obs[vvv]+'_'+domain+'_'+str(years_common2label[0])+'_'+str(years_common2label[-1])+'_'+vers+'.nc'
                    encoding = {'upper_tercile_binary': {'zlib': True, 'complevel': compression_level}, 'center_tercile_binary': {'zlib': True, 'complevel': compression_level}, 'lower_tercile_binary': {'zlib': True, 'complevel': compression_level}}
                    tercile_bin_obs_singlevar.to_netcdf(savename_tercile_bin_obs_singlevar,encoding=encoding)
                    tercile_bin_obs_singlevar.close()
                    del(tercile_bin_obs_singlevar)
                    time.sleep(1)
                
                # # # option to save various variables per file 
                # savename_tercile_bin_obs = dir_netcdf_terciles+'/tercile_bin_pticlima_'+agg_labels[ag]+'_'+obs[oo]+'_'+domain+'_'+str(years_common2label[0])+'_'+str(years_common2label[-1])+'_'+vers+'.nc'
                # encoding = {'upper_tercile_binary': {'zlib': True, 'complevel': compression_level}, 'center_tercile_binary': {'zlib': True, 'complevel': compression_level}, 'lower_tercile_binary': {'zlib': True, 'complevel': compression_level}}
                # tercile_bin_obs.to_netcdf(savename_tercile_bin_obs,encoding=encoding)

                #clean
                upper_prob.close()
                center_prob.close()
                lower_prob.close()
                tercile_prob.close()
                lower_tercile_obs.close()
                center_tercile_obs.close()
                upper_tercile_obs.close()
                tercile_bin_obs.close()
                del(upper_prob,center_prob,lower_prob,tercile_prob,lower_tercile_obs,center_tercile_obs,upper_tercile_obs,tercile_bin_obs)

                #save the quantiles separately for each aggregation time and model
                #convert the two numpy arrays containing the two types of quantiles (memberwise and ensemble) into two xarray data arrays, merge them to a single xarray dataset, add attributes to this dataset and save it to netCDF format
                #gcm_quantile_vals = xr.DataArray(gcm_quantile_vals, coords=[detrending,variables_gcm,models[mm],np.round(quantiles,2).astype(precision),season2quan,lead2quan,members,y2quan,x2quan], dims=['detrended','variable','model','quantile_threshold','season','lead','member','y','x'], name='quantile_memberwise')
                gcm_quantile_vals = xr.DataArray(gcm_quantile_vals, coords=[detrending,variables_gcm,np.round(quantiles,2).astype(precision),season2quan,lead2quan,members,y2quan,x2quan], dims=['detrended','variable','quantile_threshold','season','lead','member','y','x'], name='quantile_memberwise')
                gcm_quantile_vals.attrs['description'] = 'quantile thresholds calculated separately fore each ensemble member' 
                #quantile_vals_ens = xr.DataArray(quantile_vals_ens, coords=[detrending,variables_gcm,models[mm],np.round(quantiles,2).astype(precision),season2quan,lead2quan,y2quan,x2quan], dims=['detrended','variable','model','quantile_threshold','season','lead','y','x'], name='quantile_ensemble')
                quantile_vals_ens = xr.DataArray(quantile_vals_ens, coords=[detrending,variables_gcm,np.round(quantiles,2).astype(precision),season2quan,lead2quan,y2quan,x2quan], dims=['detrended','variable','quantile_threshold','season','lead','y','x'], name='quantile_ensemble')
                quantile_vals_ens.attrs['description'] = 'quantile thresholds calculated on all ensemble members; the distinct ensemble members have been concatenated along the time dimension prior to calculating the quantiles'
                quantile_vals_merged = xr.merge((gcm_quantile_vals,quantile_vals_ens))

                #add singeton dimensions for visualization purposes
                quantile_vals_merged = quantile_vals_merged.expand_dims(aggregation=[agg_labels[ag]])
                quantile_vals_merged = quantile_vals_merged.expand_dims(model=[models[mm]])

                #dimension attributes
                quantile_vals_merged['x'].attrs = x_attrs
                quantile_vals_merged['y'].attrs = y_attrs
                quantile_vals_merged['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
                quantile_vals_merged['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
                #quantile_vals_merged['model'].attrs['info'] = 'Name and version of the model / prediction system'
                quantile_vals_merged['quantile_threshold'].attrs['info'] = 'Quantile thresholds rounded to 2 decimals'
                quantile_vals_merged['season'].attrs['info'] = 'Season the forecast is valid for'
                quantile_vals_merged['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
                #global attributes
                quantile_vals_merged.attrs['model'] = models[mm]
                quantile_vals_merged.attrs['reference_period'] = str(years_quantile[0])+' to '+str(years_quantile[-1])
                quantile_vals_merged.attrs['version'] = vers
                quantile_vals_merged.attrs['author'] = "Swen Brands (CSIC-UC, Instituto de Fisica de Cantabria), brandssf@ifca.unican.es or swen.brands@gmail.com"
                            
                # #save to netCDF, option to save various variables per file 
                # savename_quantiles = dir_netcdf_quantiles+'/quantiles_pticlima_'+agg_labels[ag]+'_'+models[mm]+'_'+domain+'_'+str(years_quantile[0])+'_'+str(years_quantile[-1])+'_'+vers+'.nc'
                # encoding = {'quantile_memberwise': {'zlib': True, 'complevel': compression_level}, 'quantile_ensemble': {'zlib': True, 'complevel': compression_level}}
                # quantile_vals_merged.to_netcdf(savename_quantiles,encoding=encoding)

                # option to save one variable per file
                for vvv in np.arange(len(variables_gcm)):
                    quantile_vals_merged_singlevar = quantile_vals_merged.sel(variable=variables_gcm[vvv]).drop_vars("variable")
                    quantile_vals_merged_singlevar.attrs['variable'] = variables_gcm[vvv]
                    savename_quantile_vals_merged_singlevar =  dir_netcdf_quantiles+'/quantiles_pticlima_'+agg_labels[ag]+'_'+models[mm]+'_'+variables_gcm[vvv]+'_'+domain+'_'+str(years_quantile[0])+'_'+str(years_quantile[-1])+'_'+vers+'.nc'
                    encoding = {'quantile_memberwise': {'zlib': True, 'complevel': compression_level}, 'quantile_ensemble': {'zlib': True, 'complevel': compression_level}}
                    quantile_vals_merged_singlevar.to_netcdf(savename_quantile_vals_merged_singlevar,encoding=encoding)
                    quantile_vals_merged_singlevar.close()
                    del(quantile_vals_merged_singlevar)
                    time.sleep(1)
                
                #close and delete xarray objects that are specific to modulator[mo] = 'none'
                gcm_quantile_vals.close()
                quantile_vals_ens.close()
                quantile_vals_merged.close()
                del(gcm_quantile_vals,quantile_vals_ens,quantile_vals_merged)

            #close remaining xarray objects
            season2quan.close()
            lead2quan.close()
            y2quan.close()
            x2quan.close()
            del(season2quan,lead2quan,y2quan,x2quan)

print('INFO: get_skill_season.py has been run successfully. A flag is written at '+FLAGDIR)
flagfile = FLAGDIR+'/get_skill_season_'+str(vers)+'_'+str(models)+'_model_'+str(variables_gcm)+'_'+str(agg_labels)+'_'+str(modulators)+'_'+str(phases)+'.flag'
flagfile = flagfile.replace("[","").replace("]","").replace("'","").replace(",","_")
file = open(flagfile,'w')
file.write('get_skill_season.py has been run successfully for '+str(vers)+', '+str(models)+', '+str(variables_obs)+', '+str(variables_gcm)+', '+str(agg_labels)+', '+str(modulators)+', '+str(phases))
file.close()
#print the elapsed time and close
end_time = time.time()
elapsed_time = (end_time - start_time)/60
print('The execution time of the entire script was: '+str(elapsed_time)+' minutes')
quit()