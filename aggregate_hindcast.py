#!/usr/bin/env python

'''This script aggregates daily GCM data arrays with the 4 dimensions time, member, lat, lon (or similar) to monthly-mean data arrays with the 5 dimensions time, lead, member, lat, lon and saves a newly generated xarray DataArray to netCDF format.
This is done to compare these monthly GCM values with monthly observations, regridded to the GCM grid with the <regrid_obs.py> script located in the same directory. The length of the time dimension in the output file
is 12 (months) x number of years set in the <years> parameter. If an init month is not set in the <imonth> parameter (e.g. because it is not available), then the corresponding variable value is set to nan in the output file.
Forecasts are used if no hindcasts are available for a given year (e.g. for ECMWF51 hindcasts are availble unitl 2016 only). The range of considered years is set in the <years> parameter.
Note that the monthly mean-value of the last lead-time (set in <n_lead>) may be calculated on very few daily values and in this case should be discared aferwareds in the <get_skill.py> script contained in the same folder.
Author: Swen Brands, brandssf@ifca.unican.es'''

#load packages
import numpy as np
import xarray as xr
import dask
import os
import pandas as pd
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cf
import pdb as pdb #then type <pdb.set_trace()> at a given line in the code below
exec(open('functions_seasonal.py').read()) #reads the <functions_seasonal.py> script containing a set of custom functions needed here

##set input parameters for observational datasets to be regridded
#variables = ['hurs','pr','psl','rsds','sfcWind','tas','tasmax','tasmin'] #variable names in directories and file names, note that pr and rsds are initially fluxes accumulated over the entire forecast period; these variables are dis-aggregeated to daily accumulations below in this script.
#variables_nc = ['hurs','pr','msi','rsds','sfcWind','tas','tasmax','tasmin'] #variable names within the netCDF files

#variables = ['psl','sfcWind','tas','pr','rsds'] #variable names in directories and file names
#variables_nc = ['psl','sfcWind','tas','pr','rsds'] #variable names within the netCDF files, differs in case of msi (msi is used within the file, but psl is used in the file name)
#3variables_new = ['msl','si10','t2m','tp','ssrd'] #new variable names; as provided by ERA5 data from CDS

variables = ['tas'] #variable names in directories and file names
variables_nc = ['tas'] #variable names within the netCDF files, differs in case of msi (msi is used within the file, but psl is used in the file name)
variables_new = ['t2m'] #new variable names; as provided by ERA5 data from CDS

#years = [1981,2016] #years to be regridded, the output files will be filled with monthly values, aggregated from daily values in this script, covering all months beginning in January of the indicated start year and ending in December of the indicated end year. If no daily input data is found for a given month, nans will be placed in the monthly output netCDF files.
years = [1981,2023]

#set input parameters for model datasets, only used to get the land-sea mask of the models listed in <model>
model = ['ecmwf'] #seasonal forecast model
version = ['51'] #and version thereof; pertains to <model> loop indicated with <mm> below
nr_mem = [25] #number of considered ensemble members, pertains to <model> loop. For instance, ECMWF51 has 25 hindcast and 51 forecast members so <nr_mem = 25> should be set if hindcasts and forecasts are combined in the skill evaluation. The first nr_mem members are selected.
imonth = [1,2,3,4,5,6,7,8,9,10,11,12] #month the forecasts are initialized on, 1 refers to the January 1st, 2 to Febrary 1st etc.
n_lead = 8 #considered lead-time in months

#set MEDCOF domain
domain = 'medcof' #spatial domain the model data is available on. So far, this is just a label used to find the input files and name the output files.
save_corrected_files = 'yes' #currently experimental

#set basic path structure for observations and land-sea masks from the models
home = os.getenv('HOME')
gcm_store = 'F' #laptop, F or extdisk2
savepath_base = home+'/datos/tareas/proyectos/pticlima/seasonal/results/gcm/aggregated' #Directory of the output files generated by this script

## EXECUTE #############################################################
xr.set_options(file_cache_maxsize=1)

#set path to input gcm files
if gcm_store == 'laptop':
    path_gcm_base = home+'/datos/GCMData/seasonal-original-single-levels/'+domain # head directory of the source files
elif gcm_store == 'F':
    path_gcm_base = '/media/swen/F/datos/GCMData/seasonal-original-single-levels/'+domain # head directory of the source files
elif gcm_store == 'extdisk2':
    path_gcm_base = '/media/swen/ext_disk2/datos/GCMData/seasonal-original-single-levels/'+domain # head directory of the source files
else:
    raise Exception('ERROR: unknown entry for <path_gcm_base> !')
print('The GCM files will be loaded from the base directory '+path_gcm_base+'...')

years_vec = np.arange(years[0],years[1]+1) #create an array of year
n_mon = len(years_vec)*12+n_lead-1 #length of the monthly time series in the output data array generated by this script, 12 is hard-coded because it refers to the number of months per year and therefore is a static variable, if the initialization is not provided in <imonth> the output data is set to nan
for mm in np.arange(len(model)):
    #create directory of the output netcdf files if necessary
    if os.path.isdir(savepath_base+'/'+model[mm]+version[mm]) != True:
        os.makedirs(savepath_base+'/'+model[mm]+version[mm])
    print('INFO: aggregating '+model[mm]+version[mm]+' data for '+str(nr_mem[mm])+' '+str(years[0])+' to '+str(years[-1])+' and months '+str(imonth).replace('[','').replace(',','').replace(']',''))
    for vv in np.arange(len(variables)):
        datelist = [] #init date list
        for yy in np.arange(len(years_vec)):
            #Check whether to use hindcasts or forecasts
            if years_vec[yy] > 2016 and model[mm]+version[mm] == 'ecmwf51':
                print('Info: No hindcast available for '+model[mm]+version[mm]+' and year '+str(years_vec[yy])+'. The forecast is loaded instead...')
                product = 'forecast'
            else:
                #print('Info: Loading hindcast for '+model[mm]+version[mm]+' and year '+str(years_vec[yy])+'...')
                product = 'hindcast'                
            #load each monthly init separately, aggregate daily to monthly-mean data and fill the numpy array <data_mon> interatively.
            for im in np.arange(len(imonth)):
                print('INFO: Loading '+variables[vv]+' from '+model[mm]+version[mm]+' on '+domain+' domain for '+str(imonth[im]).zfill(2)+' '+str(years_vec[yy]))
                path_gcm_data = path_gcm_base+'/'+product+'/'+variables[vv]+'/'+model[mm]+'/'+version[mm]+'/'+str(years_vec[yy])+str(imonth[im]).zfill(2)+'/seasonal-original-single-levels_'+domain+'_'+product+'_'+variables[vv]+'_'+model[mm]+'_'+version[mm]+'_'+str(years_vec[yy])+str(imonth[im]).zfill(2)+'.nc'
                
                #check whether netCDF file for years_vec[yy] and imonth[im], containing the monthly gcm intis, exists. This is done because a try because some files are missing. If the file is not there, continue to the next step of the loop / month indexed by <im>. 
                if os.path.isfile(path_gcm_data):
                    nc = xr.open_dataset(path_gcm_data)
                else:
                    print('WARNING: '+path_gcm_data+' is not available! Proceed to load the next netCDF file containing '+model[mm]+version[mm]+' data for '+str(years_vec[yy])+' and '+str(imonth[im]))
                    continue
                
                #transform GCM variables and units, if necessary
                nc, file_valid = transform_gcm_variable(nc,variables_nc[vv],variables_new[vv],model[mm],version[mm])
                
                # if (variables[vv] == 'tas') & (model[mm] == 'ecmwf') & (version[mm] == '51'):
                    # print('Info: Adding 2x273.15 to '+variables[vv]+' data from '+model[mm]+version[mm]+' to correct Predictia workflow error and then transform into Kelvin.')
                    # #nc[variables[vv]].values = nc[variables[vv]].values+273.15
                    # nc[variables[vv]][:] = nc[variables[vv]]+273.15+273.15
                    # nc[variables[vv]].attrs['units'] = 'daily mean '+variables_new[vv]+' in Kelvin'
                # elif (variables[vv] in ('pr','rsds')) & (model[mm] == 'ecmwf') & (version[mm] == '51'):
                    # print('Info: Disaggregate '+variables[vv]+' accumulated over the '+str(len(nc.time))+' days forecast period from '+model[mm]+version[mm]+' to daily sums.')
                    # vals_disagg = np.diff(nc[variables[vv]].values,n=1,axis=0)
                    # shape_disagg = vals_disagg.shape
                    # add_day = np.expand_dims(vals_disagg[-1,:,:,:],axis=0) #get last available difference
                    # #add_day = np.zeros((1,shape_disagg[1],shape_disagg[2],shape_disagg[3]))
                    # #add_day[:] = np.nan
                    # vals_disagg = np.concatenate((vals_disagg,add_day),axis=0)
                    # nc[variables[vv]][:] = vals_disagg
                    # nc[variables[vv]].attrs['units'] = 'daily accumulated '+variables_new[vv]+' in '+nc[variables[vv]].attrs['units']
                # else:
                    # print('Info: No data transformation is applied for '+variables[vv]+' data from '+model[mm]+version[mm]+'.')
                
                ##select ensemble members. This is done because the ensemble members in the forecast period may be more than in the hindcast period, e.g. 25 vs. 50 in ECWMF 51
                print('INFO: Selecting the first '+str(nr_mem[mm])+' ensemble members from a total of '+str(nc.member.shape[0])+' members...') 
                nc = nc.isel(member=np.arange(nr_mem[mm]))
                
                nc_mon = nc[variables_nc[vv]].resample(time="1MS").mean(dim="forecast_time") #https://stackoverflow.com/questions/50564459/using-xarray-to-make-monthly-average
                dates_mon = pd.DatetimeIndex(nc_mon.time)
                datelist = datelist+list(nc_mon.time.values) #concatenate the date list to create a monthly unique date vector covering the whole period considered in <years>; see below.
                if yy == 0 and im == 0:
                    data_mon = np.zeros((n_mon,n_lead,nc_mon.shape[1],nc_mon.shape[2],nc_mon.shape[3]))
                    data_mon[:] = np.nan

                    ##get dimensions and metadata to save in output netCDF file below
                    var_units = nc[variables_nc[vv]].units
                    #var_name = nc[variables_nc[vv]].name #optionally use variable name from input netCDF files
                    members = nc.member.values
                    region = nc.region.values
                    lons = nc.x.values
                    #lon_attrs = nc.x.attrs #currently not used
                    lats = nc.y.values
                    #lat_attrs = nc.y.attrs #currently not used
                
                pos_time = dates_mon.month-1 + ((dates_mon.year - years_vec[0])* 12)
                pos_lead = np.arange(len(dates_mon.month)) #corresponding position along the "lead" dimension
                data_mon[pos_time,pos_lead,:,:,:] = nc_mon.values
                nc.close() #close the currently open nc file object
                
                #if the input netCDF file is not valid, as revealed by transform_gcm_variable(), overwrite the original file with the newly created one
                if (file_valid == 0) & (save_corrected_files == 'yes'):
                    del(nc) #delete the previously opened nc file object
                    nc = xr.open_dataset(path_gcm_data) #and re-open it
                    #get encoding and variable unit of the input netCDF file for all dimensions and variables
                    ec_x = nc['x'].encoding
                    ec_y = nc['y'].encoding
                    ec_member = nc['member'].encoding
                    ec_forecast_reference_time = nc['forecast_reference_time'].encoding
                    ec_region = nc['region'].encoding
                    ec_time = nc['time'].encoding
                    ec_forecast_time = nc['forecast_time'].encoding
                    ec_var = nc[variables_nc[vv]].encoding
                    units_var = nc[variables_nc[vv]].units
                    
                    nc[variables_nc[vv]].values = (nc[variables_nc[vv]].astype(ec_var.get('dtype'))+273.15).values #set to float64 to be coherente with input data and subtract 273.15 to transform Kelvin to degrees Celsius and thus be coherent with the other ecmwf 51 input file download and processed by Predictia
                    #nc[variables_nc[vv]].attrs['units'] = units_var, is not necessary is previous lines works with .values; otherwise, the variable attributes are dropped and shoud be re-assigned here
                    path_corrected_gcm_data = path_gcm_base+'/'+product+'/'+variables[vv]+'/'+model[mm]+'/'+version[mm]+'/'+str(years_vec[yy])+str(imonth[im]).zfill(2)+'/corrected_seasonal-original-single-levels_'+domain+'_'+product+'_'+variables[vv]+'_'+model[mm]+'_'+version[mm]+'_'+str(years_vec[yy])+str(imonth[im]).zfill(2)+'.nc'
                    print('INFO: The units of the input array were wrong and have been corrected. The corrected array with units coherent to the remaining files is newly stored in '+path_corrected_gcm_data+' !')
                    #encoding = {'x': ec_x, 'y': ec_x, 'member': ec_member, 'forecast_reference_time': ec_forecast_reference_time, 'region': ec_region, 'time': ec_time, 'forecast_time': ec_forecast_time, variables_nc[vv]: ec_var}
                    # Valid encodings are: {'chunksizes', 'least_significant_digit', 'shuffle', 'complevel', 'compression', 'fletcher32', 'dtype', 'zlib', '_FillValue', 'contiguous'}
                    #encoding = {variables_nc[vv]: {'dtype': ec_var.get('dtype'), 'zlib': ec_var.get('zlib'), 'complevel': ec_var.get('complevel'), 'chunksizes': ec_var.get('chunksizes'), '_FillValue': ec_var.get('_FillValue'), 'shuffle': ec_var.get('shuffle'), 'fletcher32': ec_var.get('fletcher32'), 'contiguous': ec_var.get('contiguos')}}
                    var_encoding = {variables_nc[vv]: {'dtype': ec_var.get('dtype'), 'zlib': ec_var.get('zlib'), 'complevel': ec_var.get('complevel'), '_FillValue': ec_var.get('_FillValue'), 'shuffle': ec_var.get('shuffle'), 'fletcher32': ec_var.get('fletcher32'), 'contiguous': ec_var.get('contiguos')}}
                    nc.to_netcdf(path_corrected_gcm_data,encoding=var_encoding)
                    nc.close()
                    del(nc)
                    
                    #replace the old erroneous file with the new corrected one
                    print('INFO: Upon user request the erroneous file '+path_gcm_data+' is replaced with the new corrected file '+path_corrected_gcm_data+' !')
                    os.rename(path_corrected_gcm_data,path_gcm_data)
                    
                elif (file_valid == 0) & (save_corrected_files == 'no'):
                    print('INFO: The units of the input array were wrong and have been corrected for further processing with the pySeasonal package. However, as requested by the user, the wrong input netCDF file is not overwritten with the corrected file !')
                    nc.close()
                    del(nc)
                elif file_valid == 1:
                    print('INFO: The input file is valid following the criteria defined in transform_gcm_variable() and no corrections are necessary.')
                else:
                    nc.close()
                    del(nc)
                    raise Exception('ERROR: unknown entry for <file_valid> !')
                
                nc_mon.close()
                del(nc_mon)
                print(pos_time)
        
        ## generate pandas Datetime object with all unique dates, create xarray DataArray and save to netCDF
        datelist = pd.DatetimeIndex(datelist).unique()
        startdate = str(datelist.year[0])+'-01-01 00:00:00' #the start calendar day of the output nc file is fixed at 1st of January for ECMWF
        enddate = str(years[-1]+1)+'-'+str(n_lead-1).zfill(2)+startdate[-12:] #the end calendar day of the output nc file is fixed at 1st of July for ECMWF51 due to the 8-month leadtime (from December 1 of the previous year to July 1 of the end year)
        leads = np.arange(n_lead)
        daterange = pd.date_range(start=startdate, end=enddate, freq='MS') #MS = month start frequency, see https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases
        outnc = xr.DataArray(data_mon, coords=[daterange, leads, members, lats, lons], dims=['time', 'lead', 'member', 'y', 'x'], name=variables_new[vv])
        
        ##cut out the last n_lead-1 months to harmonize the time dimension with observations, currently not used because this is done afterwards in <get_skill.py> 
        #yearbool = (daterange.year >= years[0]) & (daterange.year <= years[1])
        #outnc = outnc.isel(time = yearbool)
        
        ##set netCDF attributes
        #variable attributes
        outnc.attrs['units'] = var_units
        outnc.attrs['standard_name'] = variables_new[vv]
        outnc.attrs['long_name'] = variables_new[vv]        
        ##time attributes
        #outnc.time.attrs['units'] = 'month' #The script runs into an error if this attribute is set because outnc cannot be saved
        outnc.time.attrs['standard_name'] = 'time'
        outnc.time.attrs['long_name'] = 'time'
        outnc.time.attrs['description'] = 'The forecast is valid for the indicated month and year.'
        #lead attribtues
        outnc.lead.attrs['units'] = 'month'
        outnc.lead.attrs['standard_name'] = 'lead'
        outnc.lead.attrs['long_name'] = 'forecast lead-time'
        outnc.lead.attrs['description'] = 'The forecast lead-time in months, i.e. 0 = from the init date to the last day of the first month, 1 = from the first day to the last day of the second month, and so on.'
        #member attributes
        outnc.member.attrs['units'] = 'categorical, '+str(members[0])+' to '+str(members[-1])
        outnc.member.attrs['standard_name'] = 'member'
        outnc.member.attrs['long_name'] = 'ensemble member'
        outnc.member.attrs['description'] = 'indicator of model member within the '+model[mm]+version[mm]+' ensemble as provided by the input files'
        #lon and lat attributes
        outnc.x.attrs['units'] = 'degrees_east'
        outnc.x.attrs['standard_name'] = 'longitude'
        outnc.x.attrs['long_name'] = 'longitude'
        outnc.y.attrs['units'] = 'degrees_north'
        outnc.y.attrs['standard_name'] = 'latitude'
        outnc.y.attrs['long_name'] = 'latitude'
        
        savename = savepath_base+'/'+model[mm]+version[mm]+'/'+variables_new[vv]+'_mon_'+model[mm]+version[mm]+'_'+str(nr_mem[mm])+'m_'+domain+'_'+str(years[0])+'_'+str(years[-1])+'.nc'
        outnc.to_netcdf(savename)
        outnc.close()

print('INFO: aggregate_hindcast.py has been run successfully! The output nc files containing the temporally aggregeted GCM data can be found in '+savepath_base)

