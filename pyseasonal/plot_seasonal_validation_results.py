#!/usr/bin/env python

'''Plots verification results calculated before with get_skill_season.py and generates binary skill masks that are stored in netCDF format.
Author: Swen Brands, brandssf@ifca.unican.es
'''

#load packages
import math
import sys
import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import cartopy.crs as ccrs
import cartopy.feature as cf
import os
import pandas as pd
import xskillscore as xs
from math import radians, cos, sin, asin, sqrt #needed to calculate haversine distance
import pdb as pdb #then type <pdb.set_trace()> at a given line in the code below
import time
import yaml
from pathlib import Path

from functions_seasonal import (
    apply_sea_mask,
    get_sub_domain,
    get_spatial_aggregation,
    plot_pcolormesh_seasonal,
    get_map_lowfreq_var,
)

start_time = time.time()

# optional input parameters passed via bash
if len(sys.argv) > 1:
    print("Reading from input parameters passed via bash")
    agg_label = [str(sys.argv[1])] # a list containing character strings
    vers = str(sys.argv[2]) # a single character string
    domain = str(sys.argv[3]) # a single character string
else:
    # agg_label = ['1mon','3mon'] #list of strings used to label to aggregation period in the output files generated by this script; the length of this list defines the number of aggregation windows
    agg_label = ['1mon']
    vers = 'v1r' #version of the validation results
    domain = 'medcof'


# INDICATE CONFIGURATION FILE ######################################

configuration_file = 'config_for_plot_seasonal_validation_results_'+domain+'.yaml'

####################################################################

#this is a function to load the configuration file
def load_config(config_file='config/'+configuration_file):
    """Load configuration from YAML file"""
    config_path = Path(__file__).parent.parent / config_file
    print('The path of the configuration file is '+str(config_path))
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)

    # Setup paths based on GCM_STORE environment variable
    gcm_store = os.getenv('GCM_STORE', 'lustre')
    if gcm_store in config['paths']:
        paths = config['paths'][gcm_store]
        config['paths'] = paths
    else:
        raise ValueError('Unknown entry for <gcm_store> !')

    return config

#load configuration from YAML file
config = load_config()

#set input parameters from configuration file
models = config['models']

#parameters per modell
variables = []
variables_out = []
file_years = []
ref_dataset = []
for mm in np.arange(len(models)):
    variables.append(config['model_settings'][models[mm]]['variables'])
    variables_out.append(config['model_settings'][models[mm]]['variables_out'])
    file_years.append(config['model_settings'][models[mm]]['file_years'])
    ref_dataset.append(config['model_settings'][models[mm]]['ref_dataset'])

subperiods = config['subperiods']
domain = config['domain']
sub_domain = config['sub_domain']
masked_variables = config['masked_variables']
corr_outlier = config['corr_outlier']
detrending = config['detrending']
critval_rho = config['critval_rho']
critval_skillscore = config['critval_skillscore']
critval_relbias = config['critval_relbias']
critval_bias = config['critval_bias']
critval_reliability = config['critval_reliability']
critval_rpc = config['critval_rpc']
scores = config['scores']
cont_scores = config['cont_scores']
relbias_max = config['relbias_max']
manual_cbar_variables = tuple(config['manual_cbar_variables']) #convert to tuple to match original code
meanrho_max = config['meanrho_max']
precision = config['precision']
plot_maps = config['plot_maps']
dpival = config['dpival']
figformat = config['figformat']
colormap_ascend = config['colormap_ascend']
colormap_div = config['colormap_div']
titlesize = config['titlesize']

# Extract paths from configuration
paths = config['paths'] # get paths from configuration
home = paths['home']
rundir = paths['rundir']
dir_flag = paths['dir_flag']+'/'+domain
auxdir = paths['auxdir']
dir_netcdf = paths['dir_netcdf']+'/'+vers #path to outupt netcdf files produced with this script, containing an xarray dataset with all verification results
mask_dir = paths['mask_dir'] #path to the land-sea masks

##EXECUTE ##############################################################

#load custom functions of the pySeasonal and pySolar packages (to be merged in the future) and go to run directory
os.chdir(rundir)

print('INFO: Verfying '+str(models)+' against for '+str(variables)+' from '+str(ref_dataset)+' domain '+domain+' and sub-domain '+sub_domain+', detrending '+str(detrending)+' and outlier correction '+corr_outlier)
## check consistency of input parameters
for mm in np.arange(len(models)):
    if len(variables[mm]) != len(ref_dataset[mm]):
        raise ValueError('The two input lists <variables[mm]> and <ref_dataset[mm]> must have the same length !')
    if len(variables[mm]) != len(variables_out[mm]):
        raise ValueError('The two input lists <variables[mm]> and <variables_out[mm]> must have the same length !')

#create output directories needed by this script, if needed.
if os.path.isdir(dir_netcdf) != True:
    os.makedirs(dir_netcdf)
if os.path.isdir(dir_flag) != True:
    os.makedirs(dir_flag)

#init global minimum and maximum values
max_len_var = max(len(var_sub) for var_sub in variables) #get maximum length of all sublists in the <variables> list
minvals_map = np.zeros((len(agg_label),len(subperiods),len(detrending),max_len_var,len(models),len(scores))) #init array containing zero values
minvals_map[:] = np.nan # transform zero to nan
maxvals_map = minvals_map.copy()
minvals_pcolor_fraction = minvals_map.copy()
maxvals_pcolor_fraction = minvals_map.copy()
minvals_pcolor_mean = minvals_map.copy()
maxvals_pcolor_mean = minvals_map.copy()

#get the lead times per aggregation period and model
#get maximum lead from files obtained with get_skill_season.py
lead_arr = np.zeros((len(agg_label),len(models)))
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/scores/'+sub_domain+'/'+agg_label[ag] #set path to the directory containing the validation results
    for mm in range(len(models)):
        if models[mm] in ('ecmwf51','cmcc35','cmcc4','eccc5','dwd22'):
            filename_input = 'validation_results_season_'+variables[mm][0]+'_'+agg_label[ag]+'_'+models[mm]+'_vs_'+ref_dataset[mm][0]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[0]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[0]+'_'+vers+'.nc'
        else:
            raise ValueError('Unknown entry for <models[mm]> !')
        nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input, decode_timedelta=False) #load the input dataset
        lead_arr[ag,mm] = len(nc_results.lead.values)
        nc_results.close()
lead_arr = xr.DataArray(lead_arr,coords=[agg_label,models],dims=['aggregation','model'], name='lead-time')

#get minimium and maximum values of the colormaps for 1) maps, 2) pcolors displaying areal fractions in percent and 3) pcolors displaying areal mean values
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/scores/'+sub_domain+'/'+agg_label[ag] #set path to the directory containing the validation results

    for mm in range(len(models)):
        for su in np.arange(len(subperiods)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables[mm])):
                    colormaps_fractions_spatial = [] #one colormap per score
                    colormaps_meanvals_spatial = []
                    #load netcdf files containing the verification results
                    filename_input = 'validation_results_season_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+models[mm]+'_vs_'+ref_dataset[mm][vv]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.nc'
                    nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input, decode_timedelta=False) #load the input dataset

                    #optionally apply land sea mask; set values of sea to nan
                    if variables[mm][vv] in masked_variables:
                        print('Upon user request, values for sea grid-boxes are set to nan for '+variables[mm][vv]+' !')

                        #get mask label as a function of the requested sub-domain
                        if domain == 'medcof' and sub_domain in ('medcof','medcof2'):
                            mask_file_indir = 'ECMWF_Land_Medcof_descending_lat_reformatted.nc' # mask file as it appears in its directory
                        elif domain == 'medcof' and sub_domain == 'iberia':
                            mask_file_indir = 'ECMWF_Land_Iberia.nc'
                        elif domain == 'Iberia' and sub_domain == 'Iberia':
                            mask_file_indir = 'PTI-grid_Iberia_010_descending_lat_reformatted.nc'
                        elif domain == 'Canarias' and sub_domain == 'Canarias':
                            mask_file_indir = 'PTI-grid_Canarias_descending_lat_reformatted.nc'
                        else:
                            raise ValueError('Check entry for <domain> and/or <sub_domain> input parameters !')

                        mask_file = mask_dir+'/'+mask_file_indir #here, descending lats are needed (check why the DataArrays behave distinct concerning ascending or descending lats in pySeasonal)
                        nc_results = apply_sea_mask(nc_results,mask_file,'y','x')

                    elif variables[mm][vv] not in masked_variables:
                        print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variables[mm][vv]+' !')
                    else:
                        ValueError('check whether <variables[mm][vv]> is in <masked_variables> !')

                    #optionally cut out sub domain
                    if domain == 'medcof' and sub_domain in ('iberia','medcof2'):
                        nc_results = get_sub_domain(nc_results,sub_domain) #select sub-domain to be verified
                    elif sub_domain == domain: #if set to <medcof>, then no sub-domain is chosen
                        print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
                    else:
                        raise ValueError('Unknown entry for the <domain> and/or <sub_domain> input parameters !')

                    #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
                    if det == 0 and vv == 0 and mm == 0:
                        #get meshes for obtaining the areal average or areal percentage of significant hindcast correlation coefficient
                        xx,yy = np.meshgrid(nc_results.x.values,nc_results.y.values)

                    #extract the min and max values for each score, <map> prefix points to values used for mapping at the grid-box scale and <pcolor> points to the values used in the pcolor figure
                    for sc in np.arange(len(scores)):
                        if scores[sc] in ('bias','relbias'):
                            if scores[sc] == 'relbias' and variables[mm][vv] in manual_cbar_variables:
                                print('INFO: for '+variables[mm][vv]+' and '+scores[sc]+', no min and max values are stored because they can be very large in dry regions due to the near-to-zero climatolologial precipitation.')
                            else:
                                maxvals_map[ag,su,det,vv,mm,sc] = np.abs(nc_results[scores[sc]]).max().values
                                minvals_map[ag,su,det,vv,mm,sc] = np.abs(nc_results[scores[sc]]).max().values*-1
                                meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                                fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()*-1
                                maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                                minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                        elif scores[sc] in ('mae','mape','rmse','crps_ensemble'):
                            maxvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].max().values
                            minvals_map[ag,su,det,vv,mm,sc] = 0
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                        elif scores[sc] in ('reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile'):
                            maxvals_map[ag,su,det,vv,mm,sc] = 0.5 #global maximum for the specific model, dataset, and variable, suggested by Jose Manuel Guti√©rrez
                            minvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].min().values #global minimum for the specific model, dataset, and variable
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.min()
                            #minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_ascend)
                        elif scores[sc] in ('rpc','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy)
                            if scores[sc] == 'rpc':
                                maxvals_map[ag,su,det,vv,mm,sc] = 2
                                minvals_map[ag,su,det,vv,mm,sc] = 0
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 2
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            else:
                                maxvals_map[ag,su,det,vv,mm,sc] = 1
                                minvals_map[ag,su,det,vv,mm,sc] = -1
                                # maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()
                                # minvals_pcolor_mean[ag,su,det,vv,mm,sc] = np.abs(meanvals_spatial).max()*-1
                                maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0.85
                                minvals_pcolor_mean[ag,su,det,vv,mm,sc] = -0.85

                            #pcolor colorbar limits for rpc and others are equal
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                        elif scores[sc] in ('pearson_r','spearman_r'):
                            if scores[sc] in ('pearson_r'):
                                score_pval = 'pearson_pval'
                            elif scores[sc] in ('spearman_r'):
                                score_pval = 'spearman_pval'
                            else:
                                raise ValueError('ERROR: check entry in <scores[sc]> !')
                            maxvals_map[ag,su,det,vv,mm,sc] = nc_results[scores[sc]].max().values
                            minvals_map[ag,su,det,vv,mm,sc] = 0
                            meanvals_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            # maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = meanvals_spatial.max()
                            # minvals_pcolor_mean[ag,su,det,vv,mm,sc] = 0
                            maxvals_pcolor_mean[ag,su,det,vv,mm,sc] = 1
                            minvals_pcolor_mean[ag,su,det,vv,mm,sc] = -1
                            fractions_spatial = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rho,pval_f=nc_results[score_pval].values,mode_f='fraction_smaller_pos',lat_f=yy)
                            maxvals_pcolor_fraction[ag,su,det,vv,mm,sc] = fractions_spatial.max()
                            minvals_pcolor_fraction[ag,su,det,vv,mm,sc] = 0
                            colormaps_fractions_spatial.append(colormap_ascend)
                            colormaps_meanvals_spatial.append(colormap_div)
                            del(score_pval)
                        else:
                            raise ValueError('Unknown value for <scores[sc]> !')
                    ##close file
                    nc_results.close()
                    del(nc_results)

#get minimum and maximum colorbar colours

minvals_pcolor_fraction = xr.DataArray(minvals_pcolor_fraction,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_pcolor_fraction = xr.DataArray(maxvals_pcolor_fraction,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

minvals_pcolor_mean = xr.DataArray(minvals_pcolor_mean,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_pcolor_mean = xr.DataArray(maxvals_pcolor_mean,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

minvals_map = xr.DataArray(minvals_map,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='minimum_values')
maxvals_map = xr.DataArray(maxvals_map,coords=[agg_label,subperiods,detrending,variables[mm],models,scores],dims=['aggregation','subperiod', 'detrending','variable','model','score'], name='maximum_values')

#then plot the results with this min and max values
for ag in np.arange(len(agg_label)):
    dir_netcdf_scores = dir_netcdf+'/scores/'+sub_domain+'/'+agg_label[ag] #set path to the directory containing the validation results
    dir_netcdf_skillmasks = dir_netcdf+'/skill_masks/'+sub_domain+'/'+agg_label[ag] #set path to the directory containing the validation results

    #create netCDF output directory if necessary
    if os.path.isdir(dir_netcdf_skillmasks) != True:
        os.makedirs(dir_netcdf_skillmasks)

    for mm in range(len(models)):
        dir_figs = dir_netcdf+'/skill_figs/'+sub_domain+'/'+agg_label[ag]+'/'+models[mm]+'/'+str(file_years[mm][0])+'_'+str(file_years[mm][1]) #path to output figures file generated by this script
        for su in np.arange(len(subperiods)):
            for det in np.arange(len(detrending)):
                for vv in np.arange(len(variables[mm])):
                    #create output directories if they do not exist.
                    if os.path.isdir(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps') != True:
                        os.makedirs(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps')

                    #load netcdf files containing the verification results
                    filename_input = 'validation_results_season_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+models[mm]+'_vs_'+ref_dataset[mm][vv]+'_'+domain+'_corroutlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.nc'
                    nc_results = xr.open_dataset(dir_netcdf_scores+'/'+filename_input, decode_timedelta=False)
                    lead_step = len(nc_results.lead.values) #length of the "lead" dimension

                    #optionally apply land sea mask; set values of sea to nan
                    if variables[mm][vv] in masked_variables:
                        print('Upon user request, values for sea grid-boxes are set to nan for '+variables[mm][vv]+' !')

                        #get mask label as a function of the requested sub-domain
                        if domain == 'medcof' and sub_domain in ('medcof','medcof2'):
                            mask_file_indir = 'ECMWF_Land_Medcof_descending_lat_reformatted.nc' # mask file as it appears in its directory
                        elif domain == 'medcof' and sub_domain == 'iberia':
                            mask_file_indir = 'ECMWF_Land_Iberia.nc'
                        elif domain == 'Iberia' and sub_domain == 'Iberia':
                            mask_file_indir = 'PTI-grid_Iberia_010_descending_lat_reformatted.nc'
                        elif domain == 'Canarias' and sub_domain == 'Canarias':
                            mask_file_indir = 'PTI-grid_Canarias_descending_lat_reformatted.nc'
                        else:
                            raise ValueError('Check entry for <domain> and/or <sub_domain> input parameters !')

                        mask_file = mask_dir+'/'+mask_file_indir #here, descending lats are needed (check why the DataArrays behave distinct concerning ascending or descending lats in pySeasonal)
                        nc_results = apply_sea_mask(nc_results,mask_file,'y','x')

                    elif variables[mm][vv] not in masked_variables:
                        print('As requested by the user, the verification results are not filtered by a land-sea mask for '+variables[mm][vv]+' !')
                    else:
                        ValueError('check whether <variables[mm][vv]> is in <masked_variables> !')

                    #optionally cut out sub domain
                    if sub_domain in ('iberia','medcof2'):
                        nc_results = get_sub_domain(nc_results,sub_domain)
                    elif sub_domain == domain: #no sub-domain is chosen
                        print('Upon user request, verification results for the '+domain+' domain will not be sub-sampled in space !')
                    else:
                        raise ValueError('ERROR: unknown entry for <sub_domain> input parameter !')

                    #initializing output numpy matrix containing a binary resutls array (1 = significant skill, 0 = spurious skill)
                    if su == 0 and det == 0 and vv == 0:
                        #get meshes for plotting the maps and init the output binary mask; halfres is used for plotting maps below
                        y_coord = nc_results.y.values
                        x_coord = nc_results.x.values
                        xx,yy = np.meshgrid(x_coord,y_coord)

                        #pdb.set_trace()
                        binary_mask = np.zeros((len(subperiods),len(detrending),len(variables_out[mm]),len(scores),len(nc_results.season),int(lead_arr.sel(aggregation=agg_label[ag],model=models[mm]).max().values),len(y_coord),len(x_coord)),dtype='single')
                        binary_mask[:] = np.nan
                        continuous_score = np.zeros((len(subperiods),len(detrending),len(variables_out[mm]),len(cont_scores),len(nc_results.season),int(lead_arr.sel(aggregation=agg_label[ag],model=models[mm]).max().values),len(y_coord),len(x_coord)),dtype='single')
                        continuous_score[:] = np.nan

                        halfres = np.abs(np.diff(nc_results.x.values))[0]/2 #needed to plot the pcolormesh

                    ##Get arrays to be shown as pcolor figures and maps (assigned as <pcolorme> and <mapme> respectively. In addition, retrieve a binary skill / no skill (1 / 0) named <binmask> below
                    score_unit = np.zeros((len(scores))).tolist()
                    score_info = score_unit.copy()
                    for sc in np.arange(len(scores)):
                        print('INFO: plotting '+scores[sc]+'...')
                        score_ref = nc_results.reference_observations
                        if os.path.isdir(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps/'+scores[sc]) != True:
                            os.makedirs(dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps/'+scores[sc])
                        if scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                            #pcolor for areal average of skill score values
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy) #calculate spatial mean crps skill score
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_skillscore,pval_f=nc_results[scores[sc]].values,mode_f='fraction_larger',lat_f=yy) #calculate areal fraction with skill score > 0
                            units_pcolor_mean = 'skill score'
                            units_pcolor_fraction = '%'
                            label_pcolor_mean = 'areal mean '+scores[sc]
                            label_pcolor_fraction = 'areal fraction > '+str(critval_skillscore)+' '+scores[sc]
                            mapme = nc_results[scores[sc]].values

                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = mapme > 0
                            mask0 = mapme <= 0
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            if scores[sc] == 'crps_ensemble_skillscore_clim':
                                score_info[sc] = 'Continuous Rank Probabililty Score with reference to a climatological forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0); the shape of the continuous variable distribution is taken from the ensemble members'
                            elif scores[sc] == 'crps_ensemble_skillscore_rand':
                                score_info[sc] = 'Continuous Rank Probabililty Score with reference to a random forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0); the shape of the continuous variable distribution is taken from the ensemble members'
                            elif scores[sc] in ('roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                score_info[sc] = 'ROC Area Under the Curve skill score with reference to a random forecast exceeding '+str(critval_skillscore)+', yes (1) or no (0)'
                            else:
                                ValueError('Unexpected entry for <scores[sc] !')

                        elif scores[sc] in ('pearson_r','spearman_r'):
                            if scores[sc] in ('pearson_r'):
                                score_pval = 'pearson_pval'
                            elif scores[sc] in ('spearman_r'):
                                score_pval = 'spearman_pval'
                            else:
                                raise ValueError('Check entry in <scores[sc]> !')

                            #areal percentage of significant grid-box scale correlation coefficients is calculated and plotted
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_testlvl_'+str(round(critval_rho*100))+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pval = nc_results[score_pval].values
                            rho = nc_results[scores[sc]].values
                            pcolorme_fraction = get_spatial_aggregation(rho.copy(),critval_rho,pval_f=pval.copy(),mode_f='fraction_smaller_pos',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                            pcolorme_mean = get_spatial_aggregation(rho.copy(),mode_f='mean',lat_f=yy) #.copy() is mandatory here; otherwise pval will be changed within the get_spatial_aggregation() function
                            mapme = rho
                            units_pcolor_mean = scores[sc]
                            units_pcolor_fraction = '%'
                            label_pcolor_fraction = 'areal fraction of sig. positive '+scores[sc]
                            label_pcolor_mean = 'areal mean '+scores[sc]

                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = (pval < critval_rho) & (rho > 0)
                            mask0 = (pval >= critval_rho) | (rho <= 0)
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = 'significant '+scores[sc]+' at '+str(round(critval_rho*100))+' percent test-level and positive sign for the ensemble mean time series, yes (1) or no (0)'

                        elif scores[sc] == 'rpc':
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_rpc,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < 1'
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = mapme > critval_rpc
                            mask0 = mapme <= critval_rpc
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                            score_info[sc] = nc_results[scores[sc]].long_name +' following '+nc_results[scores[sc]].source+' 1 for rpc > 1, 0 for rpc <= 1'

                        elif scores[sc] in ('bias','relbias'):
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(np.abs(nc_results[scores[sc]].values),mode_f='mean',lat_f=yy) #get weighted spatial mean value
                            #pcolorme = nc_results[scores[sc]].stack(flat_dim=('x', 'y')).median(dim='flat_dim') #get spatial median
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_bias,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            mapme = nc_results[scores[sc]].values

                            label_pcolor_mean = 'areal mean absolute '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_bias)
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            #add descriptive metadata
                            if scores[sc] == 'relbias':
                                info_string = 'relative bias of the ensemble mean time series in percent of the observed mean value below '+str(critval_relbias)+', yes (1) or no (0)'
                                threshold = critval_relbias #this is a percentage threshold
                            elif scores[sc] == 'bias':
                                info_string = 'bias of the ensemble mean time series below '+str(critval_bias)+', yes (1) or no (0)'
                                threshold = critval_bias
                            else:
                                raise ValueError('Unknown entry for <scores[sc]> !')

                            score_info[sc] = info_string
                            #create binary mask (skill yes/no)
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = np.abs(mapme) < threshold
                            mask0 = np.abs(mapme) >= threshold
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                        elif scores[sc] in ('reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile'):
                            savename_mean = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealmean_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            savename_fraction = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/pcolor_arealfraction_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+scores[sc]+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+'_'+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                            pcolorme_mean = get_spatial_aggregation(nc_results[scores[sc]].values,mode_f='mean',lat_f=yy)
                            pcolorme_fraction = get_spatial_aggregation(nc_results[scores[sc]].values,critval_reliability,pval_f=nc_results[scores[sc]].values,mode_f='fraction_smaller',lat_f=yy)
                            mapme = nc_results[scores[sc]].values
                            label_pcolor_mean = 'areal mean '+nc_results[scores[sc]].name
                            label_pcolor_fraction = 'areal fraction with '+nc_results[scores[sc]].name+' < '+str(critval_reliability)
                            units_pcolor_mean = nc_results[scores[sc]].units
                            units_pcolor_fraction = '%'
                            if scores[sc] == 'reliability_lower_tercile':
                                info_string = 'reliability for the lower tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            elif scores[sc] == 'reliability_center_tercile':
                                info_string = 'reliability for the center tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            elif scores[sc] == 'reliability_upper_tercile':
                                info_string = 'reliability for the upper tercile below '+str(critval_reliability)+', yes (1) or no (0)'
                                threshold = critval_reliability
                            else:
                                raise ValueError('Unknown entry for <scores[sc]> !')
                            score_info[sc] = info_string
                            #create binary mask (skill yes/no)
                            binmask = np.zeros(mapme.shape)
                            binmask[:] = np.nan
                            mask1 = np.abs(mapme) < threshold
                            mask0 = np.abs(mapme) >= threshold
                            binmask[mask1] = 1
                            binmask[mask0] = 0
                            score_unit[sc] = 'binary'
                        else:
                            raise ValueError(scores[sc]+' is currently not supported by plot_seasonal_validation_results.py !')

                        ## PLOT pcolor figures, x-axis: season / month the prediction is valid for and y-axis lead-time (1 season / month)
                        #convert to xr dataArray and add metadata necessary for plotting
                        pcolorme_mean = xr.DataArray(pcolorme_mean,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_mean)
                        pcolorme_fraction = xr.DataArray(pcolorme_fraction,coords=[np.arange(len(nc_results.season.values)),np.arange(len(nc_results.lead.values))],dims=['season', 'lead'], name=label_pcolor_fraction)
                        pcolorme_mean.attrs['units'] = units_pcolor_mean
                        pcolorme_fraction.attrs['units'] = units_pcolor_fraction
                        pcolorme_mean.attrs['season_label'] = nc_results.season.values
                        pcolorme_fraction.attrs['season_label'] = nc_results.season.values
                        pcolorme_mean.attrs['lead_label'] = nc_results.lead.values
                        pcolorme_fraction.attrs['lead_label'] = nc_results.lead.values

                        #make the pcolor plots
                        plot_pcolormesh_seasonal(pcolorme_mean,minvals_pcolor_mean.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).min().values,maxvals_pcolor_mean.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).max().values,savename_mean,colormaps_meanvals_spatial[sc],dpival)
                        plot_pcolormesh_seasonal(pcolorme_fraction,minvals_pcolor_fraction.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).min().values,maxvals_pcolor_fraction.sel(aggregation=agg_label[ag],variable=variables[mm][vv],score=scores[sc]).max().values,savename_fraction,colormaps_fractions_spatial[sc],dpival)

                        #produce a VERIFICATION MAP for each score, season and leadtime
                        if plot_maps == 'yes':
                            ('As requested by the user, verification maps are plotted !')
                            seasons = nc_results.season.values
                            leads = nc_results.lead.values
                            if scores[sc] in ('relbias','bias') and detrending[det] == 'yes':
                                print('INFO: '+scores[sc]+' is not plotted for detrended time series since the intercept/mean is also removed by the detrending function and the bias is thus 0 by definition.')
                            else:
                                for sea in np.arange(len(seasons)):
                                    for ll in np.arange(len(leads)):
                                        if scores[sc] in ('pearson_r','spearman_r'):
                                            critval_label = str(round(critval_rho*100))
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        elif scores[sc] in ('relbias'):
                                            critval_label = str(critval_relbias)
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        elif scores[sc] in ('bias','reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile'):
                                            critval_label = str(critval_bias)
                                            agreeind = binmask[sea,ll,:,:] == 0 #if set to 0, no signficance layer is plotted upon the pclormesh in get_map_lowfreq_var() function
                                        elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                            critval_label = str(critval_skillscore)
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        elif scores[sc] in ('rpc'):
                                            critval_label = str(critval_rpc)
                                            agreeind = binmask[sea,ll,:,:] == 1
                                        else:
                                            raise ValueError(scores[sc]+' is not yet supported by this function !')
                                        title = variables[mm][vv]+' '+seasons[sea]+' '+leads[ll]+' '+scores[sc]+' '+critval_label+' dtr'+detrending[det]+' '+sub_domain+' '+models[mm]+' vs '+score_ref+' '+str(file_years[mm][0])+' '+str(file_years[mm][1])
                                        savename = dir_figs+'/'+subperiods[su]+'/'+variables[mm][vv]+'/maps/'+scores[sc]+'/map_'+variables[mm][vv]+'_'+agg_label[ag]+'_'+seasons[sea]+'_'+leads[ll]+'_'+scores[sc]+'_'+critval_label+'_'+sub_domain+'_'+models[mm]+'_vs_'+score_ref+'_corr_outlier_'+corr_outlier+'_detrended_'+detrending[det]+'_'+str(file_years[mm][0])+str(file_years[mm][1])+'_'+subperiods[su]+'_'+vers+'.'+figformat
                                        cbarlabel = scores[sc]+' ('+str(nc_results[scores[sc]].units)+')'

                                        # set variables-specific limits for bias and relative bias
                                        # if scores[sc] in ('bias','relbias') and variables[mm][vv] in manual_cbar_variables:
                                        if scores[sc] in ('bias','relbias') and variables[mm][vv]:
                                            abs_max = np.max((np.abs(minvals_map.sel(variable=variables[mm][vv],score=scores[sc]).min().values),np.abs(maxvals_map.sel(variable=variables[mm][vv],score=scores[sc]).max().values)))
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                                        # elif scores[sc] == 'relbias' and variables[mm][vv] in manual_cbar_variables:
                                        #     get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,relbias_max*-1,relbias_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal') #colormap limits were set by the user in <relbias_max>
                                        elif scores[sc] in ('reliability_lower_tercile','reliability_center_tercile','reliability_upper_tercile'):
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,0,maxvals_map.sel(score=scores[sc]).max().values,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                        # Equal CRPS limits for all variables
                                        elif scores[sc] in ('crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                                            abs_max = np.max((np.abs(minvals_map.sel(score=scores[sc]).min().values),np.abs(maxvals_map.sel(score=scores[sc]).max().values)))# retain the maximum absolute value in the data, used to define the lower and upper limits of the colorbar in the next line
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,abs_max*-1,abs_max,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                        # Equal limits for remaining scores and variables
                                        elif scores[sc] in ('pearson_r','spearman_r'): #upper and lower limits are set at -1 and 1 in the next line
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,-1,1,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                                        else:
                                            #get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map[det,sc],maxvals_map[det,sc],dpival,title,savename,halfres,colormaps[sc],titlesize,cbarlabel) #colormap limits have been inferred from the score arrays above
                                            get_map_lowfreq_var(mapme[sea,ll,:,:],xx,yy,agreeind,minvals_map.sel(score=scores[sc]).min().values,maxvals_map.sel(score=scores[sc]).max().values,dpival,title,savename,halfres,colormaps_meanvals_spatial[sc],titlesize,cbarlabel,orientation_f='horizontal')
                        elif plot_maps == 'no':
                            print('As requested by the user, no verification maps are plotted !')
                        else:
                            ValueError('Check entry for <plot_maps> !')

                        #fill numpy array with binary mask
                        binary_mask[su,det,vv,sc,:,0:lead_step,:,:] = binmask

                    #fill numpy array with continuous skill scores to be added to the above binary mask
                    for csc in np.arange(len(cont_scores)):
                        continuous_score[su,det,vv,csc,:,0:lead_step,:,:] = nc_results[cont_scores[csc]].values

                    ##close input nc files and produced xr dataset
                    pcolorme_mean.close()
                    pcolorme_fraction.close()

        #bring the binary result masks into xarray data array format, one array per score. Then assign metadata to score / dataarray and stack them all as variables into a definite xarray dataset to be stored on netCDF
        for sc in np.arange(len(scores)):
            if scores[sc] in ('rpc','bias','relbias','pearson_r','spearman_r','crps_ensemble_skillscore_clim','crps_ensemble_skillscore_rand','roc_auc_lower_tercile_skillscore','roc_auc_center_tercile_skillscore','roc_auc_upper_tercile_skillscore'):
                print('INFO: saving binary validation mask for '+scores[sc])
                binary_mask_score_i = binary_mask[:,:,:,sc,:,:,:,:]
                # convert numpy array to xarray data array
                binary_mask_score_i = xr.DataArray(binary_mask_score_i,coords=[subperiods,detrending,variables_out[mm],nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['subperiod', 'detrended', 'variable', 'season', 'lead', 'y', 'x'], name=scores[sc]+'_binary')

                binary_mask_score_i.attrs['name'] = score_info[sc]
                binary_mask_score_i.attrs['units'] = score_unit[sc]
                binary_mask_score_i.attrs['info'] = score_info[sc]
                if sc == 0:
                    ds_binary_mask = binary_mask_score_i.to_dataset()
                else:
                    ds_binary_mask[scores[sc]+'_binary'] = binary_mask_score_i
                binary_mask_score_i.close()
                del(binary_mask_score_i)

                # #set version of the netCDF output file
                # if vers == 'as_input_file':
                    # version_label = nc_results.version
                # else:
                    # version_label = vers

                if nc_results.version != vers:
                    raise ValueError('Validation versions requested by the user in <vers> input variable does not match with metadata obtained from input file !')
            else:
                print('WARNING: Validation results for '+scores[sc]+' are not yet saved to netCDF because the transition to binary format still has to be discussed with the other PTI members.')
                continue

        for csc in np.arange(len(cont_scores)):
            print('INFO: saving continuous validation results for '+cont_scores[csc])
            continuous_score_i = continuous_score[:,:,:,csc,:,:,:,:]
            # convert numpy array to xarray data array
            continuous_score_i = xr.DataArray(continuous_score_i,coords=[subperiods,detrending,variables_out[mm],nc_results.season,nc_results.lead,nc_results.y,nc_results.x],dims=['subperiod', 'detrended', 'variable', 'season', 'lead', 'y', 'x'], name=cont_scores[csc]+'_continuous')
            continuous_score_i.attrs['name'] = cont_scores[csc]
            continuous_score_i.attrs['units'] = 'continuous values'
            if csc == 0:
                ds_continuous_score = continuous_score_i.to_dataset()
            else:
                ds_continuous_score[cont_scores[csc]+'_continuous'] = continuous_score_i
            continuous_score_i.close()
            del(continuous_score_i)

        #merge binary masks and continuous verification results
        ds_mask_plus_cont = xr.merge([ds_binary_mask,ds_continuous_score])
        # add global attributes
        ds_mask_plus_cont.attrs['version'] = vers
        ds_mask_plus_cont.attrs['model'] = models[mm]
        ds_mask_plus_cont.attrs['accumulation_period'] = agg_label[ag]
        ds_mask_plus_cont.attrs['validation_period'] = str(file_years[mm]).replace('[','').replace(']','').replace(', ',' to ')+', grouped by subperiods as indicated by the <subperiod> coordinate'
        ds_mask_plus_cont.attrs['author'] = "Swen Brands (Instituto de Fisica de Cantabria, CSIC-UC), email: brandssf@ifca.unican.es"
        ds_mask_plus_cont.attrs['nan_criterion'] = 'A nan is set at a given grid-box if it is returned by xskillscore, e.g. due to a division by zero. It has been confirmed that this occcurs, e.g., if it does not rain at all either in the modelled or quasi-observed time-series.'

        # add dimension and variable attributes
        ds_mask_plus_cont['subperiod'].attrs['info'] = 'Verification subperiod: <none> for no subperiod, <enso0init> for neutral ENSO events, <enso1init> for warm / El Ni√±o events and <enso2init> for cold / La Ni√±a events. Condition is valid on the month the model is initialized and becomes available, which is indicated by the <init> suffix.'
        ds_mask_plus_cont['detrended'].attrs['info'] = 'Linear de-trending was applied to the modelled and (quasi)observed time series prior to validation; yes or no'
        ds_mask_plus_cont['variable'].attrs['info'] = 'Meteorological variable acronym according to ERA5 nomenclature followed by Copernicus Climate Data Store (CDS)'
        ds_mask_plus_cont['season'].attrs['info'] = 'Season the forecast is valid for'
        ds_mask_plus_cont['lead'].attrs['info'] = 'Leadtime of the forecast; one per month'
        ds_mask_plus_cont['y'].attrs['name'] = 'latitude'
        ds_mask_plus_cont['y'].attrs['standard_name'] = 'latitude'
        ds_mask_plus_cont['x'].attrs['name'] = 'longitude'
        ds_mask_plus_cont['x'].attrs['standard_name'] = 'longitude'

        #save the binary mask xarray dataset and close
        nc_results.close()
        savename_netcdf = dir_netcdf_skillmasks+'/skill_masks_pticlima_'+sub_domain+'_'+agg_label[ag]+'_'+models[mm]+'_'+vers+'.nc'
        ds_mask_plus_cont.to_netcdf(savename_netcdf)

        ds_binary_mask.close()
        ds_mask_plus_cont.close()
        del(nc_results,ds_binary_mask,ds_mask_plus_cont)

    print('INFO: saving results at:')
    print(savename_netcdf)

print('INFO: plot_seasonal_validation_results.py has been run successfully. A flag is written at '+dir_flag)
flagfile = dir_flag+'/plot_seasonal_valiations_results_'+str(vers)+'_'+str(models)+'_'+domain+'_'+sub_domain+'_'+str(agg_label)+'_'+str(subperiods)+'_mapping_'+plot_maps+'.flag'
flagfile = flagfile.replace("[","").replace("]","").replace("'","").replace(",","_").replace(" ","")
file = open(flagfile,'w')
file.write('plot_seasonal_validation_results.py has been run successfully for '+str(vers)+', '+str(models)+', '+str(variables)+', '+str(domain)+', '+str(sub_domain)+', '+str(agg_label)+', '+str(subperiods)+', mapping '+plot_maps)
file.close()
#print the elapsed time and close
end_time = time.time()
elapsed_time = (end_time - start_time)/60
print('The execution time of the entire script was: '+str(elapsed_time)+' minutes')

quit()
#sys.exit(0)
